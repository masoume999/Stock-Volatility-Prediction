{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "f31d2QX72Q-8",
        "AIQfC7oiLhnU",
        "UiS7McIrLmEd",
        "b1e3A5gvPzR6",
        "JgH4xoeTU2xa",
        "b4HabdZkeZeL"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8Bmw42Ki0AU8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "from google.colab import drive\n",
        "import yfinance as yf\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, GRU, Dense, Dropout, Flatten, Bidirectional\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from math import sqrt\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "path = '/content/drive/MyDrive/Volatility/New_data_2000_2024/Not_normal_wd/'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uif3K8sx1zgI",
        "outputId": "3647ff46-acba-4f94-a0c0-ada69f6051ad"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def set_index(df):\n",
        "  df.index = pd.to_datetime(df['Date'])\n",
        "  df.drop(columns=['Date'], inplace=True)"
      ],
      "metadata": {
        "id": "IEBT-saF1ziO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filename = 'HV_data.csv'\n",
        "HV_data = pd.read_csv(path + filename)"
      ],
      "metadata": {
        "id": "4L7n--ks1-w1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_index(HV_data)"
      ],
      "metadata": {
        "id": "2L4kSCVl2LAW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tm_data = HV_data"
      ],
      "metadata": {
        "id": "2MyjHCW6180d"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "HV_data = HV_data.drop(columns=['HV'])"
      ],
      "metadata": {
        "id": "xp31SJq42DaW"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "HV_data['HV'] = tm_data['HV']"
      ],
      "metadata": {
        "id": "_HvxZqmQ2DeP"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "HV_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "id": "_2HB9UH92Dho",
        "outputId": "ae346258-6660-41f3-ee8f-81804be1290f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            ('GARCH', 'normal', 0)  ('GARCH', 'normal', 1)  \\\n",
              "Date                                                         \n",
              "2000-02-02                0.039601                0.038301   \n",
              "2000-02-03                0.037979                0.038355   \n",
              "2000-02-04                0.036791                0.037755   \n",
              "2000-02-07                0.046593                0.055072   \n",
              "2000-02-08                0.049131                0.041984   \n",
              "...                            ...                     ...   \n",
              "2024-08-26                0.000120               -0.000665   \n",
              "2024-08-27               -0.003889               -0.004798   \n",
              "2024-08-28                0.000280               -0.001148   \n",
              "2024-08-29               -0.000182               -0.000395   \n",
              "2024-08-30               -0.000978               -0.000269   \n",
              "\n",
              "            ('GARCH', 'gaussian', 0)  ('GARCH', 'gaussian', 1)  \\\n",
              "Date                                                             \n",
              "2000-02-02                  0.039601                  0.038301   \n",
              "2000-02-03                  0.037979                  0.038355   \n",
              "2000-02-04                  0.036791                  0.037755   \n",
              "2000-02-07                  0.046593                  0.055072   \n",
              "2000-02-08                  0.049131                  0.041984   \n",
              "...                              ...                       ...   \n",
              "2024-08-26                  0.000120                 -0.000665   \n",
              "2024-08-27                 -0.003889                 -0.004798   \n",
              "2024-08-28                  0.000280                 -0.001148   \n",
              "2024-08-29                 -0.000182                 -0.000395   \n",
              "2024-08-30                 -0.000978                 -0.000269   \n",
              "\n",
              "            ('GARCH', 'ged', 0)  ('GARCH', 'ged', 1)  \\\n",
              "Date                                                   \n",
              "2000-02-02             0.040044             0.039199   \n",
              "2000-02-03             0.041000             0.040608   \n",
              "2000-02-04             0.038214             0.040159   \n",
              "2000-02-07             0.047968             0.057512   \n",
              "2000-02-08             0.049560             0.042487   \n",
              "...                         ...                  ...   \n",
              "2024-08-26             0.000456            -0.000424   \n",
              "2024-08-27            -0.003539            -0.002953   \n",
              "2024-08-28             0.000449            -0.000383   \n",
              "2024-08-29            -0.000122             0.000615   \n",
              "2024-08-30            -0.000987             0.000618   \n",
              "\n",
              "            ('FIGARCH', 'normal', 0)  ('FIGARCH', 'normal', 1)  \\\n",
              "Date                                                             \n",
              "2000-02-02                  0.038388                  0.038388   \n",
              "2000-02-03                  0.038633                  0.038633   \n",
              "2000-02-04                  0.036990                  0.036990   \n",
              "2000-02-07                  0.046474                  0.046474   \n",
              "2000-02-08                  0.046711                  0.046711   \n",
              "...                              ...                       ...   \n",
              "2024-08-26                  0.000121                  0.000121   \n",
              "2024-08-27                 -0.004368                 -0.004368   \n",
              "2024-08-28                  0.000483                  0.000483   \n",
              "2024-08-29                 -0.000352                 -0.000352   \n",
              "2024-08-30                 -0.000533                 -0.000533   \n",
              "\n",
              "            ('FIGARCH', 'gaussian', 0)  ('FIGARCH', 'gaussian', 1)  ...  \\\n",
              "Date                                                                ...   \n",
              "2000-02-02                    0.038388                    0.038388  ...   \n",
              "2000-02-03                    0.038633                    0.038633  ...   \n",
              "2000-02-04                    0.036990                    0.036990  ...   \n",
              "2000-02-07                    0.046474                    0.046474  ...   \n",
              "2000-02-08                    0.046711                    0.046711  ...   \n",
              "...                                ...                         ...  ...   \n",
              "2024-08-26                    0.000121                    0.000121  ...   \n",
              "2024-08-27                   -0.004368                   -0.004368  ...   \n",
              "2024-08-28                    0.000483                    0.000483  ...   \n",
              "2024-08-29                   -0.000352                   -0.000352  ...   \n",
              "2024-08-30                   -0.000533                   -0.000533  ...   \n",
              "\n",
              "            unemployment_rate   usd_eur     usd_jpy   usd_gbp    usd_cny  \\\n",
              "Date                                                                       \n",
              "2000-02-02          11.596551  2.781970  307.252039  4.529620  23.415205   \n",
              "2000-02-03          11.596551  2.799436  311.491144  4.529266  23.412659   \n",
              "2000-02-04          11.419775  2.728548  306.262089  4.474254  23.415452   \n",
              "2000-02-07          11.313708  2.733357  299.491542  4.460147  23.414391   \n",
              "2000-02-08          11.313708  2.730104  301.761354  4.470789  23.415982   \n",
              "...                       ...       ...         ...       ...        ...   \n",
              "2024-08-26           0.000000 -0.002546    0.509117 -0.003041   0.005162   \n",
              "2024-08-27           0.000000  0.002051   -0.551543 -0.001202  -0.006788   \n",
              "2024-08-28           0.000000  0.000849    0.247487  0.000849   0.002263   \n",
              "2024-08-29           0.000000  0.002333   -0.148492  0.002404  -0.000071   \n",
              "2024-08-30           0.000000  0.001838   -0.685894  0.003818   0.005091   \n",
              "\n",
              "             usd_cad    usd_mxn     gt_data  log_returns        HV  \n",
              "Date                                                                \n",
              "2000-02-02  4.090860  26.750733  209.303607    -0.005604  0.039337  \n",
              "2000-02-03  4.119569  26.561052  209.303607    -0.008693  0.039588  \n",
              "2000-02-04  4.106629  26.433950  209.303607     0.000572  0.037904  \n",
              "2000-02-07  4.140641  26.339020  209.303607     0.027307  0.044257  \n",
              "2000-02-08  4.142338  26.135551  209.303607     0.010478  0.049006  \n",
              "...              ...        ...         ...          ...       ...  \n",
              "2024-08-26  0.001980  -0.105925    0.404061     0.008246  0.000123  \n",
              "2024-08-27 -0.001556  -0.173948    0.404061     0.009336  0.000656  \n",
              "2024-08-28  0.002051  -0.219910    0.707107     0.010307  0.000087  \n",
              "2024-08-29 -0.000566   0.084711   -0.101015     0.005365 -0.000019  \n",
              "2024-08-30 -0.002333   0.092207   -0.101015    -0.007129  0.000208  \n",
              "\n",
              "[6184 rows x 36 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d961fd3b-b549-4fec-a355-e5f1d709d6c0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>('GARCH', 'normal', 0)</th>\n",
              "      <th>('GARCH', 'normal', 1)</th>\n",
              "      <th>('GARCH', 'gaussian', 0)</th>\n",
              "      <th>('GARCH', 'gaussian', 1)</th>\n",
              "      <th>('GARCH', 'ged', 0)</th>\n",
              "      <th>('GARCH', 'ged', 1)</th>\n",
              "      <th>('FIGARCH', 'normal', 0)</th>\n",
              "      <th>('FIGARCH', 'normal', 1)</th>\n",
              "      <th>('FIGARCH', 'gaussian', 0)</th>\n",
              "      <th>('FIGARCH', 'gaussian', 1)</th>\n",
              "      <th>...</th>\n",
              "      <th>unemployment_rate</th>\n",
              "      <th>usd_eur</th>\n",
              "      <th>usd_jpy</th>\n",
              "      <th>usd_gbp</th>\n",
              "      <th>usd_cny</th>\n",
              "      <th>usd_cad</th>\n",
              "      <th>usd_mxn</th>\n",
              "      <th>gt_data</th>\n",
              "      <th>log_returns</th>\n",
              "      <th>HV</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2000-02-02</th>\n",
              "      <td>0.039601</td>\n",
              "      <td>0.038301</td>\n",
              "      <td>0.039601</td>\n",
              "      <td>0.038301</td>\n",
              "      <td>0.040044</td>\n",
              "      <td>0.039199</td>\n",
              "      <td>0.038388</td>\n",
              "      <td>0.038388</td>\n",
              "      <td>0.038388</td>\n",
              "      <td>0.038388</td>\n",
              "      <td>...</td>\n",
              "      <td>11.596551</td>\n",
              "      <td>2.781970</td>\n",
              "      <td>307.252039</td>\n",
              "      <td>4.529620</td>\n",
              "      <td>23.415205</td>\n",
              "      <td>4.090860</td>\n",
              "      <td>26.750733</td>\n",
              "      <td>209.303607</td>\n",
              "      <td>-0.005604</td>\n",
              "      <td>0.039337</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-02-03</th>\n",
              "      <td>0.037979</td>\n",
              "      <td>0.038355</td>\n",
              "      <td>0.037979</td>\n",
              "      <td>0.038355</td>\n",
              "      <td>0.041000</td>\n",
              "      <td>0.040608</td>\n",
              "      <td>0.038633</td>\n",
              "      <td>0.038633</td>\n",
              "      <td>0.038633</td>\n",
              "      <td>0.038633</td>\n",
              "      <td>...</td>\n",
              "      <td>11.596551</td>\n",
              "      <td>2.799436</td>\n",
              "      <td>311.491144</td>\n",
              "      <td>4.529266</td>\n",
              "      <td>23.412659</td>\n",
              "      <td>4.119569</td>\n",
              "      <td>26.561052</td>\n",
              "      <td>209.303607</td>\n",
              "      <td>-0.008693</td>\n",
              "      <td>0.039588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-02-04</th>\n",
              "      <td>0.036791</td>\n",
              "      <td>0.037755</td>\n",
              "      <td>0.036791</td>\n",
              "      <td>0.037755</td>\n",
              "      <td>0.038214</td>\n",
              "      <td>0.040159</td>\n",
              "      <td>0.036990</td>\n",
              "      <td>0.036990</td>\n",
              "      <td>0.036990</td>\n",
              "      <td>0.036990</td>\n",
              "      <td>...</td>\n",
              "      <td>11.419775</td>\n",
              "      <td>2.728548</td>\n",
              "      <td>306.262089</td>\n",
              "      <td>4.474254</td>\n",
              "      <td>23.415452</td>\n",
              "      <td>4.106629</td>\n",
              "      <td>26.433950</td>\n",
              "      <td>209.303607</td>\n",
              "      <td>0.000572</td>\n",
              "      <td>0.037904</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-02-07</th>\n",
              "      <td>0.046593</td>\n",
              "      <td>0.055072</td>\n",
              "      <td>0.046593</td>\n",
              "      <td>0.055072</td>\n",
              "      <td>0.047968</td>\n",
              "      <td>0.057512</td>\n",
              "      <td>0.046474</td>\n",
              "      <td>0.046474</td>\n",
              "      <td>0.046474</td>\n",
              "      <td>0.046474</td>\n",
              "      <td>...</td>\n",
              "      <td>11.313708</td>\n",
              "      <td>2.733357</td>\n",
              "      <td>299.491542</td>\n",
              "      <td>4.460147</td>\n",
              "      <td>23.414391</td>\n",
              "      <td>4.140641</td>\n",
              "      <td>26.339020</td>\n",
              "      <td>209.303607</td>\n",
              "      <td>0.027307</td>\n",
              "      <td>0.044257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-02-08</th>\n",
              "      <td>0.049131</td>\n",
              "      <td>0.041984</td>\n",
              "      <td>0.049131</td>\n",
              "      <td>0.041984</td>\n",
              "      <td>0.049560</td>\n",
              "      <td>0.042487</td>\n",
              "      <td>0.046711</td>\n",
              "      <td>0.046711</td>\n",
              "      <td>0.046711</td>\n",
              "      <td>0.046711</td>\n",
              "      <td>...</td>\n",
              "      <td>11.313708</td>\n",
              "      <td>2.730104</td>\n",
              "      <td>301.761354</td>\n",
              "      <td>4.470789</td>\n",
              "      <td>23.415982</td>\n",
              "      <td>4.142338</td>\n",
              "      <td>26.135551</td>\n",
              "      <td>209.303607</td>\n",
              "      <td>0.010478</td>\n",
              "      <td>0.049006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-08-26</th>\n",
              "      <td>0.000120</td>\n",
              "      <td>-0.000665</td>\n",
              "      <td>0.000120</td>\n",
              "      <td>-0.000665</td>\n",
              "      <td>0.000456</td>\n",
              "      <td>-0.000424</td>\n",
              "      <td>0.000121</td>\n",
              "      <td>0.000121</td>\n",
              "      <td>0.000121</td>\n",
              "      <td>0.000121</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.002546</td>\n",
              "      <td>0.509117</td>\n",
              "      <td>-0.003041</td>\n",
              "      <td>0.005162</td>\n",
              "      <td>0.001980</td>\n",
              "      <td>-0.105925</td>\n",
              "      <td>0.404061</td>\n",
              "      <td>0.008246</td>\n",
              "      <td>0.000123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-08-27</th>\n",
              "      <td>-0.003889</td>\n",
              "      <td>-0.004798</td>\n",
              "      <td>-0.003889</td>\n",
              "      <td>-0.004798</td>\n",
              "      <td>-0.003539</td>\n",
              "      <td>-0.002953</td>\n",
              "      <td>-0.004368</td>\n",
              "      <td>-0.004368</td>\n",
              "      <td>-0.004368</td>\n",
              "      <td>-0.004368</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.002051</td>\n",
              "      <td>-0.551543</td>\n",
              "      <td>-0.001202</td>\n",
              "      <td>-0.006788</td>\n",
              "      <td>-0.001556</td>\n",
              "      <td>-0.173948</td>\n",
              "      <td>0.404061</td>\n",
              "      <td>0.009336</td>\n",
              "      <td>0.000656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-08-28</th>\n",
              "      <td>0.000280</td>\n",
              "      <td>-0.001148</td>\n",
              "      <td>0.000280</td>\n",
              "      <td>-0.001148</td>\n",
              "      <td>0.000449</td>\n",
              "      <td>-0.000383</td>\n",
              "      <td>0.000483</td>\n",
              "      <td>0.000483</td>\n",
              "      <td>0.000483</td>\n",
              "      <td>0.000483</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000849</td>\n",
              "      <td>0.247487</td>\n",
              "      <td>0.000849</td>\n",
              "      <td>0.002263</td>\n",
              "      <td>0.002051</td>\n",
              "      <td>-0.219910</td>\n",
              "      <td>0.707107</td>\n",
              "      <td>0.010307</td>\n",
              "      <td>0.000087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-08-29</th>\n",
              "      <td>-0.000182</td>\n",
              "      <td>-0.000395</td>\n",
              "      <td>-0.000182</td>\n",
              "      <td>-0.000395</td>\n",
              "      <td>-0.000122</td>\n",
              "      <td>0.000615</td>\n",
              "      <td>-0.000352</td>\n",
              "      <td>-0.000352</td>\n",
              "      <td>-0.000352</td>\n",
              "      <td>-0.000352</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.002333</td>\n",
              "      <td>-0.148492</td>\n",
              "      <td>0.002404</td>\n",
              "      <td>-0.000071</td>\n",
              "      <td>-0.000566</td>\n",
              "      <td>0.084711</td>\n",
              "      <td>-0.101015</td>\n",
              "      <td>0.005365</td>\n",
              "      <td>-0.000019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-08-30</th>\n",
              "      <td>-0.000978</td>\n",
              "      <td>-0.000269</td>\n",
              "      <td>-0.000978</td>\n",
              "      <td>-0.000269</td>\n",
              "      <td>-0.000987</td>\n",
              "      <td>0.000618</td>\n",
              "      <td>-0.000533</td>\n",
              "      <td>-0.000533</td>\n",
              "      <td>-0.000533</td>\n",
              "      <td>-0.000533</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001838</td>\n",
              "      <td>-0.685894</td>\n",
              "      <td>0.003818</td>\n",
              "      <td>0.005091</td>\n",
              "      <td>-0.002333</td>\n",
              "      <td>0.092207</td>\n",
              "      <td>-0.101015</td>\n",
              "      <td>-0.007129</td>\n",
              "      <td>0.000208</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6184 rows × 36 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d961fd3b-b549-4fec-a355-e5f1d709d6c0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d961fd3b-b549-4fec-a355-e5f1d709d6c0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d961fd3b-b549-4fec-a355-e5f1d709d6c0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c9af5409-3e21-42fa-96b0-567fde0bdb2e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c9af5409-3e21-42fa-96b0-567fde0bdb2e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c9af5409-3e21-42fa-96b0-567fde0bdb2e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "HV_data"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split train, validation and test data"
      ],
      "metadata": {
        "id": "f31d2QX72Q-8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_data(data, target, train_end =datetime(2022, 5, 30), test_start=datetime(2022, 5, 31), test_size=0.1):\n",
        "  test_data = data.loc[test_start:]\n",
        "\n",
        "  train_val = data.loc[:train_end]\n",
        "  train_data, val_data = train_test_split(train_val, test_size=test_size, shuffle=False)\n",
        "\n",
        "  return train_data, val_data, test_data"
      ],
      "metadata": {
        "id": "3ZBlldE1h1rw"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sliding_window_transform(X, y, timesteps):\n",
        "  X_windows = []\n",
        "  y_windows = []\n",
        "  for i in range(len(X) - timesteps + 1):\n",
        "    X_window = X[i:i + timesteps]\n",
        "    y_window = y[i + timesteps - 1]\n",
        "    X_windows.append(X_window)\n",
        "    y_windows.append(y_window)\n",
        "\n",
        "  return np.array(X_windows), np.array(y_windows)"
      ],
      "metadata": {
        "id": "x-xBiOOU2LEc"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the rolling window function\n",
        "def rolling_window(df, in_sample_window_size, out_of_sample_size):\n",
        "  X, y = [], []\n",
        "  for i in range(in_sample_window_size, len(df) - out_of_sample_size):\n",
        "    X.append(df.iloc[i - in_sample_window_size:i, :-1].values)  # All features except the target column\n",
        "    y.append(df.iloc[i:i + out_of_sample_size, -1].values)  # Target column\n",
        "\n",
        "  return np.array(X), np.array(y)"
      ],
      "metadata": {
        "id": "H4oEdogIh6PT"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "x2Pa23Ux2Ynt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_mape(actual, predicted):\n",
        "  actual, predicted = np.array(actual), np.array(predicted)\n",
        "  return np.mean(np.abs((actual - predicted) / actual)) * 100"
      ],
      "metadata": {
        "id": "coiUqSlqjI50"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## HV"
      ],
      "metadata": {
        "id": "2Ak0aCvF2bqR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "daily_train, daily_val, daily_test = split_data(HV_data, 'HV')"
      ],
      "metadata": {
        "id": "9Me1cu3q2LH6"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "in_sam_win_sz = 25\n",
        "out_sam_win_sz = 5"
      ],
      "metadata": {
        "id": "wbIoahpP-zBI"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "HV_X_train, HV_y_train = rolling_window(daily_train, in_sam_win_sz, out_sam_win_sz)\n",
        "HV_X_val, HV_y_val = rolling_window(daily_val, in_sam_win_sz, out_sam_win_sz)\n",
        "HV_X_test, HV_y_test = rolling_window(daily_test, in_sam_win_sz, out_sam_win_sz)"
      ],
      "metadata": {
        "id": "hxzzyyCR-1_m"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# HV_X_train = HV_X_train.reshape(HV_X_train.shape[0], win_sz, -1)\n",
        "# HV_X_val = HV_X_val.reshape(HV_X_val.shape[0], win_sz, -1)\n",
        "# HV_X_test = HV_X_test.reshape(HV_X_test.shape[0], win_sz, -1)"
      ],
      "metadata": {
        "id": "ns46ckgGA42H"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LSTM"
      ],
      "metadata": {
        "id": "AIQfC7oiLhnU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_garch_model = Sequential()\n",
        "lstm_garch_model.add(LSTM(48, input_shape=(HV_X_train.shape[1], HV_X_train.shape[2]), return_sequences=True))\n",
        "lstm_garch_model.add(Dropout(0.1))\n",
        "lstm_garch_model.add(LSTM(16))\n",
        "lstm_garch_model.add(Dropout(0.1))\n",
        "lstm_garch_model.add(Dense(5))\n",
        "\n",
        "lstm_garch_model.compile(optimizer=Adam(learning_rate=0.01), loss='mse')"
      ],
      "metadata": {
        "id": "Zf6h10cy1zlx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e5c5a06-2fc2-4e58-ee85-c0abeb3e5380"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_garch_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "Zpm8uSZJ3ESB",
        "outputId": "ffe7561a-090d-4ea5-d266-d7ccd2458b21"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m48\u001b[0m)              │          \u001b[38;5;34m16,128\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m48\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │           \u001b[38;5;34m4,160\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │              \u001b[38;5;34m85\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,128</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">85</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m20,373\u001b[0m (79.58 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,373</span> (79.58 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m20,373\u001b[0m (79.58 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,373</span> (79.58 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_history = lstm_garch_model.fit(HV_X_train, HV_y_train, epochs=80, batch_size=32, validation_data=(HV_X_val, HV_y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FcrtK-L3NgU",
        "outputId": "ffa3c136-914c-4194-a9ac-0844af114278"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - loss: 0.0101 - val_loss: 1.3723e-05\n",
            "Epoch 2/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 1.6937e-04 - val_loss: 5.9467e-06\n",
            "Epoch 3/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - loss: 1.2241e-04 - val_loss: 6.2645e-06\n",
            "Epoch 4/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 8.9961e-05 - val_loss: 5.6252e-06\n",
            "Epoch 5/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - loss: 9.3204e-05 - val_loss: 3.5015e-06\n",
            "Epoch 6/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 50ms/step - loss: 7.9564e-05 - val_loss: 2.5326e-06\n",
            "Epoch 7/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 37ms/step - loss: 7.3488e-05 - val_loss: 2.9084e-06\n",
            "Epoch 8/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 8.0615e-05 - val_loss: 1.0491e-06\n",
            "Epoch 9/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 6.0358e-05 - val_loss: 5.6939e-06\n",
            "Epoch 10/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - loss: 7.7137e-05 - val_loss: 7.8371e-06\n",
            "Epoch 11/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 6.0364e-05 - val_loss: 1.5141e-06\n",
            "Epoch 12/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - loss: 6.6465e-05 - val_loss: 5.0147e-06\n",
            "Epoch 13/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - loss: 8.4450e-05 - val_loss: 4.8126e-06\n",
            "Epoch 14/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - loss: 6.1218e-05 - val_loss: 1.3885e-06\n",
            "Epoch 15/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 5.6227e-05 - val_loss: 3.7114e-06\n",
            "Epoch 16/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 5.6542e-05 - val_loss: 1.2490e-06\n",
            "Epoch 17/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 38ms/step - loss: 7.9196e-05 - val_loss: 1.7270e-06\n",
            "Epoch 18/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 5.6959e-05 - val_loss: 3.9816e-06\n",
            "Epoch 19/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - loss: 5.8269e-05 - val_loss: 3.8398e-06\n",
            "Epoch 20/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - loss: 6.2856e-05 - val_loss: 7.9694e-07\n",
            "Epoch 21/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 28ms/step - loss: 6.5410e-05 - val_loss: 2.5080e-06\n",
            "Epoch 22/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 5.9813e-05 - val_loss: 2.2560e-06\n",
            "Epoch 23/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 5.9111e-05 - val_loss: 3.7615e-06\n",
            "Epoch 24/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - loss: 6.6305e-05 - val_loss: 1.3173e-05\n",
            "Epoch 25/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - loss: 6.3874e-05 - val_loss: 4.8370e-06\n",
            "Epoch 26/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - loss: 7.1031e-05 - val_loss: 3.2613e-06\n",
            "Epoch 27/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 7.7019e-05 - val_loss: 4.4475e-07\n",
            "Epoch 28/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 38ms/step - loss: 6.5633e-05 - val_loss: 6.1423e-06\n",
            "Epoch 29/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 6.2989e-05 - val_loss: 6.3272e-07\n",
            "Epoch 30/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 6.4158e-05 - val_loss: 4.8373e-06\n",
            "Epoch 31/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 35ms/step - loss: 5.9879e-05 - val_loss: 5.4340e-06\n",
            "Epoch 32/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 7.5756e-05 - val_loss: 7.9601e-06\n",
            "Epoch 33/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - loss: 7.9374e-05 - val_loss: 3.8321e-05\n",
            "Epoch 34/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 8.4439e-05 - val_loss: 1.4677e-06\n",
            "Epoch 35/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - loss: 6.8246e-05 - val_loss: 1.1713e-06\n",
            "Epoch 36/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 5.8342e-05 - val_loss: 5.6047e-06\n",
            "Epoch 37/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 6.2762e-05 - val_loss: 3.8241e-06\n",
            "Epoch 38/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 5.4103e-05 - val_loss: 7.2075e-06\n",
            "Epoch 39/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - loss: 6.8083e-05 - val_loss: 3.3427e-06\n",
            "Epoch 40/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 7.1591e-05 - val_loss: 5.7174e-04\n",
            "Epoch 41/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - loss: 5.2115e-04 - val_loss: 1.1072e-06\n",
            "Epoch 42/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 7.0618e-05 - val_loss: 1.6621e-06\n",
            "Epoch 43/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - loss: 5.6439e-05 - val_loss: 1.6683e-06\n",
            "Epoch 44/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 33ms/step - loss: 6.3317e-05 - val_loss: 9.7913e-07\n",
            "Epoch 45/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 5.9494e-05 - val_loss: 1.3785e-06\n",
            "Epoch 46/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - loss: 7.2678e-05 - val_loss: 8.3309e-06\n",
            "Epoch 47/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 6.7700e-05 - val_loss: 2.6668e-05\n",
            "Epoch 48/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - loss: 7.4194e-05 - val_loss: 9.1405e-06\n",
            "Epoch 49/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 5.9530e-05 - val_loss: 3.1624e-05\n",
            "Epoch 50/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - loss: 7.4965e-05 - val_loss: 1.2838e-06\n",
            "Epoch 51/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - loss: 7.2085e-05 - val_loss: 1.5532e-05\n",
            "Epoch 52/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 6.3438e-05 - val_loss: 1.7580e-05\n",
            "Epoch 53/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - loss: 6.3886e-05 - val_loss: 1.7346e-06\n",
            "Epoch 54/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - loss: 6.7417e-05 - val_loss: 8.0462e-06\n",
            "Epoch 55/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 5.6457e-05 - val_loss: 3.2815e-06\n",
            "Epoch 56/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 5.1470e-05 - val_loss: 1.8189e-06\n",
            "Epoch 57/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 28ms/step - loss: 8.4894e-05 - val_loss: 1.1747e-05\n",
            "Epoch 58/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - loss: 6.2940e-05 - val_loss: 2.3459e-05\n",
            "Epoch 59/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 7.0877e-05 - val_loss: 1.0757e-04\n",
            "Epoch 60/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 8.7832e-05 - val_loss: 2.2831e-06\n",
            "Epoch 61/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 35ms/step - loss: 5.8742e-05 - val_loss: 1.8924e-06\n",
            "Epoch 62/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 7.8861e-05 - val_loss: 1.3610e-06\n",
            "Epoch 63/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - loss: 5.9291e-05 - val_loss: 2.4638e-06\n",
            "Epoch 64/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - loss: 6.4462e-05 - val_loss: 2.0364e-06\n",
            "Epoch 65/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - loss: 6.0252e-05 - val_loss: 4.6293e-06\n",
            "Epoch 66/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - loss: 5.6278e-05 - val_loss: 3.0108e-05\n",
            "Epoch 67/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 6.6651e-05 - val_loss: 3.2465e-06\n",
            "Epoch 68/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - loss: 6.3809e-05 - val_loss: 3.9326e-06\n",
            "Epoch 69/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 28ms/step - loss: 6.4638e-05 - val_loss: 4.4312e-07\n",
            "Epoch 70/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 6.9394e-05 - val_loss: 1.8340e-05\n",
            "Epoch 71/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - loss: 6.9437e-05 - val_loss: 2.6853e-05\n",
            "Epoch 72/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - loss: 7.5658e-05 - val_loss: 1.0527e-05\n",
            "Epoch 73/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 6.4368e-05 - val_loss: 1.4243e-06\n",
            "Epoch 74/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - loss: 5.2945e-05 - val_loss: 5.0994e-06\n",
            "Epoch 75/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - loss: 6.1557e-05 - val_loss: 1.7088e-06\n",
            "Epoch 76/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 23ms/step - loss: 5.6164e-05 - val_loss: 7.6454e-07\n",
            "Epoch 77/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 34ms/step - loss: 6.6239e-05 - val_loss: 4.2866e-06\n",
            "Epoch 78/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 6.7612e-05 - val_loss: 5.7801e-05\n",
            "Epoch 79/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - loss: 7.4442e-05 - val_loss: 5.2106e-05\n",
            "Epoch 80/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 34ms/step - loss: 8.4695e-05 - val_loss: 7.2256e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions\n",
        "HV_test_predictions = lstm_garch_model.predict(HV_X_test)"
      ],
      "metadata": {
        "id": "A-zmdwqm_6_e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7e8b943-5874-43b5-d4e8-52798785bdbe"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mse = mean_squared_error(HV_y_test, HV_test_predictions)\n",
        "print(f'MSE: {mse}')\n",
        "\n",
        "rmse = np.sqrt(mse)\n",
        "print(f'RMSE: {rmse}')\n",
        "\n",
        "mae = mean_absolute_error(HV_y_test, HV_test_predictions)\n",
        "print(f'MAE: {mae}')\n",
        "\n",
        "mape = calculate_mape(HV_y_test, HV_test_predictions)\n",
        "print(f'MAPE: {mape}%')"
      ],
      "metadata": {
        "id": "Y8BUSWddHo1Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a39f9ad-51e1-4935-b3a4-e9819940de1a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 7.228990239524999e-06\n",
            "RMSE: 0.0026886781584126054\n",
            "MAE: 0.002212884378317901\n",
            "MAPE: 31116.480984335034%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GRU"
      ],
      "metadata": {
        "id": "UiS7McIrLmEd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gru_model = Sequential()\n",
        "gru_model.add(GRU(48, input_shape=(HV_X_train.shape[1], HV_X_train.shape[2]), return_sequences=True))\n",
        "gru_model.add(Dropout(0.1))\n",
        "gru_model.add(GRU(16))\n",
        "gru_model.add(Dropout(0.1))\n",
        "gru_model.add(Dense(5))\n",
        "\n",
        "gru_model.compile(optimizer=Adam(learning_rate=0.01), loss='mse')"
      ],
      "metadata": {
        "id": "2fd5ZZjRH2dD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gru_model.summary()"
      ],
      "metadata": {
        "id": "fi7nCfJRL0nz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gru_history = gru_model.fit(HV_X_train, HV_y_train, epochs=80, batch_size=32, validation_data=(HV_X_val, HV_y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAo9MoSmNg_1",
        "outputId": "12a38494-4453-465f-9232-dafd0abe259b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - loss: 0.0533 - val_loss: 1.4514e-05\n",
            "Epoch 2/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - loss: 2.0091e-04 - val_loss: 5.9310e-06\n",
            "Epoch 3/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - loss: 1.2887e-04 - val_loss: 4.0802e-06\n",
            "Epoch 4/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 9.6715e-05 - val_loss: 3.0445e-06\n",
            "Epoch 5/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - loss: 9.9466e-05 - val_loss: 3.5547e-06\n",
            "Epoch 6/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - loss: 7.6158e-05 - val_loss: 4.0919e-06\n",
            "Epoch 7/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - loss: 7.2741e-05 - val_loss: 3.5202e-06\n",
            "Epoch 8/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - loss: 6.3532e-05 - val_loss: 3.8449e-06\n",
            "Epoch 9/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 6.9472e-05 - val_loss: 3.0267e-06\n",
            "Epoch 10/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - loss: 6.6837e-05 - val_loss: 3.9332e-06\n",
            "Epoch 11/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - loss: 6.9891e-05 - val_loss: 5.0246e-06\n",
            "Epoch 12/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - loss: 7.1557e-05 - val_loss: 2.9063e-06\n",
            "Epoch 13/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - loss: 6.0110e-05 - val_loss: 3.2327e-06\n",
            "Epoch 14/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 5.8943e-05 - val_loss: 3.0396e-06\n",
            "Epoch 15/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - loss: 7.5491e-05 - val_loss: 3.9198e-06\n",
            "Epoch 16/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - loss: 5.6031e-05 - val_loss: 3.6287e-06\n",
            "Epoch 17/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - loss: 5.5958e-05 - val_loss: 3.3052e-06\n",
            "Epoch 18/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - loss: 7.1113e-05 - val_loss: 3.1345e-06\n",
            "Epoch 19/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 30ms/step - loss: 5.9562e-05 - val_loss: 3.2618e-06\n",
            "Epoch 20/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - loss: 5.4712e-05 - val_loss: 6.4480e-06\n",
            "Epoch 21/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - loss: 6.1931e-05 - val_loss: 2.7144e-06\n",
            "Epoch 22/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - loss: 6.1716e-05 - val_loss: 5.5028e-06\n",
            "Epoch 23/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 7.2658e-05 - val_loss: 4.0530e-06\n",
            "Epoch 24/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 28ms/step - loss: 6.7567e-05 - val_loss: 5.0718e-06\n",
            "Epoch 25/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - loss: 5.9711e-05 - val_loss: 4.3140e-06\n",
            "Epoch 26/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 7.0657e-05 - val_loss: 3.3694e-06\n",
            "Epoch 27/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 5.9756e-05 - val_loss: 2.9853e-06\n",
            "Epoch 28/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 35ms/step - loss: 7.5420e-05 - val_loss: 3.2889e-06\n",
            "Epoch 29/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - loss: 6.2745e-05 - val_loss: 3.7595e-06\n",
            "Epoch 30/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - loss: 5.3226e-05 - val_loss: 1.1404e-05\n",
            "Epoch 31/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 7.6548e-05 - val_loss: 1.0222e-05\n",
            "Epoch 32/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - loss: 8.1947e-05 - val_loss: 2.5676e-06\n",
            "Epoch 33/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - loss: 6.9934e-05 - val_loss: 4.0964e-06\n",
            "Epoch 34/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - loss: 6.1715e-05 - val_loss: 2.3268e-05\n",
            "Epoch 35/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - loss: 7.4126e-05 - val_loss: 2.2617e-06\n",
            "Epoch 36/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - loss: 6.5305e-05 - val_loss: 1.7692e-04\n",
            "Epoch 37/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 39ms/step - loss: 1.5786e-04 - val_loss: 5.9566e-06\n",
            "Epoch 38/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - loss: 6.9234e-05 - val_loss: 7.7219e-06\n",
            "Epoch 39/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - loss: 6.9036e-05 - val_loss: 3.3459e-06\n",
            "Epoch 40/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 39ms/step - loss: 7.2763e-05 - val_loss: 8.3375e-06\n",
            "Epoch 41/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - loss: 6.4785e-05 - val_loss: 1.4686e-05\n",
            "Epoch 42/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 8.4242e-05 - val_loss: 3.0269e-06\n",
            "Epoch 43/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - loss: 6.6948e-05 - val_loss: 5.2854e-05\n",
            "Epoch 44/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 7.6583e-05 - val_loss: 1.7438e-06\n",
            "Epoch 45/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - loss: 7.7379e-05 - val_loss: 2.6823e-05\n",
            "Epoch 46/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 7.6528e-05 - val_loss: 3.1728e-06\n",
            "Epoch 47/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - loss: 6.5748e-05 - val_loss: 3.2155e-06\n",
            "Epoch 48/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 6.3806e-05 - val_loss: 7.1192e-06\n",
            "Epoch 49/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - loss: 6.9609e-05 - val_loss: 4.8040e-06\n",
            "Epoch 50/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - loss: 6.5734e-05 - val_loss: 1.3311e-05\n",
            "Epoch 51/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - loss: 7.0250e-05 - val_loss: 1.5686e-05\n",
            "Epoch 52/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - loss: 6.4696e-05 - val_loss: 1.7322e-05\n",
            "Epoch 53/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 40ms/step - loss: 6.5208e-05 - val_loss: 4.6888e-06\n",
            "Epoch 54/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - loss: 6.8151e-05 - val_loss: 1.1316e-05\n",
            "Epoch 55/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - loss: 8.1684e-05 - val_loss: 3.2867e-06\n",
            "Epoch 56/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - loss: 5.9918e-05 - val_loss: 3.0747e-05\n",
            "Epoch 57/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 28ms/step - loss: 6.6910e-05 - val_loss: 2.3949e-06\n",
            "Epoch 58/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - loss: 6.5280e-05 - val_loss: 3.6329e-06\n",
            "Epoch 59/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 37ms/step - loss: 6.1105e-05 - val_loss: 3.2564e-05\n",
            "Epoch 60/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - loss: 7.3721e-05 - val_loss: 3.3054e-05\n",
            "Epoch 61/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - loss: 6.9627e-05 - val_loss: 8.5006e-06\n",
            "Epoch 62/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - loss: 6.2469e-05 - val_loss: 1.1883e-05\n",
            "Epoch 63/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 6.4294e-05 - val_loss: 8.6708e-06\n",
            "Epoch 64/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - loss: 5.3327e-05 - val_loss: 4.5144e-06\n",
            "Epoch 65/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - loss: 6.6010e-05 - val_loss: 3.1157e-06\n",
            "Epoch 66/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 34ms/step - loss: 7.0378e-05 - val_loss: 7.9392e-06\n",
            "Epoch 67/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - loss: 6.5702e-05 - val_loss: 1.3414e-05\n",
            "Epoch 68/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - loss: 6.6220e-05 - val_loss: 4.5127e-05\n",
            "Epoch 69/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - loss: 5.9463e-05 - val_loss: 7.6954e-06\n",
            "Epoch 70/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - loss: 6.5441e-05 - val_loss: 8.4236e-06\n",
            "Epoch 71/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - loss: 7.0010e-05 - val_loss: 1.8721e-05\n",
            "Epoch 72/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 43ms/step - loss: 6.0369e-05 - val_loss: 1.6193e-05\n",
            "Epoch 73/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - loss: 6.4141e-05 - val_loss: 1.1503e-05\n",
            "Epoch 74/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - loss: 7.3029e-05 - val_loss: 4.4756e-06\n",
            "Epoch 75/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 37ms/step - loss: 7.3245e-05 - val_loss: 9.3063e-06\n",
            "Epoch 76/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - loss: 7.0204e-05 - val_loss: 1.4728e-06\n",
            "Epoch 77/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - loss: 6.8914e-05 - val_loss: 2.5162e-06\n",
            "Epoch 78/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - loss: 6.8454e-05 - val_loss: 3.4497e-06\n",
            "Epoch 79/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - loss: 6.1780e-05 - val_loss: 4.0441e-06\n",
            "Epoch 80/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - loss: 7.6636e-05 - val_loss: 1.1536e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions\n",
        "HV_gru_predictions = gru_model.predict(HV_X_test)"
      ],
      "metadata": {
        "id": "jed591XqNhSM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfffcaa7-7c35-4bc5-ef03-e81729b1e550"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mse = mean_squared_error(HV_y_test, HV_gru_predictions)\n",
        "print(f'MSE: {mse}')\n",
        "\n",
        "rmse = np.sqrt(mse)\n",
        "print(f'RMSE: {rmse}')\n",
        "\n",
        "mae = mean_absolute_error(HV_y_test, HV_gru_predictions)\n",
        "print(f'MAE: {mae}')\n",
        "\n",
        "mape = calculate_mape(HV_y_test, HV_gru_predictions)\n",
        "print(f'MAPE: {mape}%')"
      ],
      "metadata": {
        "id": "WeZeC001NhcB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b82a5a9-a457-4347-ed09-f13b14e52145"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 1.1709414715888632e-05\n",
            "RMSE: 0.0034219022072362955\n",
            "MAE: 0.0031337627766335778\n",
            "MAPE: 44649.79379835331%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LSTM_GRU"
      ],
      "metadata": {
        "id": "b1e3A5gvPzR6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_gru_model = Sequential()\n",
        "lstm_gru_model.add(LSTM(48, input_shape=(HV_X_train.shape[1], HV_X_train.shape[2]), return_sequences=True))\n",
        "lstm_gru_model.add(Dropout(0.1))\n",
        "lstm_gru_model.add(GRU(16))\n",
        "lstm_gru_model.add(Dropout(0.1))\n",
        "lstm_gru_model.add(Dense(5))\n",
        "\n",
        "lstm_gru_model.compile(optimizer=Adam(learning_rate=0.01), loss='mse')"
      ],
      "metadata": {
        "id": "M4sDHB06Nhfb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fd129c1-d848-40ab-d100-80be1ec66ae7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_gru_model.summary()"
      ],
      "metadata": {
        "id": "OihmLvRzQWlV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "427bf501-ffc9-4e4e-d798-ff04f0b99af8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m48\u001b[0m)              │          \u001b[38;5;34m16,128\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m48\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_2 (\u001b[38;5;33mGRU\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │           \u001b[38;5;34m3,168\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │              \u001b[38;5;34m85\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,128</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,168</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">85</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m19,381\u001b[0m (75.71 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,381</span> (75.71 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m19,381\u001b[0m (75.71 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,381</span> (75.71 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_gru_history = lstm_gru_model.fit(HV_X_train, HV_y_train, epochs=80, batch_size=32, validation_data=(HV_X_val, HV_y_val))"
      ],
      "metadata": {
        "id": "_6UxHjRWQWnn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e16998f-30ce-46f7-919d-697999899011"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - loss: 0.0291 - val_loss: 1.1602e-04\n",
            "Epoch 2/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 5.2867e-04 - val_loss: 1.9767e-05\n",
            "Epoch 3/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - loss: 2.5477e-04 - val_loss: 2.1394e-05\n",
            "Epoch 4/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - loss: 1.5634e-04 - val_loss: 1.6351e-05\n",
            "Epoch 5/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 1.3544e-04 - val_loss: 5.1577e-06\n",
            "Epoch 6/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 28ms/step - loss: 1.1162e-04 - val_loss: 5.2675e-06\n",
            "Epoch 7/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - loss: 1.0033e-04 - val_loss: 6.2387e-06\n",
            "Epoch 8/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 25ms/step - loss: 8.0679e-05 - val_loss: 3.9093e-06\n",
            "Epoch 9/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - loss: 7.5528e-05 - val_loss: 4.0896e-06\n",
            "Epoch 10/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 7.1112e-05 - val_loss: 3.0306e-06\n",
            "Epoch 11/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - loss: 6.4705e-05 - val_loss: 2.1738e-06\n",
            "Epoch 12/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - loss: 6.3398e-05 - val_loss: 7.2793e-06\n",
            "Epoch 13/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 7.0162e-05 - val_loss: 3.6826e-06\n",
            "Epoch 14/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 6.7205e-05 - val_loss: 2.3911e-06\n",
            "Epoch 15/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 37ms/step - loss: 6.7221e-05 - val_loss: 9.5885e-06\n",
            "Epoch 16/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - loss: 6.3361e-05 - val_loss: 1.1979e-05\n",
            "Epoch 17/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 37ms/step - loss: 8.1177e-05 - val_loss: 8.6463e-06\n",
            "Epoch 18/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 28ms/step - loss: 7.8922e-05 - val_loss: 7.0027e-06\n",
            "Epoch 19/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - loss: 6.1695e-05 - val_loss: 1.8968e-06\n",
            "Epoch 20/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 37ms/step - loss: 7.5512e-05 - val_loss: 5.0981e-06\n",
            "Epoch 21/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - loss: 6.9192e-05 - val_loss: 5.7400e-06\n",
            "Epoch 22/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - loss: 6.5082e-05 - val_loss: 1.2177e-06\n",
            "Epoch 23/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - loss: 6.7972e-05 - val_loss: 4.6299e-06\n",
            "Epoch 24/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 7.0207e-05 - val_loss: 4.5105e-06\n",
            "Epoch 25/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - loss: 6.3889e-05 - val_loss: 3.7586e-06\n",
            "Epoch 26/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - loss: 7.4021e-05 - val_loss: 4.2272e-06\n",
            "Epoch 27/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 6.3685e-05 - val_loss: 1.8242e-05\n",
            "Epoch 28/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - loss: 6.8595e-05 - val_loss: 7.6183e-06\n",
            "Epoch 29/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - loss: 5.4205e-05 - val_loss: 2.0656e-06\n",
            "Epoch 30/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 5.7310e-05 - val_loss: 2.2965e-05\n",
            "Epoch 31/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - loss: 7.9530e-05 - val_loss: 2.1946e-06\n",
            "Epoch 32/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - loss: 7.4737e-05 - val_loss: 2.4518e-06\n",
            "Epoch 33/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 5.9357e-05 - val_loss: 2.2593e-06\n",
            "Epoch 34/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - loss: 7.5239e-05 - val_loss: 1.9666e-06\n",
            "Epoch 35/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - loss: 7.4181e-05 - val_loss: 3.7105e-06\n",
            "Epoch 36/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - loss: 6.4671e-05 - val_loss: 6.4920e-06\n",
            "Epoch 37/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 31ms/step - loss: 6.8177e-05 - val_loss: 3.4548e-06\n",
            "Epoch 38/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 7.4531e-05 - val_loss: 1.8572e-05\n",
            "Epoch 39/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - loss: 8.2146e-05 - val_loss: 1.0291e-04\n",
            "Epoch 40/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - loss: 8.0392e-05 - val_loss: 3.0699e-05\n",
            "Epoch 41/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 5.9129e-05 - val_loss: 6.0272e-06\n",
            "Epoch 42/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - loss: 7.6730e-05 - val_loss: 6.7244e-06\n",
            "Epoch 43/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - loss: 4.9188e-05 - val_loss: 5.8103e-06\n",
            "Epoch 44/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - loss: 6.6178e-05 - val_loss: 2.5803e-06\n",
            "Epoch 45/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - loss: 7.3713e-05 - val_loss: 4.1333e-05\n",
            "Epoch 46/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 7.5110e-05 - val_loss: 5.4886e-06\n",
            "Epoch 47/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 6.6430e-05 - val_loss: 2.4285e-06\n",
            "Epoch 48/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - loss: 5.5275e-05 - val_loss: 1.3069e-05\n",
            "Epoch 49/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 7.6703e-05 - val_loss: 3.7869e-06\n",
            "Epoch 50/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - loss: 7.7292e-05 - val_loss: 1.8628e-05\n",
            "Epoch 51/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - loss: 8.0315e-05 - val_loss: 2.3838e-05\n",
            "Epoch 52/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - loss: 8.0038e-05 - val_loss: 2.8875e-06\n",
            "Epoch 53/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 38ms/step - loss: 7.1765e-05 - val_loss: 9.2689e-06\n",
            "Epoch 54/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 5.6886e-05 - val_loss: 5.0208e-06\n",
            "Epoch 55/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - loss: 8.6432e-05 - val_loss: 5.2949e-06\n",
            "Epoch 56/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - loss: 7.4639e-05 - val_loss: 4.2051e-06\n",
            "Epoch 57/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - loss: 6.6977e-05 - val_loss: 3.5512e-06\n",
            "Epoch 58/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - loss: 6.9072e-05 - val_loss: 4.0686e-05\n",
            "Epoch 59/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - loss: 7.3436e-05 - val_loss: 6.2798e-06\n",
            "Epoch 60/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 30ms/step - loss: 7.3772e-05 - val_loss: 4.9962e-06\n",
            "Epoch 61/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - loss: 6.7346e-05 - val_loss: 4.2205e-06\n",
            "Epoch 62/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 5.8497e-05 - val_loss: 7.0355e-06\n",
            "Epoch 63/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 6.3807e-05 - val_loss: 7.6313e-06\n",
            "Epoch 64/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 34ms/step - loss: 5.4514e-05 - val_loss: 2.1376e-05\n",
            "Epoch 65/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - loss: 7.6996e-05 - val_loss: 2.3700e-06\n",
            "Epoch 66/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - loss: 6.7663e-05 - val_loss: 4.6782e-06\n",
            "Epoch 67/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 28ms/step - loss: 4.8181e-05 - val_loss: 3.7334e-06\n",
            "Epoch 68/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - loss: 5.6138e-05 - val_loss: 7.3480e-05\n",
            "Epoch 69/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 8.4767e-05 - val_loss: 9.5041e-06\n",
            "Epoch 70/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - loss: 7.8064e-05 - val_loss: 3.4431e-06\n",
            "Epoch 71/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - loss: 5.5804e-05 - val_loss: 4.9788e-06\n",
            "Epoch 72/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 29ms/step - loss: 5.6860e-05 - val_loss: 3.1966e-06\n",
            "Epoch 73/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - loss: 8.0263e-05 - val_loss: 1.0922e-05\n",
            "Epoch 74/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 7.2954e-05 - val_loss: 2.3286e-06\n",
            "Epoch 75/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - loss: 6.7287e-05 - val_loss: 2.7844e-06\n",
            "Epoch 76/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - loss: 6.9394e-05 - val_loss: 3.8636e-06\n",
            "Epoch 77/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 7.4242e-05 - val_loss: 5.5619e-06\n",
            "Epoch 78/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - loss: 6.2819e-05 - val_loss: 1.1781e-05\n",
            "Epoch 79/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - loss: 7.2559e-05 - val_loss: 3.9412e-06\n",
            "Epoch 80/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 7.0050e-05 - val_loss: 2.5750e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions\n",
        "HV_lstm_gru_predictions = lstm_gru_model.predict(HV_X_test)"
      ],
      "metadata": {
        "id": "HQLIfgQ5QWsf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed050ed5-c1bb-490a-f12f-c2b5e390e498"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mse = mean_squared_error(HV_y_test, HV_lstm_gru_predictions)\n",
        "print(f'MSE: {mse}')\n",
        "\n",
        "rmse = np.sqrt(mse)\n",
        "print(f'RMSE: {rmse}')\n",
        "\n",
        "mae = mean_absolute_error(HV_y_test, HV_lstm_gru_predictions)\n",
        "print(f'MAE: {mae}')\n",
        "\n",
        "mape = calculate_mape(HV_y_test, HV_lstm_gru_predictions)\n",
        "print(f'MAPE: {mape}%')"
      ],
      "metadata": {
        "id": "ieo5NKO1QWvw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f60ff00-7e61-4c88-e455-2eb7aedc3150"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 2.4543411124304922e-06\n",
            "RMSE: 0.0015666336880172378\n",
            "MAE: 0.0012387070480063768\n",
            "MAPE: 17230.679909540304%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BiLSTM"
      ],
      "metadata": {
        "id": "JgH4xoeTU2xa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bilstm_model = Sequential()\n",
        "bilstm_model.add(Bidirectional(LSTM(48, return_sequences=True), input_shape=(HV_X_train.shape[1], HV_X_train.shape[2])))\n",
        "bilstm_model.add(Dropout(0.1))\n",
        "bilstm_model.add(Bidirectional(LSTM(16)))\n",
        "bilstm_model.add(Dropout(0.1))\n",
        "bilstm_model.add(Dense(5))\n",
        "\n",
        "bilstm_model.compile(optimizer=Adam(learning_rate=0.01), loss='mse')"
      ],
      "metadata": {
        "id": "OWUQwJo7QWyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bilstm_model.summary()"
      ],
      "metadata": {
        "id": "HnknoIEUcfdt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bilstm_history = bilstm_model.fit(HV_X_train, HV_y_train, epochs=80, batch_size=32, validation_data=(HV_X_val, HV_y_val))"
      ],
      "metadata": {
        "id": "4bc45pjEatbC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions\n",
        "HV_bilstm_predictions = bilstm_model.predict(HV_X_test)"
      ],
      "metadata": {
        "id": "tSQQeKmCatdG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47906fc8-1d7a-4edf-c4c4-ac631ba3d5ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mse = mean_squared_error(HV_y_test, HV_bilstm_predictions)\n",
        "print(f'MSE: {mse}')\n",
        "\n",
        "rmse = np.sqrt(mse)\n",
        "print(f'RMSE: {rmse}')\n",
        "\n",
        "mae = mean_absolute_error(HV_y_test, HV_bilstm_predictions)\n",
        "print(f'MAE: {mae}')\n",
        "\n",
        "mape = calculate_mape(HV_y_test, HV_bilstm_predictions)\n",
        "print(f'MAPE: {mape}%')"
      ],
      "metadata": {
        "id": "GQwOXFU3atgm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57c458d3-0570-4476-cec8-5c033bfc3342"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 8.120603418915605e-06\n",
            "RMSE: 0.002849667247051067\n",
            "MAE: 0.0026374769310524722\n",
            "MAPE: 37347.43550935421%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BiLSTM_GRU"
      ],
      "metadata": {
        "id": "b4HabdZkeZeL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bilstm_gru_model = Sequential()\n",
        "bilstm_gru_model.add(Bidirectional(LSTM(48, return_sequences=True), input_shape=(HV_X_train.shape[1], HV_X_train.shape[2])))\n",
        "bilstm_gru_model.add(Dropout(0.1))\n",
        "bilstm_gru_model.add(GRU(16))\n",
        "bilstm_gru_model.add(Dropout(0.1))\n",
        "bilstm_gru_model.add(Dense(5))\n",
        "\n",
        "bilstm_gru_model.compile(optimizer=Adam(learning_rate=0.01), loss='mse')"
      ],
      "metadata": {
        "id": "39zUotTIc80l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98dcd25f-84e0-4eee-9264-93ccbe893924"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bilstm_gru_model.summary()"
      ],
      "metadata": {
        "id": "ueo7IuG1eqcL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "cd3a9330-599f-44eb-de5e-bce6667d7b34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ bidirectional_3 (\u001b[38;5;33mBidirectional\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m96\u001b[0m)              │          \u001b[38;5;34m32,256\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m96\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_4 (\u001b[38;5;33mGRU\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │           \u001b[38;5;34m5,472\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_11 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │              \u001b[38;5;34m85\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ bidirectional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">32,256</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">5,472</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">85</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m37,813\u001b[0m (147.71 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">37,813</span> (147.71 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m37,813\u001b[0m (147.71 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">37,813</span> (147.71 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bilstm_gru_history = bilstm_gru_model.fit(HV_X_train, HV_y_train, epochs=80, batch_size=32, validation_data=(HV_X_val, HV_y_val))"
      ],
      "metadata": {
        "id": "UrcF0MvXeqeh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4917a494-ea5f-4686-ccb7-c9c3058b9481"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 45ms/step - loss: 0.0339 - val_loss: 9.6630e-05\n",
            "Epoch 2/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 49ms/step - loss: 4.1968e-04 - val_loss: 1.5072e-05\n",
            "Epoch 3/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - loss: 1.9548e-04 - val_loss: 5.2549e-06\n",
            "Epoch 4/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - loss: 1.2985e-04 - val_loss: 1.0680e-05\n",
            "Epoch 5/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 9.6946e-05 - val_loss: 2.4289e-06\n",
            "Epoch 6/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - loss: 8.5007e-05 - val_loss: 3.6795e-06\n",
            "Epoch 7/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 49ms/step - loss: 8.2091e-05 - val_loss: 2.0624e-06\n",
            "Epoch 8/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 33ms/step - loss: 7.4086e-05 - val_loss: 1.6963e-06\n",
            "Epoch 9/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - loss: 6.1681e-05 - val_loss: 5.0886e-06\n",
            "Epoch 10/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - loss: 6.7297e-05 - val_loss: 1.3797e-06\n",
            "Epoch 11/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - loss: 6.6988e-05 - val_loss: 2.5886e-06\n",
            "Epoch 12/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - loss: 5.8161e-05 - val_loss: 8.7261e-07\n",
            "Epoch 13/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 34ms/step - loss: 5.6520e-05 - val_loss: 8.3810e-06\n",
            "Epoch 14/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 7.2029e-05 - val_loss: 6.2829e-06\n",
            "Epoch 15/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 45ms/step - loss: 6.6702e-05 - val_loss: 1.4450e-06\n",
            "Epoch 16/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - loss: 5.7117e-05 - val_loss: 1.0228e-06\n",
            "Epoch 17/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - loss: 6.5242e-05 - val_loss: 8.5041e-06\n",
            "Epoch 18/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 49ms/step - loss: 6.0761e-05 - val_loss: 2.8102e-06\n",
            "Epoch 19/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 35ms/step - loss: 5.5585e-05 - val_loss: 2.4334e-06\n",
            "Epoch 20/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 5.6451e-05 - val_loss: 1.2176e-06\n",
            "Epoch 21/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 47ms/step - loss: 7.0689e-05 - val_loss: 1.2345e-05\n",
            "Epoch 22/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - loss: 7.2738e-05 - val_loss: 7.0074e-06\n",
            "Epoch 23/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 49ms/step - loss: 6.0356e-05 - val_loss: 8.6680e-07\n",
            "Epoch 24/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 36ms/step - loss: 5.1422e-05 - val_loss: 1.1538e-05\n",
            "Epoch 25/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 5.6409e-05 - val_loss: 1.4697e-05\n",
            "Epoch 26/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 49ms/step - loss: 7.3690e-05 - val_loss: 7.4621e-07\n",
            "Epoch 27/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 35ms/step - loss: 6.9336e-05 - val_loss: 8.2543e-06\n",
            "Epoch 28/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 6.0472e-05 - val_loss: 8.1711e-06\n",
            "Epoch 29/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - loss: 7.7034e-05 - val_loss: 1.5412e-06\n",
            "Epoch 30/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - loss: 7.3519e-05 - val_loss: 5.1358e-05\n",
            "Epoch 31/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 1.0252e-04 - val_loss: 5.7604e-06\n",
            "Epoch 32/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - loss: 8.1792e-05 - val_loss: 4.7101e-06\n",
            "Epoch 33/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 7.5490e-05 - val_loss: 6.7786e-06\n",
            "Epoch 34/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 5.4405e-05 - val_loss: 1.1473e-06\n",
            "Epoch 35/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - loss: 6.3107e-05 - val_loss: 3.7461e-06\n",
            "Epoch 36/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 7.0814e-05 - val_loss: 1.8945e-06\n",
            "Epoch 37/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 6.4725e-05 - val_loss: 7.9917e-06\n",
            "Epoch 38/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - loss: 7.4019e-05 - val_loss: 1.8217e-05\n",
            "Epoch 39/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 33ms/step - loss: 6.8354e-05 - val_loss: 5.9307e-06\n",
            "Epoch 40/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 5.3716e-05 - val_loss: 8.5232e-07\n",
            "Epoch 41/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 48ms/step - loss: 7.0991e-05 - val_loss: 2.8812e-06\n",
            "Epoch 42/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 35ms/step - loss: 8.2057e-05 - val_loss: 6.6269e-07\n",
            "Epoch 43/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - loss: 6.1855e-05 - val_loss: 5.4632e-06\n",
            "Epoch 44/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 37ms/step - loss: 6.4863e-05 - val_loss: 2.2141e-06\n",
            "Epoch 45/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 46ms/step - loss: 6.2738e-05 - val_loss: 5.3486e-06\n",
            "Epoch 46/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - loss: 5.3638e-05 - val_loss: 2.3981e-06\n",
            "Epoch 47/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - loss: 6.4950e-05 - val_loss: 1.1418e-06\n",
            "Epoch 48/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 34ms/step - loss: 5.8575e-05 - val_loss: 1.3107e-06\n",
            "Epoch 49/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - loss: 6.7551e-05 - val_loss: 3.1393e-06\n",
            "Epoch 50/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 5.4938e-05 - val_loss: 1.0134e-06\n",
            "Epoch 51/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - loss: 6.3434e-05 - val_loss: 7.4337e-05\n",
            "Epoch 52/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - loss: 6.9503e-05 - val_loss: 1.6774e-05\n",
            "Epoch 53/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 47ms/step - loss: 5.3229e-05 - val_loss: 7.6486e-07\n",
            "Epoch 54/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - loss: 6.4913e-05 - val_loss: 1.9442e-06\n",
            "Epoch 55/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 49ms/step - loss: 6.5724e-05 - val_loss: 3.9889e-06\n",
            "Epoch 56/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - loss: 6.2228e-05 - val_loss: 4.8636e-05\n",
            "Epoch 57/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 40ms/step - loss: 9.6095e-05 - val_loss: 1.0326e-06\n",
            "Epoch 58/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 45ms/step - loss: 7.1558e-05 - val_loss: 7.7385e-07\n",
            "Epoch 59/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - loss: 6.2152e-05 - val_loss: 3.6540e-06\n",
            "Epoch 60/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 53ms/step - loss: 7.4658e-05 - val_loss: 4.2697e-06\n",
            "Epoch 61/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - loss: 5.1456e-05 - val_loss: 4.6281e-06\n",
            "Epoch 62/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - loss: 6.7531e-05 - val_loss: 3.6300e-06\n",
            "Epoch 63/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - loss: 4.5420e-05 - val_loss: 1.6547e-06\n",
            "Epoch 64/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 7.8420e-05 - val_loss: 7.1599e-06\n",
            "Epoch 65/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 50ms/step - loss: 5.8799e-05 - val_loss: 7.2374e-06\n",
            "Epoch 66/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 36ms/step - loss: 5.5240e-05 - val_loss: 4.4673e-06\n",
            "Epoch 67/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - loss: 5.7999e-05 - val_loss: 6.3988e-07\n",
            "Epoch 68/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 52ms/step - loss: 6.0979e-05 - val_loss: 1.4996e-06\n",
            "Epoch 69/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - loss: 6.8772e-05 - val_loss: 1.1192e-06\n",
            "Epoch 70/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 52ms/step - loss: 8.3007e-05 - val_loss: 1.4074e-06\n",
            "Epoch 71/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - loss: 6.5926e-05 - val_loss: 9.7774e-06\n",
            "Epoch 72/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 44ms/step - loss: 7.4067e-05 - val_loss: 2.0613e-07\n",
            "Epoch 73/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - loss: 5.9183e-05 - val_loss: 2.3888e-06\n",
            "Epoch 74/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - loss: 6.7033e-05 - val_loss: 1.3734e-06\n",
            "Epoch 75/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 7.7122e-05 - val_loss: 1.1442e-05\n",
            "Epoch 76/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 49ms/step - loss: 7.2715e-05 - val_loss: 2.3625e-06\n",
            "Epoch 77/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 46ms/step - loss: 6.4682e-05 - val_loss: 4.6564e-06\n",
            "Epoch 78/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 34ms/step - loss: 6.5620e-05 - val_loss: 3.4892e-06\n",
            "Epoch 79/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 49ms/step - loss: 6.6982e-05 - val_loss: 3.8689e-06\n",
            "Epoch 80/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 37ms/step - loss: 6.3126e-05 - val_loss: 5.9663e-07\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions\n",
        "HV_bilstm_gru_predictions = bilstm_gru_model.predict(HV_X_test)"
      ],
      "metadata": {
        "id": "v5nF6O0HeqiA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75903278-68d1-4975-f4a9-6d9e10183dee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mse = mean_squared_error(HV_y_test, HV_bilstm_gru_predictions)\n",
        "print(f'MSE: {mse}')\n",
        "\n",
        "rmse = np.sqrt(mse)\n",
        "print(f'RMSE: {rmse}')\n",
        "\n",
        "mae = mean_absolute_error(HV_y_test, HV_bilstm_gru_predictions)\n",
        "print(f'MAE: {mae}')\n",
        "\n",
        "mape = calculate_mape(HV_y_test, HV_bilstm_gru_predictions)\n",
        "print(f'MAPE: {mape}%')"
      ],
      "metadata": {
        "id": "f61Cmfi-e2N4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86c80ae6-3f58-47a7-cce4-1926b8e19e77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 6.472612620134574e-07\n",
            "RMSE: 0.0008045254887282673\n",
            "MAE: 0.0006273253992673622\n",
            "MAPE: 7969.562201704585%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e8AKY6e_hk8C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# path_1 = '/content/drive/MyDrive/Volatility/New_data_2000_2024/New_predictions/HV/'\n",
        "\n",
        "# df_pred = pd.DataFrame(HV_test_predictions[:,0], columns=['lstm_pred'])\n",
        "# filename = 'LSTM_pred.csv'\n",
        "# df_pred.to_csv(path_1 + filename)\n",
        "\n",
        "\n",
        "# df_pred = pd.DataFrame(HV_gru_predictions[:,0], columns=['gru_pred'])\n",
        "# filename = 'GRU_pred.csv'\n",
        "# df_pred.to_csv(path_1 + filename)\n",
        "\n",
        "\n",
        "# df_pred = pd.DataFrame(HV_lstm_gru_predictions[:,0], columns=['lstm_gru_pred'])\n",
        "# filename = 'LSTM_GRU_pred.csv'\n",
        "# df_pred.to_csv(path_1 + filename)\n",
        "\n",
        "\n",
        "# df_pred = pd.DataFrame(HV_bilstm_predictions[:,0], columns=['bilstm_pred'])\n",
        "# filename = 'BiLSTM_pred.csv'\n",
        "# df_pred.to_csv(path_1 + filename)\n",
        "\n",
        "\n",
        "# df_pred = pd.DataFrame(HV_bilstm_gru_predictions[:,0], columns=['bilstm_gru_pred'])\n",
        "# filename = 'BiLSTM_GRU_pred.csv'\n",
        "# df_pred.to_csv(path_1 + filename)"
      ],
      "metadata": {
        "id": "MucMIBImhvlz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tc7D6w6Fhvn3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}