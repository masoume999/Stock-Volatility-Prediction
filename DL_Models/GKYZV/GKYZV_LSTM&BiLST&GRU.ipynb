{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Bmw42Ki0AU8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "from google.colab import drive\n",
        "import yfinance as yf\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, GRU, Dense, Dropout, Flatten, Bidirectional\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from math import sqrt\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uif3K8sx1zgI",
        "outputId": "3596faa5-d789-477e-b3bb-84106fc407c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')\n",
        "path = '/content/drive/MyDrive/Volatility/New_data_2000_2024/Not_normal_wd/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IEBT-saF1ziO"
      },
      "outputs": [],
      "source": [
        "def set_index(df):\n",
        "  df.index = pd.to_datetime(df['Date'])\n",
        "  df.drop(columns=['Date'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4L7n--ks1-w1"
      },
      "outputs": [],
      "source": [
        "filename = 'GKYZV_data.csv'\n",
        "HV_data = pd.read_csv(path + filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2L4kSCVl2LAW"
      },
      "outputs": [],
      "source": [
        "set_index(HV_data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tm_data = HV_data"
      ],
      "metadata": {
        "id": "MUph8QOh17u7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "HV_data = HV_data.drop(columns=['GKYZV'])"
      ],
      "metadata": {
        "id": "H9oAAkT42CXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "HV_data['GKYZV'] = tm_data['GKYZV']"
      ],
      "metadata": {
        "id": "_jB8-BG32CZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "HV_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "pdz2OKtR2Cb1",
        "outputId": "4917a0d8-f681-4378-8961-0095112c5513"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            ('FIGARCH', 'normal', 0)  ('FIGARCH', 'normal', 1)  \\\n",
              "Date                                                             \n",
              "2000-02-02                  0.038388                  0.038388   \n",
              "2000-02-03                  0.038633                  0.038633   \n",
              "2000-02-04                  0.036990                  0.036990   \n",
              "2000-02-07                  0.046474                  0.046474   \n",
              "2000-02-08                  0.046711                  0.046711   \n",
              "...                              ...                       ...   \n",
              "2024-08-26                  0.000121                  0.000121   \n",
              "2024-08-27                 -0.004368                 -0.004368   \n",
              "2024-08-28                  0.000483                  0.000483   \n",
              "2024-08-29                 -0.000352                 -0.000352   \n",
              "2024-08-30                 -0.000533                 -0.000533   \n",
              "\n",
              "            ('FIGARCH', 'gaussian', 0)  ('FIGARCH', 'gaussian', 1)  \\\n",
              "Date                                                                 \n",
              "2000-02-02                    0.038388                    0.038388   \n",
              "2000-02-03                    0.038633                    0.038633   \n",
              "2000-02-04                    0.036990                    0.036990   \n",
              "2000-02-07                    0.046474                    0.046474   \n",
              "2000-02-08                    0.046711                    0.046711   \n",
              "...                                ...                         ...   \n",
              "2024-08-26                    0.000121                    0.000121   \n",
              "2024-08-27                   -0.004368                   -0.004368   \n",
              "2024-08-28                    0.000483                    0.000483   \n",
              "2024-08-29                   -0.000352                   -0.000352   \n",
              "2024-08-30                   -0.000533                   -0.000533   \n",
              "\n",
              "              gdp_growth        volume  ('GARCH', 'normal', 0)  \\\n",
              "Date                                                             \n",
              "2000-02-02  28984.929215  2.945453e+09                0.039601   \n",
              "2000-02-03  28984.929215  2.935907e+09                0.037979   \n",
              "2000-02-04  28984.929215  3.274647e+09                0.036791   \n",
              "2000-02-07  28984.929215  3.413593e+09                0.046593   \n",
              "2000-02-08  28984.929215  2.868803e+09                0.049131   \n",
              "...                  ...           ...                     ...   \n",
              "2024-08-26      0.000000  1.609587e+08                0.000120   \n",
              "2024-08-27      0.000000  9.767973e+07               -0.003889   \n",
              "2024-08-28      0.000000  2.498703e+08                0.000280   \n",
              "2024-08-29      0.000000 -1.799304e+08               -0.000182   \n",
              "2024-08-30      0.000000 -7.921081e+08               -0.000978   \n",
              "\n",
              "            ('GARCH', 'normal', 1)  ('GARCH', 'gaussian', 0)  \\\n",
              "Date                                                           \n",
              "2000-02-02                0.038301                  0.039601   \n",
              "2000-02-03                0.038355                  0.037979   \n",
              "2000-02-04                0.037755                  0.036791   \n",
              "2000-02-07                0.055072                  0.046593   \n",
              "2000-02-08                0.041984                  0.049131   \n",
              "...                            ...                       ...   \n",
              "2024-08-26               -0.000665                  0.000120   \n",
              "2024-08-27               -0.004798                 -0.003889   \n",
              "2024-08-28               -0.001148                  0.000280   \n",
              "2024-08-29               -0.000395                 -0.000182   \n",
              "2024-08-30               -0.000269                 -0.000978   \n",
              "\n",
              "            ('GARCH', 'gaussian', 1)  ...   usd_eur     usd_jpy   usd_gbp  \\\n",
              "Date                                  ...                                   \n",
              "2000-02-02                  0.038301  ...  2.781970  307.252039  4.529620   \n",
              "2000-02-03                  0.038355  ...  2.799436  311.491144  4.529266   \n",
              "2000-02-04                  0.037755  ...  2.728548  306.262089  4.474254   \n",
              "2000-02-07                  0.055072  ...  2.733357  299.491542  4.460147   \n",
              "2000-02-08                  0.041984  ...  2.730104  301.761354  4.470789   \n",
              "...                              ...  ...       ...         ...       ...   \n",
              "2024-08-26                 -0.000665  ... -0.002546    0.509117 -0.003041   \n",
              "2024-08-27                 -0.004798  ...  0.002051   -0.551543 -0.001202   \n",
              "2024-08-28                 -0.001148  ...  0.000849    0.247487  0.000849   \n",
              "2024-08-29                 -0.000395  ...  0.002333   -0.148492  0.002404   \n",
              "2024-08-30                 -0.000269  ...  0.001838   -0.685894  0.003818   \n",
              "\n",
              "              usd_cny   usd_cad    usd_mxn     gt_data  log_returns  \\\n",
              "Date                                                                  \n",
              "2000-02-02  23.415205  4.090860  26.750733  209.303607    -0.005604   \n",
              "2000-02-03  23.412659  4.119569  26.561052  209.303607    -0.008693   \n",
              "2000-02-04  23.415452  4.106629  26.433950  209.303607     0.000572   \n",
              "2000-02-07  23.414391  4.140641  26.339020  209.303607     0.027307   \n",
              "2000-02-08  23.415982  4.142338  26.135551  209.303607     0.010478   \n",
              "...               ...       ...        ...         ...          ...   \n",
              "2024-08-26   0.005162  0.001980  -0.105925    0.404061     0.008246   \n",
              "2024-08-27  -0.006788 -0.001556  -0.173948    0.404061     0.009336   \n",
              "2024-08-28   0.002263  0.002051  -0.219910    0.707107     0.010307   \n",
              "2024-08-29  -0.000071 -0.000566   0.084711   -0.101015     0.005365   \n",
              "2024-08-30   0.005091 -0.002333   0.092207   -0.101015    -0.007129   \n",
              "\n",
              "            ('APARCH', 'studentst', 1)     GKYZV  \n",
              "Date                                              \n",
              "2000-02-02                    0.037128  0.034017  \n",
              "2000-02-03                    0.038336  0.034689  \n",
              "2000-02-04                    0.049778  0.032966  \n",
              "2000-02-07                    0.065732  0.036397  \n",
              "2000-02-08                    0.043373  0.037620  \n",
              "...                                ...       ...  \n",
              "2024-08-26                   -0.004076  0.000040  \n",
              "2024-08-27                   -0.005604  0.000047  \n",
              "2024-08-28                   -0.001642  0.000051  \n",
              "2024-08-29                    0.000277  0.000078  \n",
              "2024-08-30                    0.000044  0.000352  \n",
              "\n",
              "[6184 rows x 30 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-301ed6cb-e336-4acb-afb0-2f7c8b0215e3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>('FIGARCH', 'normal', 0)</th>\n",
              "      <th>('FIGARCH', 'normal', 1)</th>\n",
              "      <th>('FIGARCH', 'gaussian', 0)</th>\n",
              "      <th>('FIGARCH', 'gaussian', 1)</th>\n",
              "      <th>gdp_growth</th>\n",
              "      <th>volume</th>\n",
              "      <th>('GARCH', 'normal', 0)</th>\n",
              "      <th>('GARCH', 'normal', 1)</th>\n",
              "      <th>('GARCH', 'gaussian', 0)</th>\n",
              "      <th>('GARCH', 'gaussian', 1)</th>\n",
              "      <th>...</th>\n",
              "      <th>usd_eur</th>\n",
              "      <th>usd_jpy</th>\n",
              "      <th>usd_gbp</th>\n",
              "      <th>usd_cny</th>\n",
              "      <th>usd_cad</th>\n",
              "      <th>usd_mxn</th>\n",
              "      <th>gt_data</th>\n",
              "      <th>log_returns</th>\n",
              "      <th>('APARCH', 'studentst', 1)</th>\n",
              "      <th>GKYZV</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2000-02-02</th>\n",
              "      <td>0.038388</td>\n",
              "      <td>0.038388</td>\n",
              "      <td>0.038388</td>\n",
              "      <td>0.038388</td>\n",
              "      <td>28984.929215</td>\n",
              "      <td>2.945453e+09</td>\n",
              "      <td>0.039601</td>\n",
              "      <td>0.038301</td>\n",
              "      <td>0.039601</td>\n",
              "      <td>0.038301</td>\n",
              "      <td>...</td>\n",
              "      <td>2.781970</td>\n",
              "      <td>307.252039</td>\n",
              "      <td>4.529620</td>\n",
              "      <td>23.415205</td>\n",
              "      <td>4.090860</td>\n",
              "      <td>26.750733</td>\n",
              "      <td>209.303607</td>\n",
              "      <td>-0.005604</td>\n",
              "      <td>0.037128</td>\n",
              "      <td>0.034017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-02-03</th>\n",
              "      <td>0.038633</td>\n",
              "      <td>0.038633</td>\n",
              "      <td>0.038633</td>\n",
              "      <td>0.038633</td>\n",
              "      <td>28984.929215</td>\n",
              "      <td>2.935907e+09</td>\n",
              "      <td>0.037979</td>\n",
              "      <td>0.038355</td>\n",
              "      <td>0.037979</td>\n",
              "      <td>0.038355</td>\n",
              "      <td>...</td>\n",
              "      <td>2.799436</td>\n",
              "      <td>311.491144</td>\n",
              "      <td>4.529266</td>\n",
              "      <td>23.412659</td>\n",
              "      <td>4.119569</td>\n",
              "      <td>26.561052</td>\n",
              "      <td>209.303607</td>\n",
              "      <td>-0.008693</td>\n",
              "      <td>0.038336</td>\n",
              "      <td>0.034689</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-02-04</th>\n",
              "      <td>0.036990</td>\n",
              "      <td>0.036990</td>\n",
              "      <td>0.036990</td>\n",
              "      <td>0.036990</td>\n",
              "      <td>28984.929215</td>\n",
              "      <td>3.274647e+09</td>\n",
              "      <td>0.036791</td>\n",
              "      <td>0.037755</td>\n",
              "      <td>0.036791</td>\n",
              "      <td>0.037755</td>\n",
              "      <td>...</td>\n",
              "      <td>2.728548</td>\n",
              "      <td>306.262089</td>\n",
              "      <td>4.474254</td>\n",
              "      <td>23.415452</td>\n",
              "      <td>4.106629</td>\n",
              "      <td>26.433950</td>\n",
              "      <td>209.303607</td>\n",
              "      <td>0.000572</td>\n",
              "      <td>0.049778</td>\n",
              "      <td>0.032966</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-02-07</th>\n",
              "      <td>0.046474</td>\n",
              "      <td>0.046474</td>\n",
              "      <td>0.046474</td>\n",
              "      <td>0.046474</td>\n",
              "      <td>28984.929215</td>\n",
              "      <td>3.413593e+09</td>\n",
              "      <td>0.046593</td>\n",
              "      <td>0.055072</td>\n",
              "      <td>0.046593</td>\n",
              "      <td>0.055072</td>\n",
              "      <td>...</td>\n",
              "      <td>2.733357</td>\n",
              "      <td>299.491542</td>\n",
              "      <td>4.460147</td>\n",
              "      <td>23.414391</td>\n",
              "      <td>4.140641</td>\n",
              "      <td>26.339020</td>\n",
              "      <td>209.303607</td>\n",
              "      <td>0.027307</td>\n",
              "      <td>0.065732</td>\n",
              "      <td>0.036397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-02-08</th>\n",
              "      <td>0.046711</td>\n",
              "      <td>0.046711</td>\n",
              "      <td>0.046711</td>\n",
              "      <td>0.046711</td>\n",
              "      <td>28984.929215</td>\n",
              "      <td>2.868803e+09</td>\n",
              "      <td>0.049131</td>\n",
              "      <td>0.041984</td>\n",
              "      <td>0.049131</td>\n",
              "      <td>0.041984</td>\n",
              "      <td>...</td>\n",
              "      <td>2.730104</td>\n",
              "      <td>301.761354</td>\n",
              "      <td>4.470789</td>\n",
              "      <td>23.415982</td>\n",
              "      <td>4.142338</td>\n",
              "      <td>26.135551</td>\n",
              "      <td>209.303607</td>\n",
              "      <td>0.010478</td>\n",
              "      <td>0.043373</td>\n",
              "      <td>0.037620</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-08-26</th>\n",
              "      <td>0.000121</td>\n",
              "      <td>0.000121</td>\n",
              "      <td>0.000121</td>\n",
              "      <td>0.000121</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.609587e+08</td>\n",
              "      <td>0.000120</td>\n",
              "      <td>-0.000665</td>\n",
              "      <td>0.000120</td>\n",
              "      <td>-0.000665</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.002546</td>\n",
              "      <td>0.509117</td>\n",
              "      <td>-0.003041</td>\n",
              "      <td>0.005162</td>\n",
              "      <td>0.001980</td>\n",
              "      <td>-0.105925</td>\n",
              "      <td>0.404061</td>\n",
              "      <td>0.008246</td>\n",
              "      <td>-0.004076</td>\n",
              "      <td>0.000040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-08-27</th>\n",
              "      <td>-0.004368</td>\n",
              "      <td>-0.004368</td>\n",
              "      <td>-0.004368</td>\n",
              "      <td>-0.004368</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9.767973e+07</td>\n",
              "      <td>-0.003889</td>\n",
              "      <td>-0.004798</td>\n",
              "      <td>-0.003889</td>\n",
              "      <td>-0.004798</td>\n",
              "      <td>...</td>\n",
              "      <td>0.002051</td>\n",
              "      <td>-0.551543</td>\n",
              "      <td>-0.001202</td>\n",
              "      <td>-0.006788</td>\n",
              "      <td>-0.001556</td>\n",
              "      <td>-0.173948</td>\n",
              "      <td>0.404061</td>\n",
              "      <td>0.009336</td>\n",
              "      <td>-0.005604</td>\n",
              "      <td>0.000047</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-08-28</th>\n",
              "      <td>0.000483</td>\n",
              "      <td>0.000483</td>\n",
              "      <td>0.000483</td>\n",
              "      <td>0.000483</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.498703e+08</td>\n",
              "      <td>0.000280</td>\n",
              "      <td>-0.001148</td>\n",
              "      <td>0.000280</td>\n",
              "      <td>-0.001148</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000849</td>\n",
              "      <td>0.247487</td>\n",
              "      <td>0.000849</td>\n",
              "      <td>0.002263</td>\n",
              "      <td>0.002051</td>\n",
              "      <td>-0.219910</td>\n",
              "      <td>0.707107</td>\n",
              "      <td>0.010307</td>\n",
              "      <td>-0.001642</td>\n",
              "      <td>0.000051</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-08-29</th>\n",
              "      <td>-0.000352</td>\n",
              "      <td>-0.000352</td>\n",
              "      <td>-0.000352</td>\n",
              "      <td>-0.000352</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.799304e+08</td>\n",
              "      <td>-0.000182</td>\n",
              "      <td>-0.000395</td>\n",
              "      <td>-0.000182</td>\n",
              "      <td>-0.000395</td>\n",
              "      <td>...</td>\n",
              "      <td>0.002333</td>\n",
              "      <td>-0.148492</td>\n",
              "      <td>0.002404</td>\n",
              "      <td>-0.000071</td>\n",
              "      <td>-0.000566</td>\n",
              "      <td>0.084711</td>\n",
              "      <td>-0.101015</td>\n",
              "      <td>0.005365</td>\n",
              "      <td>0.000277</td>\n",
              "      <td>0.000078</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-08-30</th>\n",
              "      <td>-0.000533</td>\n",
              "      <td>-0.000533</td>\n",
              "      <td>-0.000533</td>\n",
              "      <td>-0.000533</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-7.921081e+08</td>\n",
              "      <td>-0.000978</td>\n",
              "      <td>-0.000269</td>\n",
              "      <td>-0.000978</td>\n",
              "      <td>-0.000269</td>\n",
              "      <td>...</td>\n",
              "      <td>0.001838</td>\n",
              "      <td>-0.685894</td>\n",
              "      <td>0.003818</td>\n",
              "      <td>0.005091</td>\n",
              "      <td>-0.002333</td>\n",
              "      <td>0.092207</td>\n",
              "      <td>-0.101015</td>\n",
              "      <td>-0.007129</td>\n",
              "      <td>0.000044</td>\n",
              "      <td>0.000352</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6184 rows × 30 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-301ed6cb-e336-4acb-afb0-2f7c8b0215e3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-301ed6cb-e336-4acb-afb0-2f7c8b0215e3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-301ed6cb-e336-4acb-afb0-2f7c8b0215e3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0856f626-f2bf-4cc8-b6f6-d9cf58573e55\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0856f626-f2bf-4cc8-b6f6-d9cf58573e55')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0856f626-f2bf-4cc8-b6f6-d9cf58573e55 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "HV_data"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f31d2QX72Q-8"
      },
      "source": [
        "# Split train, validation and test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ZBlldE1h1rw"
      },
      "outputs": [],
      "source": [
        "def split_data(data, target, train_end =datetime(2022, 5, 30), test_start=datetime(2022, 5, 31), test_size=0.1):\n",
        "  test_data = data.loc[test_start:]\n",
        "\n",
        "  train_val = data.loc[:train_end]\n",
        "  train_data, val_data = train_test_split(train_val, test_size=test_size, shuffle=False)\n",
        "\n",
        "  return train_data, val_data, test_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x-xBiOOU2LEc"
      },
      "outputs": [],
      "source": [
        "def sliding_window_transform(X, y, timesteps):\n",
        "  X_windows = []\n",
        "  y_windows = []\n",
        "  for i in range(len(X) - timesteps + 1):\n",
        "    X_window = X[i:i + timesteps]\n",
        "    y_window = y[i + timesteps - 1]\n",
        "    X_windows.append(X_window)\n",
        "    y_windows.append(y_window)\n",
        "\n",
        "  return np.array(X_windows), np.array(y_windows)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H4oEdogIh6PT"
      },
      "outputs": [],
      "source": [
        "# Define the rolling window function\n",
        "def rolling_window(df, in_sample_window_size, out_of_sample_size):\n",
        "  X, y = [], []\n",
        "  for i in range(in_sample_window_size, len(df) - out_of_sample_size):\n",
        "    X.append(df.iloc[i - in_sample_window_size:i, :-1].values)  # All features except the target column\n",
        "    y.append(df.iloc[i:i + out_of_sample_size, -1].values)  # Target column\n",
        "\n",
        "  return np.array(X), np.array(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2Pa23Ux2Ynt"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "coiUqSlqjI50"
      },
      "outputs": [],
      "source": [
        "def calculate_mape(actual, predicted):\n",
        "  actual, predicted = np.array(actual), np.array(predicted)\n",
        "  return np.mean(np.abs((actual - predicted) / actual)) * 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Ak0aCvF2bqR"
      },
      "source": [
        "## GKYZV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Me1cu3q2LH6"
      },
      "outputs": [],
      "source": [
        "daily_train, daily_val, daily_test = split_data(HV_data, 'GKYZV')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wbIoahpP-zBI"
      },
      "outputs": [],
      "source": [
        "in_sam_win_sz = 25\n",
        "out_sam_win_sz = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hxzzyyCR-1_m"
      },
      "outputs": [],
      "source": [
        "HV_X_train, HV_y_train = rolling_window(daily_train, in_sam_win_sz, out_sam_win_sz)\n",
        "HV_X_val, HV_y_val = rolling_window(daily_val, in_sam_win_sz, out_sam_win_sz)\n",
        "HV_X_test, HV_y_test = rolling_window(daily_test, in_sam_win_sz, out_sam_win_sz)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ns46ckgGA42H"
      },
      "outputs": [],
      "source": [
        "# HV_X_train = HV_X_train.reshape(HV_X_train.shape[0], win_sz, -1)\n",
        "# HV_X_val = HV_X_val.reshape(HV_X_val.shape[0], win_sz, -1)\n",
        "# HV_X_test = HV_X_test.reshape(HV_X_test.shape[0], win_sz, -1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIQfC7oiLhnU"
      },
      "source": [
        "### LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zf6h10cy1zlx",
        "outputId": "f7531828-68ec-4770-9682-613badea3942"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ],
      "source": [
        "lstm_garch_model = Sequential()\n",
        "lstm_garch_model.add(LSTM(48, input_shape=(HV_X_train.shape[1], HV_X_train.shape[2]), return_sequences=True))\n",
        "lstm_garch_model.add(Dropout(0.1))\n",
        "lstm_garch_model.add(LSTM(16))\n",
        "lstm_garch_model.add(Dropout(0.1))\n",
        "lstm_garch_model.add(Dense(5))\n",
        "\n",
        "lstm_garch_model.compile(optimizer=Adam(learning_rate=0.01), loss='mse')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "Zpm8uSZJ3ESB",
        "outputId": "75a68149-414f-49a1-973c-d723acd64eac"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m48\u001b[0m)              │          \u001b[38;5;34m14,976\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m48\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │           \u001b[38;5;34m4,160\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │              \u001b[38;5;34m85\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">14,976</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">85</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m19,221\u001b[0m (75.08 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,221</span> (75.08 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m19,221\u001b[0m (75.08 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,221</span> (75.08 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "lstm_garch_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FcrtK-L3NgU",
        "outputId": "54ae2750-ac24-4555-acbb-4ebe97125b35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - loss: 0.0122 - val_loss: 1.6761e-05\n",
            "Epoch 2/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - loss: 1.9743e-04 - val_loss: 4.8173e-06\n",
            "Epoch 3/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 9.5322e-05 - val_loss: 4.5335e-06\n",
            "Epoch 4/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 7.1378e-05 - val_loss: 2.8488e-06\n",
            "Epoch 5/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - loss: 5.5747e-05 - val_loss: 2.6069e-06\n",
            "Epoch 6/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - loss: 5.2924e-05 - val_loss: 3.0129e-06\n",
            "Epoch 7/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 4.0556e-05 - val_loss: 1.1291e-05\n",
            "Epoch 8/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - loss: 4.9074e-05 - val_loss: 1.7602e-06\n",
            "Epoch 9/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - loss: 4.4191e-05 - val_loss: 2.2289e-06\n",
            "Epoch 10/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - loss: 3.4060e-05 - val_loss: 2.4687e-06\n",
            "Epoch 11/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 3.8776e-05 - val_loss: 3.8001e-06\n",
            "Epoch 12/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 28ms/step - loss: 3.6450e-05 - val_loss: 3.4904e-06\n",
            "Epoch 13/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 4.2740e-05 - val_loss: 2.7529e-06\n",
            "Epoch 14/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - loss: 4.4671e-05 - val_loss: 2.0700e-06\n",
            "Epoch 15/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - loss: 3.5722e-05 - val_loss: 6.3029e-06\n",
            "Epoch 16/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - loss: 3.4667e-05 - val_loss: 9.9093e-05\n",
            "Epoch 17/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 9.5612e-05 - val_loss: 8.3718e-06\n",
            "Epoch 18/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 3.7994e-05 - val_loss: 3.3811e-06\n",
            "Epoch 19/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - loss: 3.5399e-05 - val_loss: 2.2248e-06\n",
            "Epoch 20/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - loss: 3.6272e-05 - val_loss: 4.3033e-06\n",
            "Epoch 21/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 2.4823e-05 - val_loss: 9.6028e-06\n",
            "Epoch 22/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - loss: 3.6738e-05 - val_loss: 2.0403e-06\n",
            "Epoch 23/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - loss: 3.4417e-05 - val_loss: 4.3015e-06\n",
            "Epoch 24/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - loss: 3.3743e-05 - val_loss: 6.6326e-06\n",
            "Epoch 25/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - loss: 3.1430e-05 - val_loss: 5.2274e-06\n",
            "Epoch 26/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - loss: 4.0067e-05 - val_loss: 2.3436e-06\n",
            "Epoch 27/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - loss: 3.0381e-05 - val_loss: 2.4316e-06\n",
            "Epoch 28/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 3.2039e-05 - val_loss: 3.5262e-06\n",
            "Epoch 29/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 33ms/step - loss: 3.5692e-05 - val_loss: 1.8909e-06\n",
            "Epoch 30/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 21ms/step - loss: 3.9681e-05 - val_loss: 1.9289e-06\n",
            "Epoch 31/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 35ms/step - loss: 3.2140e-05 - val_loss: 2.7500e-06\n",
            "Epoch 32/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 21ms/step - loss: 2.9863e-05 - val_loss: 6.1329e-06\n",
            "Epoch 33/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 3.3050e-05 - val_loss: 2.3552e-06\n",
            "Epoch 34/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - loss: 3.5493e-05 - val_loss: 3.5229e-06\n",
            "Epoch 35/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - loss: 2.7834e-05 - val_loss: 7.1189e-06\n",
            "Epoch 36/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - loss: 3.2172e-05 - val_loss: 3.0758e-06\n",
            "Epoch 37/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 34ms/step - loss: 3.2955e-05 - val_loss: 1.4632e-06\n",
            "Epoch 38/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 3.3150e-05 - val_loss: 4.3173e-06\n",
            "Epoch 39/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - loss: 3.3394e-05 - val_loss: 8.8722e-07\n",
            "Epoch 40/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - loss: 2.7886e-05 - val_loss: 1.0880e-05\n",
            "Epoch 41/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 3.1710e-05 - val_loss: 2.5497e-06\n",
            "Epoch 42/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 3.2427e-05 - val_loss: 4.3844e-06\n",
            "Epoch 43/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 28ms/step - loss: 3.6674e-05 - val_loss: 1.9929e-05\n",
            "Epoch 44/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - loss: 3.4629e-05 - val_loss: 1.2729e-04\n",
            "Epoch 45/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 9.4818e-05 - val_loss: 3.7892e-06\n",
            "Epoch 46/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 48ms/step - loss: 2.7714e-05 - val_loss: 7.4650e-06\n",
            "Epoch 47/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 21ms/step - loss: 3.7332e-05 - val_loss: 1.4404e-06\n",
            "Epoch 48/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 2.6367e-05 - val_loss: 3.4032e-06\n",
            "Epoch 49/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - loss: 2.9160e-05 - val_loss: 4.3119e-06\n",
            "Epoch 50/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 21ms/step - loss: 2.6558e-05 - val_loss: 3.3115e-06\n",
            "Epoch 51/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 27ms/step - loss: 3.2832e-05 - val_loss: 5.4193e-06\n",
            "Epoch 52/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - loss: 3.5104e-05 - val_loss: 1.6343e-06\n",
            "Epoch 53/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 2.7514e-05 - val_loss: 2.8496e-06\n",
            "Epoch 54/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - loss: 3.3099e-05 - val_loss: 2.3916e-06\n",
            "Epoch 55/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - loss: 2.8377e-05 - val_loss: 1.4450e-06\n",
            "Epoch 56/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - loss: 2.9513e-05 - val_loss: 1.9101e-06\n",
            "Epoch 57/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - loss: 3.2771e-05 - val_loss: 7.0772e-07\n",
            "Epoch 58/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - loss: 3.2840e-05 - val_loss: 3.9143e-07\n",
            "Epoch 59/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 3.3914e-05 - val_loss: 7.2516e-05\n",
            "Epoch 60/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 5.4331e-05 - val_loss: 5.5472e-06\n",
            "Epoch 61/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - loss: 3.1809e-05 - val_loss: 1.1473e-06\n",
            "Epoch 62/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 2.9227e-05 - val_loss: 2.5089e-06\n",
            "Epoch 63/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 3.1760e-05 - val_loss: 5.2536e-06\n",
            "Epoch 64/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 3.2278e-05 - val_loss: 3.8766e-06\n",
            "Epoch 65/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - loss: 3.2030e-05 - val_loss: 6.6658e-06\n",
            "Epoch 66/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 3.1682e-05 - val_loss: 3.7257e-06\n",
            "Epoch 67/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - loss: 3.7600e-05 - val_loss: 3.1785e-06\n",
            "Epoch 68/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 31ms/step - loss: 2.6722e-05 - val_loss: 1.5227e-06\n",
            "Epoch 69/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - loss: 3.3584e-05 - val_loss: 2.2099e-06\n",
            "Epoch 70/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 3.1628e-05 - val_loss: 1.2067e-05\n",
            "Epoch 71/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - loss: 4.1747e-05 - val_loss: 7.0948e-07\n",
            "Epoch 72/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - loss: 2.9548e-05 - val_loss: 7.7974e-06\n",
            "Epoch 73/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 3.3706e-05 - val_loss: 4.4217e-06\n",
            "Epoch 74/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - loss: 3.2465e-05 - val_loss: 4.0551e-06\n",
            "Epoch 75/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - loss: 3.5625e-05 - val_loss: 1.9202e-06\n",
            "Epoch 76/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 21ms/step - loss: 2.7802e-05 - val_loss: 6.1683e-06\n",
            "Epoch 77/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 3.0664e-05 - val_loss: 8.9465e-07\n",
            "Epoch 78/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - loss: 3.2809e-05 - val_loss: 4.8883e-06\n",
            "Epoch 79/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 3.9064e-05 - val_loss: 1.2101e-06\n",
            "Epoch 80/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - loss: 3.2809e-05 - val_loss: 3.9908e-06\n"
          ]
        }
      ],
      "source": [
        "lstm_history = lstm_garch_model.fit(HV_X_train, HV_y_train, epochs=80, batch_size=32, validation_data=(HV_X_val, HV_y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A-zmdwqm_6_e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "206c863e-04fb-423d-da2f-718863a7c476"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step\n"
          ]
        }
      ],
      "source": [
        "# Predictions\n",
        "HV_test_predictions = lstm_garch_model.predict(HV_X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y8BUSWddHo1Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ac3e1d2-30df-4a71-ac63-3fd950ea84dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 3.7799650945069476e-06\n",
            "RMSE: 0.0019442132327774512\n",
            "MAE: 0.001746345970562458\n",
            "MAPE: 9742.62088252184%\n"
          ]
        }
      ],
      "source": [
        "mse = mean_squared_error(HV_y_test, HV_test_predictions)\n",
        "print(f'MSE: {mse}')\n",
        "\n",
        "rmse = np.sqrt(mse)\n",
        "print(f'RMSE: {rmse}')\n",
        "\n",
        "mae = mean_absolute_error(HV_y_test, HV_test_predictions)\n",
        "print(f'MAE: {mae}')\n",
        "\n",
        "mape = calculate_mape(HV_y_test, HV_test_predictions)\n",
        "print(f'MAPE: {mape}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UiS7McIrLmEd"
      },
      "source": [
        "### GRU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2fd5ZZjRH2dD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff17af47-20de-4eb8-fdb3-7fa398f6c15c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ],
      "source": [
        "gru_model = Sequential()\n",
        "gru_model.add(GRU(48, input_shape=(HV_X_train.shape[1], HV_X_train.shape[2]), return_sequences=True))\n",
        "gru_model.add(Dropout(0.1))\n",
        "gru_model.add(GRU(16))\n",
        "gru_model.add(Dropout(0.1))\n",
        "gru_model.add(Dense(5))\n",
        "\n",
        "gru_model.compile(optimizer=Adam(learning_rate=0.01), loss='mse')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fi7nCfJRL0nz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "3798860d-e99c-4c6d-e84a-86a525decb23"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ gru (\u001b[38;5;33mGRU\u001b[0m)                            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m48\u001b[0m)              │          \u001b[38;5;34m11,376\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m48\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_1 (\u001b[38;5;33mGRU\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │           \u001b[38;5;34m3,168\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │              \u001b[38;5;34m85\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">11,376</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,168</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">85</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m14,629\u001b[0m (57.14 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,629</span> (57.14 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m14,629\u001b[0m (57.14 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,629</span> (57.14 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "gru_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAo9MoSmNg_1",
        "outputId": "283116cf-41f4-4aeb-9b34-fb46fc174849"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - loss: 0.0663 - val_loss: 1.5038e-04\n",
            "Epoch 2/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - loss: 4.3310e-04 - val_loss: 3.2675e-05\n",
            "Epoch 3/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - loss: 1.6952e-04 - val_loss: 1.9553e-05\n",
            "Epoch 4/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - loss: 1.1767e-04 - val_loss: 1.2643e-05\n",
            "Epoch 5/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - loss: 7.9293e-05 - val_loss: 8.1973e-06\n",
            "Epoch 6/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 28ms/step - loss: 6.7210e-05 - val_loss: 7.1869e-06\n",
            "Epoch 7/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - loss: 6.2383e-05 - val_loss: 5.8415e-06\n",
            "Epoch 8/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - loss: 6.0973e-05 - val_loss: 3.8962e-06\n",
            "Epoch 9/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - loss: 5.6517e-05 - val_loss: 4.2629e-06\n",
            "Epoch 10/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - loss: 4.3716e-05 - val_loss: 3.1495e-06\n",
            "Epoch 11/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 38ms/step - loss: 4.3486e-05 - val_loss: 2.5925e-06\n",
            "Epoch 12/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - loss: 5.0463e-05 - val_loss: 3.1225e-06\n",
            "Epoch 13/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - loss: 5.3894e-05 - val_loss: 4.0808e-06\n",
            "Epoch 14/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - loss: 4.1069e-05 - val_loss: 2.4726e-06\n",
            "Epoch 15/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - loss: 4.4360e-05 - val_loss: 1.8794e-06\n",
            "Epoch 16/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - loss: 3.7812e-05 - val_loss: 1.9136e-06\n",
            "Epoch 17/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 28ms/step - loss: 3.8435e-05 - val_loss: 7.7071e-06\n",
            "Epoch 18/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - loss: 4.4633e-05 - val_loss: 4.0885e-06\n",
            "Epoch 19/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 3.7181e-05 - val_loss: 2.7138e-06\n",
            "Epoch 20/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 40ms/step - loss: 4.1372e-05 - val_loss: 4.1283e-06\n",
            "Epoch 21/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - loss: 3.8182e-05 - val_loss: 1.2935e-06\n",
            "Epoch 22/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - loss: 3.8810e-05 - val_loss: 1.8037e-06\n",
            "Epoch 23/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 38ms/step - loss: 4.3582e-05 - val_loss: 1.5754e-06\n",
            "Epoch 24/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - loss: 4.0216e-05 - val_loss: 1.3235e-06\n",
            "Epoch 25/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 38ms/step - loss: 3.4924e-05 - val_loss: 1.1787e-06\n",
            "Epoch 26/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - loss: 3.1325e-05 - val_loss: 2.0635e-06\n",
            "Epoch 27/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - loss: 3.9471e-05 - val_loss: 1.2962e-06\n",
            "Epoch 28/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - loss: 3.7479e-05 - val_loss: 1.7988e-06\n",
            "Epoch 29/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - loss: 3.5622e-05 - val_loss: 3.5366e-06\n",
            "Epoch 30/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - loss: 3.7270e-05 - val_loss: 1.8256e-06\n",
            "Epoch 31/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - loss: 3.0734e-05 - val_loss: 1.9348e-06\n",
            "Epoch 32/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - loss: 3.2913e-05 - val_loss: 1.0689e-05\n",
            "Epoch 33/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - loss: 3.7125e-05 - val_loss: 3.0938e-06\n",
            "Epoch 34/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - loss: 3.2790e-05 - val_loss: 2.1897e-06\n",
            "Epoch 35/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 3.7197e-05 - val_loss: 1.5690e-06\n",
            "Epoch 36/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - loss: 3.6158e-05 - val_loss: 2.6125e-06\n",
            "Epoch 37/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 3.7599e-05 - val_loss: 8.6646e-06\n",
            "Epoch 38/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - loss: 3.5757e-05 - val_loss: 1.7757e-06\n",
            "Epoch 39/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - loss: 4.0312e-05 - val_loss: 5.4558e-06\n",
            "Epoch 40/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - loss: 3.6512e-05 - val_loss: 3.7104e-05\n",
            "Epoch 41/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - loss: 5.5179e-05 - val_loss: 1.8071e-06\n",
            "Epoch 42/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - loss: 2.8765e-05 - val_loss: 3.7788e-06\n",
            "Epoch 43/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 39ms/step - loss: 3.7526e-05 - val_loss: 5.2741e-06\n",
            "Epoch 44/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - loss: 3.6255e-05 - val_loss: 5.6393e-06\n",
            "Epoch 45/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - loss: 3.3192e-05 - val_loss: 9.1516e-05\n",
            "Epoch 46/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 9.0791e-05 - val_loss: 4.6741e-06\n",
            "Epoch 47/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 38ms/step - loss: 4.5758e-05 - val_loss: 3.6396e-06\n",
            "Epoch 48/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - loss: 3.1961e-05 - val_loss: 6.2871e-06\n",
            "Epoch 49/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 28ms/step - loss: 3.5437e-05 - val_loss: 1.3293e-06\n",
            "Epoch 50/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 3.4419e-05 - val_loss: 1.4874e-06\n",
            "Epoch 51/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - loss: 4.8491e-05 - val_loss: 2.1574e-05\n",
            "Epoch 52/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 37ms/step - loss: 5.2696e-05 - val_loss: 3.4269e-06\n",
            "Epoch 53/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 3.0210e-05 - val_loss: 1.8289e-06\n",
            "Epoch 54/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 38ms/step - loss: 4.0362e-05 - val_loss: 5.8614e-06\n",
            "Epoch 55/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - loss: 3.6026e-05 - val_loss: 3.2309e-06\n",
            "Epoch 56/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 37ms/step - loss: 2.9970e-05 - val_loss: 5.8438e-06\n",
            "Epoch 57/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 28ms/step - loss: 3.4307e-05 - val_loss: 3.4705e-06\n",
            "Epoch 58/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - loss: 3.5262e-05 - val_loss: 8.3484e-06\n",
            "Epoch 59/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 37ms/step - loss: 3.2199e-05 - val_loss: 5.4838e-06\n",
            "Epoch 60/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - loss: 3.9618e-05 - val_loss: 2.0348e-05\n",
            "Epoch 61/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 2.8814e-05 - val_loss: 4.2660e-06\n",
            "Epoch 62/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 33ms/step - loss: 2.8183e-05 - val_loss: 1.2411e-05\n",
            "Epoch 63/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 43ms/step - loss: 4.5745e-05 - val_loss: 1.5144e-05\n",
            "Epoch 64/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - loss: 3.3176e-05 - val_loss: 1.5540e-06\n",
            "Epoch 65/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - loss: 3.6602e-05 - val_loss: 4.1462e-06\n",
            "Epoch 66/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 37ms/step - loss: 3.5703e-05 - val_loss: 4.2373e-06\n",
            "Epoch 67/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - loss: 3.1071e-05 - val_loss: 4.6011e-06\n",
            "Epoch 68/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 28ms/step - loss: 3.1082e-05 - val_loss: 3.9696e-06\n",
            "Epoch 69/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 37ms/step - loss: 3.3115e-05 - val_loss: 6.1922e-06\n",
            "Epoch 70/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 28ms/step - loss: 4.3451e-05 - val_loss: 2.3954e-06\n",
            "Epoch 71/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - loss: 3.2751e-05 - val_loss: 5.4300e-06\n",
            "Epoch 72/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - loss: 3.1713e-05 - val_loss: 8.6208e-06\n",
            "Epoch 73/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - loss: 3.0778e-05 - val_loss: 4.5228e-06\n",
            "Epoch 74/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 37ms/step - loss: 2.9054e-05 - val_loss: 8.1833e-05\n",
            "Epoch 75/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - loss: 6.4471e-05 - val_loss: 7.9494e-06\n",
            "Epoch 76/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - loss: 4.3158e-05 - val_loss: 1.1809e-05\n",
            "Epoch 77/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - loss: 3.7983e-05 - val_loss: 1.9075e-06\n",
            "Epoch 78/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 28ms/step - loss: 3.7231e-05 - val_loss: 4.6554e-05\n",
            "Epoch 79/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - loss: 6.5705e-05 - val_loss: 1.5619e-06\n",
            "Epoch 80/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - loss: 4.2485e-05 - val_loss: 1.3333e-06\n"
          ]
        }
      ],
      "source": [
        "gru_history = gru_model.fit(HV_X_train, HV_y_train, epochs=80, batch_size=32, validation_data=(HV_X_val, HV_y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jed591XqNhSM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03e009b5-def7-4968-fc3a-8c764757cce4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step\n"
          ]
        }
      ],
      "source": [
        "# Predictions\n",
        "HV_gru_predictions = gru_model.predict(HV_X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WeZeC001NhcB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23d3cdeb-62c0-4ec9-a08b-c52956bc910a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 1.3310688057251731e-06\n",
            "RMSE: 0.001153719552458557\n",
            "MAE: 0.0008985396597258968\n",
            "MAPE: 4684.324433871822%\n"
          ]
        }
      ],
      "source": [
        "mse = mean_squared_error(HV_y_test, HV_gru_predictions)\n",
        "print(f'MSE: {mse}')\n",
        "\n",
        "rmse = np.sqrt(mse)\n",
        "print(f'RMSE: {rmse}')\n",
        "\n",
        "mae = mean_absolute_error(HV_y_test, HV_gru_predictions)\n",
        "print(f'MAE: {mae}')\n",
        "\n",
        "mape = calculate_mape(HV_y_test, HV_gru_predictions)\n",
        "print(f'MAPE: {mape}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1e3A5gvPzR6"
      },
      "source": [
        "### LSTM_GRU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M4sDHB06Nhfb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48da47d7-d2c7-4ca4-f1dc-cc35969a3737"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ],
      "source": [
        "lstm_gru_model = Sequential()\n",
        "lstm_gru_model.add(LSTM(48, input_shape=(HV_X_train.shape[1], HV_X_train.shape[2]), return_sequences=True))\n",
        "lstm_gru_model.add(Dropout(0.1))\n",
        "lstm_gru_model.add(GRU(16))\n",
        "lstm_gru_model.add(Dropout(0.1))\n",
        "lstm_gru_model.add(Dense(5))\n",
        "\n",
        "lstm_gru_model.compile(optimizer=Adam(learning_rate=0.01), loss='mse')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OihmLvRzQWlV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "c28e88f3-0b37-4214-cefb-2ea57cb22a49"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m48\u001b[0m)              │          \u001b[38;5;34m14,976\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m48\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_2 (\u001b[38;5;33mGRU\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │           \u001b[38;5;34m3,168\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │              \u001b[38;5;34m85\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">14,976</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,168</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">85</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m18,229\u001b[0m (71.21 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">18,229</span> (71.21 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m18,229\u001b[0m (71.21 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">18,229</span> (71.21 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "lstm_gru_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_6UxHjRWQWnn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3dd0a66-d92c-4d05-a05d-cf824e29f926"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 31ms/step - loss: 0.0136 - val_loss: 4.1639e-05\n",
            "Epoch 2/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 28ms/step - loss: 3.0020e-04 - val_loss: 1.4275e-05\n",
            "Epoch 3/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - loss: 1.4704e-04 - val_loss: 3.5828e-05\n",
            "Epoch 4/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - loss: 1.0734e-04 - val_loss: 7.9099e-06\n",
            "Epoch 5/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 7.0817e-05 - val_loss: 1.5164e-05\n",
            "Epoch 6/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 31ms/step - loss: 6.0907e-05 - val_loss: 4.6214e-06\n",
            "Epoch 7/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - loss: 5.3913e-05 - val_loss: 9.8891e-06\n",
            "Epoch 8/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 5.6886e-05 - val_loss: 2.1722e-05\n",
            "Epoch 9/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 5.4490e-05 - val_loss: 4.2369e-06\n",
            "Epoch 10/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - loss: 3.8098e-05 - val_loss: 3.6276e-06\n",
            "Epoch 11/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 4.2096e-05 - val_loss: 6.8559e-06\n",
            "Epoch 12/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 3.5752e-05 - val_loss: 3.9426e-06\n",
            "Epoch 13/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 33ms/step - loss: 3.6541e-05 - val_loss: 1.0112e-05\n",
            "Epoch 14/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 3.5846e-05 - val_loss: 4.4026e-06\n",
            "Epoch 15/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 4.0163e-05 - val_loss: 1.3470e-06\n",
            "Epoch 16/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 35ms/step - loss: 3.5197e-05 - val_loss: 2.5506e-06\n",
            "Epoch 17/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 3.2997e-05 - val_loss: 3.1230e-06\n",
            "Epoch 18/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - loss: 4.1767e-05 - val_loss: 4.9140e-06\n",
            "Epoch 19/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - loss: 3.1722e-05 - val_loss: 2.2258e-06\n",
            "Epoch 20/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 2.7735e-05 - val_loss: 3.6938e-06\n",
            "Epoch 21/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 3.3029e-05 - val_loss: 3.0091e-06\n",
            "Epoch 22/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - loss: 4.0688e-05 - val_loss: 2.3447e-06\n",
            "Epoch 23/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - loss: 3.1051e-05 - val_loss: 1.7667e-05\n",
            "Epoch 24/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 3.3003e-05 - val_loss: 4.4178e-05\n",
            "Epoch 25/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 4.6812e-05 - val_loss: 1.3215e-06\n",
            "Epoch 26/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 31ms/step - loss: 3.4271e-05 - val_loss: 1.5802e-06\n",
            "Epoch 27/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 2.6413e-05 - val_loss: 2.6789e-06\n",
            "Epoch 28/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 3.6296e-05 - val_loss: 1.0717e-06\n",
            "Epoch 29/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 37ms/step - loss: 2.9346e-05 - val_loss: 6.9024e-04\n",
            "Epoch 30/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - loss: 2.2185e-04 - val_loss: 2.4398e-06\n",
            "Epoch 31/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - loss: 3.2811e-05 - val_loss: 3.3960e-06\n",
            "Epoch 32/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - loss: 3.6882e-05 - val_loss: 2.3185e-06\n",
            "Epoch 33/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 3.0965e-05 - val_loss: 1.9117e-06\n",
            "Epoch 34/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 3.1318e-05 - val_loss: 2.7483e-06\n",
            "Epoch 35/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - loss: 2.8073e-05 - val_loss: 5.1978e-06\n",
            "Epoch 36/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 3.1572e-05 - val_loss: 4.6572e-06\n",
            "Epoch 37/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - loss: 3.4177e-05 - val_loss: 2.2402e-06\n",
            "Epoch 38/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 34ms/step - loss: 4.0456e-05 - val_loss: 2.6368e-05\n",
            "Epoch 39/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 30ms/step - loss: 3.9780e-05 - val_loss: 3.9335e-06\n",
            "Epoch 40/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 45ms/step - loss: 3.0442e-05 - val_loss: 6.2536e-06\n",
            "Epoch 41/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - loss: 3.4384e-05 - val_loss: 2.2259e-06\n",
            "Epoch 42/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 3.8578e-05 - val_loss: 4.0118e-06\n",
            "Epoch 43/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 31ms/step - loss: 2.8291e-05 - val_loss: 2.5166e-06\n",
            "Epoch 44/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 3.2304e-05 - val_loss: 2.2438e-06\n",
            "Epoch 45/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 27ms/step - loss: 3.2866e-05 - val_loss: 4.2253e-06\n",
            "Epoch 46/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - loss: 3.5076e-05 - val_loss: 2.8459e-05\n",
            "Epoch 47/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 3.3029e-05 - val_loss: 1.3606e-06\n",
            "Epoch 48/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - loss: 3.1408e-05 - val_loss: 2.6407e-06\n",
            "Epoch 49/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - loss: 3.4006e-05 - val_loss: 2.0376e-06\n",
            "Epoch 50/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 3.1592e-05 - val_loss: 3.5446e-05\n",
            "Epoch 51/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 5.5438e-05 - val_loss: 1.8273e-06\n",
            "Epoch 52/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 37ms/step - loss: 3.7681e-05 - val_loss: 4.3382e-06\n",
            "Epoch 53/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 2.4920e-05 - val_loss: 1.2361e-05\n",
            "Epoch 54/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 3.4934e-05 - val_loss: 1.1484e-06\n",
            "Epoch 55/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - loss: 3.4167e-05 - val_loss: 1.5008e-06\n",
            "Epoch 56/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - loss: 4.3649e-05 - val_loss: 6.3929e-06\n",
            "Epoch 57/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 2.8149e-05 - val_loss: 2.3728e-05\n",
            "Epoch 58/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 3.0528e-05 - val_loss: 2.0678e-06\n",
            "Epoch 59/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - loss: 3.0231e-05 - val_loss: 2.8252e-06\n",
            "Epoch 60/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 3.5901e-05 - val_loss: 4.2450e-06\n",
            "Epoch 61/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - loss: 4.2750e-05 - val_loss: 4.9500e-06\n",
            "Epoch 62/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - loss: 3.2341e-05 - val_loss: 2.2793e-06\n",
            "Epoch 63/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - loss: 2.7749e-05 - val_loss: 2.5435e-06\n",
            "Epoch 64/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - loss: 3.0056e-05 - val_loss: 2.3190e-06\n",
            "Epoch 65/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 3.0571e-05 - val_loss: 1.0578e-05\n",
            "Epoch 66/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 3.1684e-05 - val_loss: 2.8242e-06\n",
            "Epoch 67/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - loss: 3.7560e-05 - val_loss: 9.7644e-06\n",
            "Epoch 68/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - loss: 2.9692e-05 - val_loss: 3.8070e-05\n",
            "Epoch 69/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 5.9507e-05 - val_loss: 3.1529e-06\n",
            "Epoch 70/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 2.7849e-05 - val_loss: 2.0729e-06\n",
            "Epoch 71/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - loss: 3.4615e-05 - val_loss: 2.7848e-06\n",
            "Epoch 72/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - loss: 4.2287e-05 - val_loss: 1.8710e-06\n",
            "Epoch 73/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - loss: 3.1830e-05 - val_loss: 1.4068e-05\n",
            "Epoch 74/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - loss: 3.9892e-05 - val_loss: 1.2572e-06\n",
            "Epoch 75/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 2.8022e-05 - val_loss: 1.9139e-06\n",
            "Epoch 76/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 2.9487e-05 - val_loss: 2.5734e-06\n",
            "Epoch 77/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 31ms/step - loss: 3.1293e-05 - val_loss: 5.4920e-06\n",
            "Epoch 78/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 3.1556e-05 - val_loss: 7.3727e-05\n",
            "Epoch 79/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 5.9914e-05 - val_loss: 2.3635e-06\n",
            "Epoch 80/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 37ms/step - loss: 2.6361e-05 - val_loss: 2.7196e-06\n"
          ]
        }
      ],
      "source": [
        "lstm_gru_history = lstm_gru_model.fit(HV_X_train, HV_y_train, epochs=80, batch_size=32, validation_data=(HV_X_val, HV_y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HQLIfgQ5QWsf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db6a20b4-3a1c-4f44-f5a1-94ffdefed13c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step\n"
          ]
        }
      ],
      "source": [
        "# Predictions\n",
        "HV_lstm_gru_predictions = lstm_gru_model.predict(HV_X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ieo5NKO1QWvw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96da8775-ffee-4cb6-bbda-86db3bd906c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 2.7903487091519282e-06\n",
            "RMSE: 0.0016704336889418652\n",
            "MAE: 0.0015434081722152501\n",
            "MAPE: 8678.848685315423%\n"
          ]
        }
      ],
      "source": [
        "mse = mean_squared_error(HV_y_test, HV_lstm_gru_predictions)\n",
        "print(f'MSE: {mse}')\n",
        "\n",
        "rmse = np.sqrt(mse)\n",
        "print(f'RMSE: {rmse}')\n",
        "\n",
        "mae = mean_absolute_error(HV_y_test, HV_lstm_gru_predictions)\n",
        "print(f'MAE: {mae}')\n",
        "\n",
        "mape = calculate_mape(HV_y_test, HV_lstm_gru_predictions)\n",
        "print(f'MAPE: {mape}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgH4xoeTU2xa"
      },
      "source": [
        "### BiLSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OWUQwJo7QWyz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "129949c7-cce4-4755-e1db-8c7b7b8179eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ],
      "source": [
        "bilstm_model = Sequential()\n",
        "bilstm_model.add(Bidirectional(LSTM(48, return_sequences=True), input_shape=(HV_X_train.shape[1], HV_X_train.shape[2])))\n",
        "bilstm_model.add(Dropout(0.1))\n",
        "bilstm_model.add(Bidirectional(LSTM(16)))\n",
        "bilstm_model.add(Dropout(0.1))\n",
        "bilstm_model.add(Dense(5))\n",
        "\n",
        "bilstm_model.compile(optimizer=Adam(learning_rate=0.01), loss='mse')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HnknoIEUcfdt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "066e2918-85db-44e5-9008-e1d12ef31789"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m96\u001b[0m)              │          \u001b[38;5;34m29,952\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m96\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │          \u001b[38;5;34m14,464\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │             \u001b[38;5;34m165\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">29,952</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">14,464</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">165</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m44,581\u001b[0m (174.14 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">44,581</span> (174.14 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m44,581\u001b[0m (174.14 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">44,581</span> (174.14 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "bilstm_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4bc45pjEatbC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6acae62-0fb0-4a9f-e3a5-3392bec58cd6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 44ms/step - loss: 0.0171 - val_loss: 1.3172e-05\n",
            "Epoch 2/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 54ms/step - loss: 1.1868e-04 - val_loss: 6.6702e-06\n",
            "Epoch 3/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 37ms/step - loss: 7.2998e-05 - val_loss: 5.4763e-06\n",
            "Epoch 4/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 37ms/step - loss: 6.3550e-05 - val_loss: 4.2519e-06\n",
            "Epoch 5/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 46ms/step - loss: 4.7881e-05 - val_loss: 6.0648e-06\n",
            "Epoch 6/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 58ms/step - loss: 4.3888e-05 - val_loss: 3.3167e-06\n",
            "Epoch 7/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 5.1738e-05 - val_loss: 2.0216e-06\n",
            "Epoch 8/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 53ms/step - loss: 3.8289e-05 - val_loss: 4.2976e-06\n",
            "Epoch 9/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 37ms/step - loss: 3.8243e-05 - val_loss: 2.7338e-06\n",
            "Epoch 10/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 53ms/step - loss: 3.3132e-05 - val_loss: 4.0585e-06\n",
            "Epoch 11/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - loss: 4.0345e-05 - val_loss: 1.6895e-06\n",
            "Epoch 12/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 49ms/step - loss: 3.6858e-05 - val_loss: 2.3081e-06\n",
            "Epoch 13/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 48ms/step - loss: 3.7526e-05 - val_loss: 2.6936e-06\n",
            "Epoch 14/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 37ms/step - loss: 3.0019e-05 - val_loss: 2.2961e-06\n",
            "Epoch 15/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 54ms/step - loss: 3.1128e-05 - val_loss: 3.4932e-06\n",
            "Epoch 16/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 37ms/step - loss: 3.5354e-05 - val_loss: 1.8207e-06\n",
            "Epoch 17/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 49ms/step - loss: 3.1904e-05 - val_loss: 1.0130e-05\n",
            "Epoch 18/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 45ms/step - loss: 4.1870e-05 - val_loss: 2.2352e-06\n",
            "Epoch 19/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 3.7855e-05 - val_loss: 1.6327e-06\n",
            "Epoch 20/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 54ms/step - loss: 3.5354e-05 - val_loss: 6.1500e-07\n",
            "Epoch 21/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 38ms/step - loss: 3.6608e-05 - val_loss: 1.2526e-06\n",
            "Epoch 22/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 37ms/step - loss: 2.9281e-05 - val_loss: 6.6012e-07\n",
            "Epoch 23/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 50ms/step - loss: 3.6626e-05 - val_loss: 1.1354e-06\n",
            "Epoch 24/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 45ms/step - loss: 3.0122e-05 - val_loss: 6.6960e-06\n",
            "Epoch 25/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 38ms/step - loss: 3.0083e-05 - val_loss: 4.0481e-06\n",
            "Epoch 26/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - loss: 3.0165e-05 - val_loss: 5.1971e-07\n",
            "Epoch 27/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 2.7229e-05 - val_loss: 3.0376e-06\n",
            "Epoch 28/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 37ms/step - loss: 3.3315e-05 - val_loss: 2.3338e-06\n",
            "Epoch 29/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 3.5928e-05 - val_loss: 1.3483e-06\n",
            "Epoch 30/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 40ms/step - loss: 3.0722e-05 - val_loss: 1.2039e-06\n",
            "Epoch 31/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - loss: 3.0488e-05 - val_loss: 1.5397e-06\n",
            "Epoch 32/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 44ms/step - loss: 2.8002e-05 - val_loss: 2.1819e-05\n",
            "Epoch 33/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 55ms/step - loss: 2.9579e-05 - val_loss: 1.0602e-05\n",
            "Epoch 34/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 37ms/step - loss: 3.6513e-05 - val_loss: 4.2991e-06\n",
            "Epoch 35/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 61ms/step - loss: 3.2899e-05 - val_loss: 4.8810e-07\n",
            "Epoch 36/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 51ms/step - loss: 2.9227e-05 - val_loss: 6.2435e-06\n",
            "Epoch 37/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 38ms/step - loss: 3.4829e-05 - val_loss: 8.2938e-06\n",
            "Epoch 38/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 55ms/step - loss: 3.9426e-05 - val_loss: 2.1614e-06\n",
            "Epoch 39/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 38ms/step - loss: 3.1964e-05 - val_loss: 8.2354e-07\n",
            "Epoch 40/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 55ms/step - loss: 3.5769e-05 - val_loss: 1.4534e-06\n",
            "Epoch 41/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 37ms/step - loss: 3.0952e-05 - val_loss: 6.9378e-07\n",
            "Epoch 42/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 54ms/step - loss: 3.2803e-05 - val_loss: 4.0433e-06\n",
            "Epoch 43/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 37ms/step - loss: 3.5498e-05 - val_loss: 1.2022e-05\n",
            "Epoch 44/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 47ms/step - loss: 3.5135e-05 - val_loss: 1.6073e-05\n",
            "Epoch 45/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - loss: 3.2245e-05 - val_loss: 3.2135e-07\n",
            "Epoch 46/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - loss: 3.2234e-05 - val_loss: 1.3288e-05\n",
            "Epoch 47/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 55ms/step - loss: 3.3017e-05 - val_loss: 1.0108e-06\n",
            "Epoch 48/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - loss: 3.2984e-05 - val_loss: 1.5485e-06\n",
            "Epoch 49/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 52ms/step - loss: 3.0131e-05 - val_loss: 1.4447e-06\n",
            "Epoch 50/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 45ms/step - loss: 2.9282e-05 - val_loss: 7.1376e-07\n",
            "Epoch 51/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 47ms/step - loss: 3.2873e-05 - val_loss: 1.0569e-06\n",
            "Epoch 52/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 52ms/step - loss: 2.7388e-05 - val_loss: 5.0862e-07\n",
            "Epoch 53/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 38ms/step - loss: 2.8687e-05 - val_loss: 2.7645e-06\n",
            "Epoch 54/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 45ms/step - loss: 3.1808e-05 - val_loss: 4.2405e-06\n",
            "Epoch 55/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 40ms/step - loss: 2.7560e-05 - val_loss: 1.6556e-05\n",
            "Epoch 56/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 37ms/step - loss: 3.7433e-05 - val_loss: 1.8646e-06\n",
            "Epoch 57/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 54ms/step - loss: 3.2983e-05 - val_loss: 5.8726e-06\n",
            "Epoch 58/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 38ms/step - loss: 2.9713e-05 - val_loss: 1.3129e-06\n",
            "Epoch 59/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - loss: 2.9372e-05 - val_loss: 2.0318e-06\n",
            "Epoch 60/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 55ms/step - loss: 3.2209e-05 - val_loss: 9.5802e-06\n",
            "Epoch 61/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 38ms/step - loss: 3.0304e-05 - val_loss: 5.9980e-05\n",
            "Epoch 62/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 53ms/step - loss: 4.4985e-05 - val_loss: 1.3013e-04\n",
            "Epoch 63/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 38ms/step - loss: 1.0603e-04 - val_loss: 3.2241e-06\n",
            "Epoch 64/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - loss: 2.7287e-05 - val_loss: 2.4162e-06\n",
            "Epoch 65/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 50ms/step - loss: 3.0619e-05 - val_loss: 1.8248e-06\n",
            "Epoch 66/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 60ms/step - loss: 3.2497e-05 - val_loss: 5.2597e-05\n",
            "Epoch 67/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - loss: 4.6179e-05 - val_loss: 2.6767e-06\n",
            "Epoch 68/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 53ms/step - loss: 3.4028e-05 - val_loss: 1.2267e-06\n",
            "Epoch 69/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 37ms/step - loss: 2.9448e-05 - val_loss: 1.4507e-06\n",
            "Epoch 70/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 50ms/step - loss: 3.7266e-05 - val_loss: 6.1998e-06\n",
            "Epoch 71/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 38ms/step - loss: 2.7442e-05 - val_loss: 2.4792e-06\n",
            "Epoch 72/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 44ms/step - loss: 3.7557e-05 - val_loss: 1.2403e-06\n",
            "Epoch 73/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 41ms/step - loss: 3.3365e-05 - val_loss: 1.3203e-06\n",
            "Epoch 74/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 49ms/step - loss: 2.7055e-05 - val_loss: 3.4254e-06\n",
            "Epoch 75/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 49ms/step - loss: 2.9395e-05 - val_loss: 6.5354e-07\n",
            "Epoch 76/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 38ms/step - loss: 2.9533e-05 - val_loss: 1.2304e-05\n",
            "Epoch 77/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 46ms/step - loss: 2.9789e-05 - val_loss: 3.0716e-06\n",
            "Epoch 78/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 43ms/step - loss: 3.0456e-05 - val_loss: 2.6273e-06\n",
            "Epoch 79/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 38ms/step - loss: 3.1089e-05 - val_loss: 5.3452e-06\n",
            "Epoch 80/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 47ms/step - loss: 4.3421e-05 - val_loss: 7.2712e-06\n"
          ]
        }
      ],
      "source": [
        "bilstm_history = bilstm_model.fit(HV_X_train, HV_y_train, epochs=80, batch_size=32, validation_data=(HV_X_val, HV_y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tSQQeKmCatdG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8e3a19f-928e-4938-ba58-f7c3cf1e5623"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step\n"
          ]
        }
      ],
      "source": [
        "# Predictions\n",
        "HV_bilstm_predictions = bilstm_model.predict(HV_X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GQwOXFU3atgm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "504d01ca-a0b3-48da-ccaf-d86b409198a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 7.287767828248347e-06\n",
            "RMSE: 0.00269958660321323\n",
            "MAE: 0.0023142297591945663\n",
            "MAPE: 12331.246729154558%\n"
          ]
        }
      ],
      "source": [
        "mse = mean_squared_error(HV_y_test, HV_bilstm_predictions)\n",
        "print(f'MSE: {mse}')\n",
        "\n",
        "rmse = np.sqrt(mse)\n",
        "print(f'RMSE: {rmse}')\n",
        "\n",
        "mae = mean_absolute_error(HV_y_test, HV_bilstm_predictions)\n",
        "print(f'MAE: {mae}')\n",
        "\n",
        "mape = calculate_mape(HV_y_test, HV_bilstm_predictions)\n",
        "print(f'MAPE: {mape}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4HabdZkeZeL"
      },
      "source": [
        "### BiLSTM_GRU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "39zUotTIc80l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6e25a1d-636f-46c9-b435-a889c38cae55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ],
      "source": [
        "bilstm_gru_model = Sequential()\n",
        "bilstm_gru_model.add(Bidirectional(LSTM(48, return_sequences=True), input_shape=(HV_X_train.shape[1], HV_X_train.shape[2])))\n",
        "bilstm_gru_model.add(Dropout(0.1))\n",
        "bilstm_gru_model.add(GRU(16))\n",
        "bilstm_gru_model.add(Dropout(0.1))\n",
        "bilstm_gru_model.add(Dense(5))\n",
        "\n",
        "bilstm_gru_model.compile(optimizer=Adam(learning_rate=0.01), loss='mse')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ueo7IuG1eqcL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "4f55ae8d-c6a7-4d84-e7de-2e4eb3f6612e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m96\u001b[0m)              │          \u001b[38;5;34m29,952\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m96\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_3 (\u001b[38;5;33mGRU\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │           \u001b[38;5;34m5,472\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │              \u001b[38;5;34m85\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">29,952</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">5,472</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">85</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m35,509\u001b[0m (138.71 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">35,509</span> (138.71 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m35,509\u001b[0m (138.71 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">35,509</span> (138.71 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "bilstm_gru_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UrcF0MvXeqeh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "034298dc-2005-44f3-bbf0-9b96dbda67a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 45ms/step - loss: 0.0443 - val_loss: 1.3803e-04\n",
            "Epoch 2/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - loss: 7.1292e-04 - val_loss: 3.9578e-05\n",
            "Epoch 3/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - loss: 2.9739e-04 - val_loss: 2.1955e-05\n",
            "Epoch 4/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - loss: 1.6365e-04 - val_loss: 1.0674e-05\n",
            "Epoch 5/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 37ms/step - loss: 1.0599e-04 - val_loss: 1.0791e-05\n",
            "Epoch 6/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 32ms/step - loss: 9.7456e-05 - val_loss: 1.5324e-06\n",
            "Epoch 7/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 34ms/step - loss: 6.2014e-05 - val_loss: 1.6448e-06\n",
            "Epoch 8/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 49ms/step - loss: 5.3730e-05 - val_loss: 1.0495e-06\n",
            "Epoch 9/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - loss: 4.7837e-05 - val_loss: 1.2358e-06\n",
            "Epoch 10/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 43ms/step - loss: 4.5378e-05 - val_loss: 1.6398e-06\n",
            "Epoch 11/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 32ms/step - loss: 3.9408e-05 - val_loss: 1.7945e-06\n",
            "Epoch 12/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 46ms/step - loss: 4.7084e-05 - val_loss: 1.8585e-06\n",
            "Epoch 13/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 33ms/step - loss: 3.8359e-05 - val_loss: 3.9966e-07\n",
            "Epoch 14/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 4.3622e-05 - val_loss: 1.0807e-06\n",
            "Epoch 15/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 48ms/step - loss: 3.6667e-05 - val_loss: 5.7828e-07\n",
            "Epoch 16/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 32ms/step - loss: 3.8174e-05 - val_loss: 2.8215e-06\n",
            "Epoch 17/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - loss: 2.7478e-05 - val_loss: 2.5149e-06\n",
            "Epoch 18/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - loss: 3.1331e-05 - val_loss: 7.7862e-07\n",
            "Epoch 19/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 46ms/step - loss: 3.4005e-05 - val_loss: 4.5836e-07\n",
            "Epoch 20/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 34ms/step - loss: 3.1790e-05 - val_loss: 7.1859e-07\n",
            "Epoch 21/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 46ms/step - loss: 3.4102e-05 - val_loss: 4.7399e-06\n",
            "Epoch 22/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 34ms/step - loss: 3.6889e-05 - val_loss: 7.8931e-07\n",
            "Epoch 23/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - loss: 2.6200e-05 - val_loss: 2.0537e-06\n",
            "Epoch 24/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - loss: 2.5233e-05 - val_loss: 7.7491e-07\n",
            "Epoch 25/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 50ms/step - loss: 3.0094e-05 - val_loss: 2.1658e-06\n",
            "Epoch 26/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 33ms/step - loss: 2.5701e-05 - val_loss: 1.2060e-05\n",
            "Epoch 27/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - loss: 3.8180e-05 - val_loss: 2.5051e-06\n",
            "Epoch 28/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - loss: 3.1027e-05 - val_loss: 1.4685e-06\n",
            "Epoch 29/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 2.4771e-05 - val_loss: 4.3952e-06\n",
            "Epoch 30/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 42ms/step - loss: 3.0825e-05 - val_loss: 1.1875e-05\n",
            "Epoch 31/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 32ms/step - loss: 3.7452e-05 - val_loss: 7.9613e-07\n",
            "Epoch 32/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - loss: 3.3650e-05 - val_loss: 8.1749e-07\n",
            "Epoch 33/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 47ms/step - loss: 2.7285e-05 - val_loss: 2.6542e-06\n",
            "Epoch 34/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - loss: 2.9705e-05 - val_loss: 2.0843e-05\n",
            "Epoch 35/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 46ms/step - loss: 2.9649e-05 - val_loss: 6.1173e-07\n",
            "Epoch 36/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 33ms/step - loss: 3.5746e-05 - val_loss: 1.8651e-06\n",
            "Epoch 37/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - loss: 3.0103e-05 - val_loss: 3.0908e-06\n",
            "Epoch 38/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - loss: 2.5830e-05 - val_loss: 1.1474e-06\n",
            "Epoch 39/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - loss: 2.7326e-05 - val_loss: 2.3232e-06\n",
            "Epoch 40/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - loss: 3.5400e-05 - val_loss: 5.3423e-06\n",
            "Epoch 41/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - loss: 2.9606e-05 - val_loss: 2.5054e-06\n",
            "Epoch 42/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 49ms/step - loss: 3.7910e-05 - val_loss: 1.2723e-06\n",
            "Epoch 43/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 33ms/step - loss: 3.1701e-05 - val_loss: 1.3243e-06\n",
            "Epoch 44/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - loss: 2.9301e-05 - val_loss: 2.0048e-05\n",
            "Epoch 45/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 34ms/step - loss: 3.2140e-05 - val_loss: 1.3966e-06\n",
            "Epoch 46/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 49ms/step - loss: 3.0089e-05 - val_loss: 2.4534e-06\n",
            "Epoch 47/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - loss: 3.2254e-05 - val_loss: 4.9778e-06\n",
            "Epoch 48/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 3.2674e-05 - val_loss: 3.7644e-06\n",
            "Epoch 49/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 50ms/step - loss: 3.1803e-05 - val_loss: 2.4662e-06\n",
            "Epoch 50/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 36ms/step - loss: 2.9542e-05 - val_loss: 1.0999e-06\n",
            "Epoch 51/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 48ms/step - loss: 2.6179e-05 - val_loss: 4.2480e-06\n",
            "Epoch 52/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - loss: 3.3142e-05 - val_loss: 6.7240e-06\n",
            "Epoch 53/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 3.5178e-05 - val_loss: 1.2575e-05\n",
            "Epoch 54/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 40ms/step - loss: 3.5458e-05 - val_loss: 3.1744e-06\n",
            "Epoch 55/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - loss: 3.0274e-05 - val_loss: 1.7706e-05\n",
            "Epoch 56/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - loss: 3.7460e-05 - val_loss: 1.3822e-06\n",
            "Epoch 57/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - loss: 3.5747e-05 - val_loss: 4.4371e-06\n",
            "Epoch 58/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - loss: 3.0338e-05 - val_loss: 1.3866e-06\n",
            "Epoch 59/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 42ms/step - loss: 2.9535e-05 - val_loss: 7.6170e-07\n",
            "Epoch 60/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - loss: 3.1762e-05 - val_loss: 7.1034e-06\n",
            "Epoch 61/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 46ms/step - loss: 4.1174e-05 - val_loss: 6.1519e-06\n",
            "Epoch 62/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - loss: 3.5573e-05 - val_loss: 1.5666e-06\n",
            "Epoch 63/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 47ms/step - loss: 2.9921e-05 - val_loss: 1.8691e-06\n",
            "Epoch 64/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - loss: 3.0837e-05 - val_loss: 1.3075e-06\n",
            "Epoch 65/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - loss: 2.9364e-05 - val_loss: 7.2663e-07\n",
            "Epoch 66/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - loss: 2.5295e-05 - val_loss: 9.1943e-07\n",
            "Epoch 67/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 43ms/step - loss: 3.2248e-05 - val_loss: 1.1335e-06\n",
            "Epoch 68/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - loss: 3.1805e-05 - val_loss: 2.0082e-05\n",
            "Epoch 69/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 46ms/step - loss: 3.6871e-05 - val_loss: 2.5702e-07\n",
            "Epoch 70/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 32ms/step - loss: 4.1647e-05 - val_loss: 5.9647e-07\n",
            "Epoch 71/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - loss: 3.1775e-05 - val_loss: 2.3362e-07\n",
            "Epoch 72/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 46ms/step - loss: 2.9882e-05 - val_loss: 8.3131e-07\n",
            "Epoch 73/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - loss: 3.5995e-05 - val_loss: 8.8957e-06\n",
            "Epoch 74/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 46ms/step - loss: 3.2049e-05 - val_loss: 4.8707e-06\n",
            "Epoch 75/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - loss: 3.0234e-05 - val_loss: 4.3444e-06\n",
            "Epoch 76/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 48ms/step - loss: 3.7555e-05 - val_loss: 5.4470e-06\n",
            "Epoch 77/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 33ms/step - loss: 3.3623e-05 - val_loss: 1.2977e-06\n",
            "Epoch 78/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 49ms/step - loss: 3.2713e-05 - val_loss: 4.1320e-06\n",
            "Epoch 79/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 33ms/step - loss: 3.1085e-05 - val_loss: 9.0893e-06\n",
            "Epoch 80/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 51ms/step - loss: 3.8564e-05 - val_loss: 2.1056e-06\n"
          ]
        }
      ],
      "source": [
        "bilstm_gru_history = bilstm_gru_model.fit(HV_X_train, HV_y_train, epochs=80, batch_size=32, validation_data=(HV_X_val, HV_y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v5nF6O0HeqiA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4bebf50-29b4-420e-c4dd-e2b81dc1d6ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step\n"
          ]
        }
      ],
      "source": [
        "# Predictions\n",
        "HV_bilstm_gru_predictions = bilstm_gru_model.predict(HV_X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f61Cmfi-e2N4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb0d89ca-0912-47e9-b58d-21d25ee911b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 2.1279771825544544e-06\n",
            "RMSE: 0.0014587587814832356\n",
            "MAE: 0.0013498935572735355\n",
            "MAPE: 7232.559737756878%\n"
          ]
        }
      ],
      "source": [
        "mse = mean_squared_error(HV_y_test, HV_bilstm_gru_predictions)\n",
        "print(f'MSE: {mse}')\n",
        "\n",
        "rmse = np.sqrt(mse)\n",
        "print(f'RMSE: {rmse}')\n",
        "\n",
        "mae = mean_absolute_error(HV_y_test, HV_bilstm_gru_predictions)\n",
        "print(f'MAE: {mae}')\n",
        "\n",
        "mape = calculate_mape(HV_y_test, HV_bilstm_gru_predictions)\n",
        "print(f'MAPE: {mape}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cX3aHr7Ge2TQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "si8QLSI3_Q67"
      },
      "outputs": [],
      "source": [
        "# path_1 = '/content/drive/MyDrive/Volatility/New_data_2000_2024/New_predictions/GKYZV/'\n",
        "\n",
        "# df_pred = pd.DataFrame(HV_test_predictions[:,0], columns=['lstm_pred'])\n",
        "# filename = 'LSTM_pred.csv'\n",
        "# df_pred.to_csv(path_1 + filename)\n",
        "\n",
        "\n",
        "# df_pred = pd.DataFrame(HV_gru_predictions[:,0], columns=['gru_pred'])\n",
        "# filename = 'GRU_pred.csv'\n",
        "# df_pred.to_csv(path_1 + filename)\n",
        "\n",
        "\n",
        "# df_pred = pd.DataFrame(HV_lstm_gru_predictions[:,0], columns=['lstm_gru_pred'])\n",
        "# filename = 'LSTM_GRU_pred.csv'\n",
        "# df_pred.to_csv(path_1 + filename)\n",
        "\n",
        "\n",
        "# df_pred = pd.DataFrame(HV_bilstm_predictions[:,0], columns=['bilstm_pred'])\n",
        "# filename = 'BiLSTM_pred.csv'\n",
        "# df_pred.to_csv(path_1 + filename)\n",
        "\n",
        "\n",
        "# df_pred = pd.DataFrame(HV_bilstm_gru_predictions[:,0], columns=['bilstm_gru_pred'])\n",
        "# filename = 'BiLSTM_GRU_pred.csv'\n",
        "# df_pred.to_csv(path_1 + filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wcR3aAm-_Q9O"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "f31d2QX72Q-8"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}