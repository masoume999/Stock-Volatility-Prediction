{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFG5m0qs6dYz",
        "outputId": "e726c02d-c14b-47eb-d6e1-ec75e4c3a8ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyswarm in /usr/local/lib/python3.10/dist-packages (0.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pyswarm) (1.26.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyswarm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ldsGkAZn5nzG"
      },
      "outputs": [],
      "source": [
        "# from collections import Iterable, OrderedDict\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from collections.abc import Iterable\n",
        "from collections import OrderedDict\n",
        "from google.colab import drive\n",
        "from torch.nn import Parameter\n",
        "from datetime import datetime\n",
        "from functools import partial\n",
        "import torch.optim as optim\n",
        "from pyswarm import pso\n",
        "import torch.nn as nn\n",
        "from math import sqrt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import inspect\n",
        "import torch\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6a-XZWUjJLT"
      },
      "source": [
        "# Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mP60hsS-SkD7",
        "outputId": "ab603bbb-824b-4aee-88ed-3b60405dac88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')\n",
        "path = '/content/drive/MyDrive/Volatility/New_data_2000_2024/Not_normal_wc_real/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EII6yIaGku8G"
      },
      "outputs": [],
      "source": [
        "def set_index(df):\n",
        "  df.index = pd.to_datetime(df['Date'])\n",
        "  df.drop(columns=['Date'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hdqV80OWiosj"
      },
      "outputs": [],
      "source": [
        "filename = 'GKYZV_data.csv'\n",
        "GKYZV_data = pd.read_csv(path + filename)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GKYZV_data.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaKtbNjt5NI8",
        "outputId": "20857635-2370-4f33-dbed-c64a8116d8e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Date', 'GKYZV', 'log_returns', '('GARCH', 'normal', 0)',\n",
              "       '('GARCH', 'normal', 1)', '('GARCH', 'gaussian', 0)',\n",
              "       '('GARCH', 'gaussian', 1)', '('GARCH', 'ged', 0)',\n",
              "       '('GARCH', 'ged', 1)', '('FIGARCH', 'normal', 0)',\n",
              "       '('FIGARCH', 'normal', 1)', '('FIGARCH', 'gaussian', 0)',\n",
              "       '('FIGARCH', 'gaussian', 1)', 'vix', 'interest_rate', 'inflation_rate',\n",
              "       'usd_eur', 'usd_jpy', 'usd_gbp', 'usd_cny', 'usd_cad', 'usd_mxn',\n",
              "       'gt_data', 'unemployment_rate'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GKYZV_data.drop(columns=['vix', 'interest_rate', 'inflation_rate', 'usd_eur', 'usd_jpy', 'usd_gbp', 'usd_cny', 'usd_cad', 'usd_mxn', 'gt_data', 'unemployment_rate'], inplace=True)"
      ],
      "metadata": {
        "id": "hDhykU2QwQiQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GKYZV_data"
      ],
      "metadata": {
        "id": "x2qj6JgCwuRy",
        "outputId": "cc0fe12c-afdb-4739-a0e3-dcb0390a2d58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            Date     GKYZV  log_returns  ('GARCH', 'normal', 0)  \\\n",
              "0     2000-02-02 -0.001436     0.000077               -0.001864   \n",
              "1     2000-02-03 -0.001275     0.000020               -0.001554   \n",
              "2     2000-02-04 -0.000941     0.000152               -0.001080   \n",
              "3     2000-02-07 -0.000613     0.000090               -0.000627   \n",
              "4     2000-02-08 -0.000297    -0.000335               -0.000202   \n",
              "...          ...       ...          ...                     ...   \n",
              "6179  2024-08-26  0.000421    -0.000161               -0.000358   \n",
              "6180  2024-08-27  0.000042    -0.000193               -0.000694   \n",
              "6181  2024-08-28 -0.000355    -0.000154               -0.000954   \n",
              "6182  2024-08-29 -0.000779    -0.000150               -0.001147   \n",
              "6183  2024-08-30 -0.001194    -0.000129               -0.001232   \n",
              "\n",
              "      ('GARCH', 'normal', 1)  ('GARCH', 'gaussian', 0)  \\\n",
              "0                  -0.001725                 -0.001864   \n",
              "1                  -0.001557                 -0.001554   \n",
              "2                  -0.001163                 -0.001080   \n",
              "3                  -0.000738                 -0.000627   \n",
              "4                  -0.000335                 -0.000202   \n",
              "...                      ...                       ...   \n",
              "6179               -0.000493                 -0.000358   \n",
              "6180               -0.000707                 -0.000694   \n",
              "6181               -0.000846                 -0.000954   \n",
              "6182               -0.000937                 -0.001147   \n",
              "6183               -0.000923                 -0.001232   \n",
              "\n",
              "      ('GARCH', 'gaussian', 1)  ('GARCH', 'ged', 0)  ('GARCH', 'ged', 1)  \\\n",
              "0                    -0.001725            -0.001971            -0.001822   \n",
              "1                    -0.001557            -0.001745            -0.001612   \n",
              "2                    -0.001163            -0.001302            -0.001217   \n",
              "3                    -0.000738            -0.000863            -0.000784   \n",
              "4                    -0.000335            -0.000364            -0.000368   \n",
              "...                        ...                  ...                  ...   \n",
              "6179                 -0.000493            -0.001023            -0.000502   \n",
              "6180                 -0.000707            -0.001244            -0.000717   \n",
              "6181                 -0.000846            -0.001311            -0.000852   \n",
              "6182                 -0.000937            -0.001324            -0.000933   \n",
              "6183                 -0.000923            -0.001267            -0.000919   \n",
              "\n",
              "      ('FIGARCH', 'normal', 0)  ('FIGARCH', 'normal', 1)  \\\n",
              "0                    -0.001782                 -0.001782   \n",
              "1                    -0.001519                 -0.001519   \n",
              "2                    -0.001076                 -0.001076   \n",
              "3                    -0.000678                 -0.000678   \n",
              "4                    -0.000311                 -0.000311   \n",
              "...                        ...                       ...   \n",
              "6179                 -0.000690                 -0.000690   \n",
              "6180                 -0.000899                 -0.000899   \n",
              "6181                 -0.001012                 -0.001012   \n",
              "6182                 -0.001067                 -0.001067   \n",
              "6183                 -0.001030                 -0.001030   \n",
              "\n",
              "      ('FIGARCH', 'gaussian', 0)  ('FIGARCH', 'gaussian', 1)  \n",
              "0                      -0.001782                   -0.001782  \n",
              "1                      -0.001519                   -0.001519  \n",
              "2                      -0.001076                   -0.001076  \n",
              "3                      -0.000678                   -0.000678  \n",
              "4                      -0.000311                   -0.000311  \n",
              "...                          ...                         ...  \n",
              "6179                   -0.000690                   -0.000690  \n",
              "6180                   -0.000899                   -0.000899  \n",
              "6181                   -0.001012                   -0.001012  \n",
              "6182                   -0.001067                   -0.001067  \n",
              "6183                   -0.001030                   -0.001030  \n",
              "\n",
              "[6184 rows x 13 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-18b8e06e-e370-4bac-97f0-9ceaea5f25c3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>GKYZV</th>\n",
              "      <th>log_returns</th>\n",
              "      <th>('GARCH', 'normal', 0)</th>\n",
              "      <th>('GARCH', 'normal', 1)</th>\n",
              "      <th>('GARCH', 'gaussian', 0)</th>\n",
              "      <th>('GARCH', 'gaussian', 1)</th>\n",
              "      <th>('GARCH', 'ged', 0)</th>\n",
              "      <th>('GARCH', 'ged', 1)</th>\n",
              "      <th>('FIGARCH', 'normal', 0)</th>\n",
              "      <th>('FIGARCH', 'normal', 1)</th>\n",
              "      <th>('FIGARCH', 'gaussian', 0)</th>\n",
              "      <th>('FIGARCH', 'gaussian', 1)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2000-02-02</td>\n",
              "      <td>-0.001436</td>\n",
              "      <td>0.000077</td>\n",
              "      <td>-0.001864</td>\n",
              "      <td>-0.001725</td>\n",
              "      <td>-0.001864</td>\n",
              "      <td>-0.001725</td>\n",
              "      <td>-0.001971</td>\n",
              "      <td>-0.001822</td>\n",
              "      <td>-0.001782</td>\n",
              "      <td>-0.001782</td>\n",
              "      <td>-0.001782</td>\n",
              "      <td>-0.001782</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2000-02-03</td>\n",
              "      <td>-0.001275</td>\n",
              "      <td>0.000020</td>\n",
              "      <td>-0.001554</td>\n",
              "      <td>-0.001557</td>\n",
              "      <td>-0.001554</td>\n",
              "      <td>-0.001557</td>\n",
              "      <td>-0.001745</td>\n",
              "      <td>-0.001612</td>\n",
              "      <td>-0.001519</td>\n",
              "      <td>-0.001519</td>\n",
              "      <td>-0.001519</td>\n",
              "      <td>-0.001519</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2000-02-04</td>\n",
              "      <td>-0.000941</td>\n",
              "      <td>0.000152</td>\n",
              "      <td>-0.001080</td>\n",
              "      <td>-0.001163</td>\n",
              "      <td>-0.001080</td>\n",
              "      <td>-0.001163</td>\n",
              "      <td>-0.001302</td>\n",
              "      <td>-0.001217</td>\n",
              "      <td>-0.001076</td>\n",
              "      <td>-0.001076</td>\n",
              "      <td>-0.001076</td>\n",
              "      <td>-0.001076</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2000-02-07</td>\n",
              "      <td>-0.000613</td>\n",
              "      <td>0.000090</td>\n",
              "      <td>-0.000627</td>\n",
              "      <td>-0.000738</td>\n",
              "      <td>-0.000627</td>\n",
              "      <td>-0.000738</td>\n",
              "      <td>-0.000863</td>\n",
              "      <td>-0.000784</td>\n",
              "      <td>-0.000678</td>\n",
              "      <td>-0.000678</td>\n",
              "      <td>-0.000678</td>\n",
              "      <td>-0.000678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2000-02-08</td>\n",
              "      <td>-0.000297</td>\n",
              "      <td>-0.000335</td>\n",
              "      <td>-0.000202</td>\n",
              "      <td>-0.000335</td>\n",
              "      <td>-0.000202</td>\n",
              "      <td>-0.000335</td>\n",
              "      <td>-0.000364</td>\n",
              "      <td>-0.000368</td>\n",
              "      <td>-0.000311</td>\n",
              "      <td>-0.000311</td>\n",
              "      <td>-0.000311</td>\n",
              "      <td>-0.000311</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6179</th>\n",
              "      <td>2024-08-26</td>\n",
              "      <td>0.000421</td>\n",
              "      <td>-0.000161</td>\n",
              "      <td>-0.000358</td>\n",
              "      <td>-0.000493</td>\n",
              "      <td>-0.000358</td>\n",
              "      <td>-0.000493</td>\n",
              "      <td>-0.001023</td>\n",
              "      <td>-0.000502</td>\n",
              "      <td>-0.000690</td>\n",
              "      <td>-0.000690</td>\n",
              "      <td>-0.000690</td>\n",
              "      <td>-0.000690</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6180</th>\n",
              "      <td>2024-08-27</td>\n",
              "      <td>0.000042</td>\n",
              "      <td>-0.000193</td>\n",
              "      <td>-0.000694</td>\n",
              "      <td>-0.000707</td>\n",
              "      <td>-0.000694</td>\n",
              "      <td>-0.000707</td>\n",
              "      <td>-0.001244</td>\n",
              "      <td>-0.000717</td>\n",
              "      <td>-0.000899</td>\n",
              "      <td>-0.000899</td>\n",
              "      <td>-0.000899</td>\n",
              "      <td>-0.000899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6181</th>\n",
              "      <td>2024-08-28</td>\n",
              "      <td>-0.000355</td>\n",
              "      <td>-0.000154</td>\n",
              "      <td>-0.000954</td>\n",
              "      <td>-0.000846</td>\n",
              "      <td>-0.000954</td>\n",
              "      <td>-0.000846</td>\n",
              "      <td>-0.001311</td>\n",
              "      <td>-0.000852</td>\n",
              "      <td>-0.001012</td>\n",
              "      <td>-0.001012</td>\n",
              "      <td>-0.001012</td>\n",
              "      <td>-0.001012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6182</th>\n",
              "      <td>2024-08-29</td>\n",
              "      <td>-0.000779</td>\n",
              "      <td>-0.000150</td>\n",
              "      <td>-0.001147</td>\n",
              "      <td>-0.000937</td>\n",
              "      <td>-0.001147</td>\n",
              "      <td>-0.000937</td>\n",
              "      <td>-0.001324</td>\n",
              "      <td>-0.000933</td>\n",
              "      <td>-0.001067</td>\n",
              "      <td>-0.001067</td>\n",
              "      <td>-0.001067</td>\n",
              "      <td>-0.001067</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6183</th>\n",
              "      <td>2024-08-30</td>\n",
              "      <td>-0.001194</td>\n",
              "      <td>-0.000129</td>\n",
              "      <td>-0.001232</td>\n",
              "      <td>-0.000923</td>\n",
              "      <td>-0.001232</td>\n",
              "      <td>-0.000923</td>\n",
              "      <td>-0.001267</td>\n",
              "      <td>-0.000919</td>\n",
              "      <td>-0.001030</td>\n",
              "      <td>-0.001030</td>\n",
              "      <td>-0.001030</td>\n",
              "      <td>-0.001030</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6184 rows Ã— 13 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-18b8e06e-e370-4bac-97f0-9ceaea5f25c3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-18b8e06e-e370-4bac-97f0-9ceaea5f25c3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-18b8e06e-e370-4bac-97f0-9ceaea5f25c3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b728bf2d-9e5f-4c7c-9bcd-6ce5a05055b1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b728bf2d-9e5f-4c7c-9bcd-6ce5a05055b1')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b728bf2d-9e5f-4c7c-9bcd-6ce5a05055b1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "GKYZV_data",
              "summary": "{\n  \"name\": \"GKYZV_data\",\n  \"rows\": 6184,\n  \"fields\": [\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 6184,\n        \"samples\": [\n          \"2021-11-18\",\n          \"2016-05-12\",\n          \"2020-09-03\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"GKYZV\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0003100530643204578,\n        \"min\": -0.0032339052298374,\n        \"max\": 0.0051861080110044,\n        \"num_unique_values\": 6184,\n        \"samples\": [\n          0.000293436743805,\n          9.76602272127097e-07,\n          -0.0001014139893865\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"log_returns\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0009648019919225629,\n        \"min\": -0.0154354460668793,\n        \"max\": 0.0126865949654366,\n        \"num_unique_values\": 6184,\n        \"samples\": [\n          0.0001628402851209,\n          -8.746858572785523e-05,\n          -0.0008952318382649\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"('GARCH', 'normal', 0)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0010840926437869298,\n        \"min\": -0.0139145487816452,\n        \"max\": 0.0313539597803747,\n        \"num_unique_values\": 6184,\n        \"samples\": [\n          0.0006467445895229,\n          3.086619848237932e-06,\n          -0.0011997261820151\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"('GARCH', 'normal', 1)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0014601292763678525,\n        \"min\": -0.018872084416292,\n        \"max\": 0.0484844973091941,\n        \"num_unique_values\": 6184,\n        \"samples\": [\n          0.0005237948929504,\n          8.505600743886686e-06,\n          -0.0010951341787298\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"('GARCH', 'gaussian', 0)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0010840926437869298,\n        \"min\": -0.0139145487816452,\n        \"max\": 0.0313539597803747,\n        \"num_unique_values\": 6184,\n        \"samples\": [\n          0.0006467445895229,\n          3.086619848237932e-06,\n          -0.0011997261820151\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"('GARCH', 'gaussian', 1)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0014601292763678525,\n        \"min\": -0.018872084416292,\n        \"max\": 0.0484844973091941,\n        \"num_unique_values\": 6184,\n        \"samples\": [\n          0.0005237948929504,\n          8.505600743886686e-06,\n          -0.0010951341787298\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"('GARCH', 'ged', 0)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.001084335179517928,\n        \"min\": -0.01349308964851,\n        \"max\": 0.0291212659398564,\n        \"num_unique_values\": 6184,\n        \"samples\": [\n          0.0006837125935864,\n          -2.265574705191369e-09,\n          -0.0012936334390593\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"('GARCH', 'ged', 1)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.001245162201750965,\n        \"min\": -0.0152308619442143,\n        \"max\": 0.0339104058735364,\n        \"num_unique_values\": 6184,\n        \"samples\": [\n          0.0005969898493282,\n          2.018506313965131e-06,\n          -0.0012285714967469\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"('FIGARCH', 'normal', 0)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0009973269692231104,\n        \"min\": -0.0134531038268778,\n        \"max\": 0.0296227070670571,\n        \"num_unique_values\": 6184,\n        \"samples\": [\n          0.000632831795463,\n          5.007689976999768e-06,\n          -0.0009359679282944\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"('FIGARCH', 'normal', 1)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0009973269692231104,\n        \"min\": -0.0134531038268778,\n        \"max\": 0.0296227070670571,\n        \"num_unique_values\": 6184,\n        \"samples\": [\n          0.000632831795463,\n          5.007689976999768e-06,\n          -0.0009359679282944\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"('FIGARCH', 'gaussian', 0)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0009973269692231104,\n        \"min\": -0.0134531038268778,\n        \"max\": 0.0296227070670571,\n        \"num_unique_values\": 6184,\n        \"samples\": [\n          0.000632831795463,\n          5.007689976999768e-06,\n          -0.0009359679282944\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"('FIGARCH', 'gaussian', 1)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0009973269692231104,\n        \"min\": -0.0134531038268778,\n        \"max\": 0.0296227070670571,\n        \"num_unique_values\": 6184,\n        \"samples\": [\n          0.000632831795463,\n          5.007689976999768e-06,\n          -0.0009359679282944\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "set_index(GKYZV_data)"
      ],
      "metadata": {
        "id": "p5e-ly5p1tbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tm_data = GKYZV_data"
      ],
      "metadata": {
        "id": "EqCyHO9axLPn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GKYZV_data = GKYZV_data.drop(columns=['GKYZV'])"
      ],
      "metadata": {
        "id": "vkpwaNZIxEZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GKYZV_data['GKYZV'] = tm_data['GKYZV']"
      ],
      "metadata": {
        "id": "yPnUj4s5xQo5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ewifh-xfipA5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "outputId": "792e1283-ea17-42b1-e5d4-187e31acabd0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            log_returns  ('GARCH', 'normal', 0)  ('GARCH', 'normal', 1)  \\\n",
              "Date                                                                      \n",
              "2000-02-02     0.000077               -0.001864               -0.001725   \n",
              "2000-02-03     0.000020               -0.001554               -0.001557   \n",
              "2000-02-04     0.000152               -0.001080               -0.001163   \n",
              "2000-02-07     0.000090               -0.000627               -0.000738   \n",
              "2000-02-08    -0.000335               -0.000202               -0.000335   \n",
              "...                 ...                     ...                     ...   \n",
              "2024-08-26    -0.000161               -0.000358               -0.000493   \n",
              "2024-08-27    -0.000193               -0.000694               -0.000707   \n",
              "2024-08-28    -0.000154               -0.000954               -0.000846   \n",
              "2024-08-29    -0.000150               -0.001147               -0.000937   \n",
              "2024-08-30    -0.000129               -0.001232               -0.000923   \n",
              "\n",
              "            ('GARCH', 'gaussian', 0)  ('GARCH', 'gaussian', 1)  \\\n",
              "Date                                                             \n",
              "2000-02-02                 -0.001864                 -0.001725   \n",
              "2000-02-03                 -0.001554                 -0.001557   \n",
              "2000-02-04                 -0.001080                 -0.001163   \n",
              "2000-02-07                 -0.000627                 -0.000738   \n",
              "2000-02-08                 -0.000202                 -0.000335   \n",
              "...                              ...                       ...   \n",
              "2024-08-26                 -0.000358                 -0.000493   \n",
              "2024-08-27                 -0.000694                 -0.000707   \n",
              "2024-08-28                 -0.000954                 -0.000846   \n",
              "2024-08-29                 -0.001147                 -0.000937   \n",
              "2024-08-30                 -0.001232                 -0.000923   \n",
              "\n",
              "            ('GARCH', 'ged', 0)  ('GARCH', 'ged', 1)  \\\n",
              "Date                                                   \n",
              "2000-02-02            -0.001971            -0.001822   \n",
              "2000-02-03            -0.001745            -0.001612   \n",
              "2000-02-04            -0.001302            -0.001217   \n",
              "2000-02-07            -0.000863            -0.000784   \n",
              "2000-02-08            -0.000364            -0.000368   \n",
              "...                         ...                  ...   \n",
              "2024-08-26            -0.001023            -0.000502   \n",
              "2024-08-27            -0.001244            -0.000717   \n",
              "2024-08-28            -0.001311            -0.000852   \n",
              "2024-08-29            -0.001324            -0.000933   \n",
              "2024-08-30            -0.001267            -0.000919   \n",
              "\n",
              "            ('FIGARCH', 'normal', 0)  ('FIGARCH', 'normal', 1)  \\\n",
              "Date                                                             \n",
              "2000-02-02                 -0.001782                 -0.001782   \n",
              "2000-02-03                 -0.001519                 -0.001519   \n",
              "2000-02-04                 -0.001076                 -0.001076   \n",
              "2000-02-07                 -0.000678                 -0.000678   \n",
              "2000-02-08                 -0.000311                 -0.000311   \n",
              "...                              ...                       ...   \n",
              "2024-08-26                 -0.000690                 -0.000690   \n",
              "2024-08-27                 -0.000899                 -0.000899   \n",
              "2024-08-28                 -0.001012                 -0.001012   \n",
              "2024-08-29                 -0.001067                 -0.001067   \n",
              "2024-08-30                 -0.001030                 -0.001030   \n",
              "\n",
              "            ('FIGARCH', 'gaussian', 0)  ('FIGARCH', 'gaussian', 1)     GKYZV  \n",
              "Date                                                                          \n",
              "2000-02-02                   -0.001782                   -0.001782 -0.001436  \n",
              "2000-02-03                   -0.001519                   -0.001519 -0.001275  \n",
              "2000-02-04                   -0.001076                   -0.001076 -0.000941  \n",
              "2000-02-07                   -0.000678                   -0.000678 -0.000613  \n",
              "2000-02-08                   -0.000311                   -0.000311 -0.000297  \n",
              "...                                ...                         ...       ...  \n",
              "2024-08-26                   -0.000690                   -0.000690  0.000421  \n",
              "2024-08-27                   -0.000899                   -0.000899  0.000042  \n",
              "2024-08-28                   -0.001012                   -0.001012 -0.000355  \n",
              "2024-08-29                   -0.001067                   -0.001067 -0.000779  \n",
              "2024-08-30                   -0.001030                   -0.001030 -0.001194  \n",
              "\n",
              "[6184 rows x 12 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d3a61926-db4a-48c4-94c8-0cf2cfc95be1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>log_returns</th>\n",
              "      <th>('GARCH', 'normal', 0)</th>\n",
              "      <th>('GARCH', 'normal', 1)</th>\n",
              "      <th>('GARCH', 'gaussian', 0)</th>\n",
              "      <th>('GARCH', 'gaussian', 1)</th>\n",
              "      <th>('GARCH', 'ged', 0)</th>\n",
              "      <th>('GARCH', 'ged', 1)</th>\n",
              "      <th>('FIGARCH', 'normal', 0)</th>\n",
              "      <th>('FIGARCH', 'normal', 1)</th>\n",
              "      <th>('FIGARCH', 'gaussian', 0)</th>\n",
              "      <th>('FIGARCH', 'gaussian', 1)</th>\n",
              "      <th>GKYZV</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2000-02-02</th>\n",
              "      <td>0.000077</td>\n",
              "      <td>-0.001864</td>\n",
              "      <td>-0.001725</td>\n",
              "      <td>-0.001864</td>\n",
              "      <td>-0.001725</td>\n",
              "      <td>-0.001971</td>\n",
              "      <td>-0.001822</td>\n",
              "      <td>-0.001782</td>\n",
              "      <td>-0.001782</td>\n",
              "      <td>-0.001782</td>\n",
              "      <td>-0.001782</td>\n",
              "      <td>-0.001436</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-02-03</th>\n",
              "      <td>0.000020</td>\n",
              "      <td>-0.001554</td>\n",
              "      <td>-0.001557</td>\n",
              "      <td>-0.001554</td>\n",
              "      <td>-0.001557</td>\n",
              "      <td>-0.001745</td>\n",
              "      <td>-0.001612</td>\n",
              "      <td>-0.001519</td>\n",
              "      <td>-0.001519</td>\n",
              "      <td>-0.001519</td>\n",
              "      <td>-0.001519</td>\n",
              "      <td>-0.001275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-02-04</th>\n",
              "      <td>0.000152</td>\n",
              "      <td>-0.001080</td>\n",
              "      <td>-0.001163</td>\n",
              "      <td>-0.001080</td>\n",
              "      <td>-0.001163</td>\n",
              "      <td>-0.001302</td>\n",
              "      <td>-0.001217</td>\n",
              "      <td>-0.001076</td>\n",
              "      <td>-0.001076</td>\n",
              "      <td>-0.001076</td>\n",
              "      <td>-0.001076</td>\n",
              "      <td>-0.000941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-02-07</th>\n",
              "      <td>0.000090</td>\n",
              "      <td>-0.000627</td>\n",
              "      <td>-0.000738</td>\n",
              "      <td>-0.000627</td>\n",
              "      <td>-0.000738</td>\n",
              "      <td>-0.000863</td>\n",
              "      <td>-0.000784</td>\n",
              "      <td>-0.000678</td>\n",
              "      <td>-0.000678</td>\n",
              "      <td>-0.000678</td>\n",
              "      <td>-0.000678</td>\n",
              "      <td>-0.000613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-02-08</th>\n",
              "      <td>-0.000335</td>\n",
              "      <td>-0.000202</td>\n",
              "      <td>-0.000335</td>\n",
              "      <td>-0.000202</td>\n",
              "      <td>-0.000335</td>\n",
              "      <td>-0.000364</td>\n",
              "      <td>-0.000368</td>\n",
              "      <td>-0.000311</td>\n",
              "      <td>-0.000311</td>\n",
              "      <td>-0.000311</td>\n",
              "      <td>-0.000311</td>\n",
              "      <td>-0.000297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-08-26</th>\n",
              "      <td>-0.000161</td>\n",
              "      <td>-0.000358</td>\n",
              "      <td>-0.000493</td>\n",
              "      <td>-0.000358</td>\n",
              "      <td>-0.000493</td>\n",
              "      <td>-0.001023</td>\n",
              "      <td>-0.000502</td>\n",
              "      <td>-0.000690</td>\n",
              "      <td>-0.000690</td>\n",
              "      <td>-0.000690</td>\n",
              "      <td>-0.000690</td>\n",
              "      <td>0.000421</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-08-27</th>\n",
              "      <td>-0.000193</td>\n",
              "      <td>-0.000694</td>\n",
              "      <td>-0.000707</td>\n",
              "      <td>-0.000694</td>\n",
              "      <td>-0.000707</td>\n",
              "      <td>-0.001244</td>\n",
              "      <td>-0.000717</td>\n",
              "      <td>-0.000899</td>\n",
              "      <td>-0.000899</td>\n",
              "      <td>-0.000899</td>\n",
              "      <td>-0.000899</td>\n",
              "      <td>0.000042</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-08-28</th>\n",
              "      <td>-0.000154</td>\n",
              "      <td>-0.000954</td>\n",
              "      <td>-0.000846</td>\n",
              "      <td>-0.000954</td>\n",
              "      <td>-0.000846</td>\n",
              "      <td>-0.001311</td>\n",
              "      <td>-0.000852</td>\n",
              "      <td>-0.001012</td>\n",
              "      <td>-0.001012</td>\n",
              "      <td>-0.001012</td>\n",
              "      <td>-0.001012</td>\n",
              "      <td>-0.000355</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-08-29</th>\n",
              "      <td>-0.000150</td>\n",
              "      <td>-0.001147</td>\n",
              "      <td>-0.000937</td>\n",
              "      <td>-0.001147</td>\n",
              "      <td>-0.000937</td>\n",
              "      <td>-0.001324</td>\n",
              "      <td>-0.000933</td>\n",
              "      <td>-0.001067</td>\n",
              "      <td>-0.001067</td>\n",
              "      <td>-0.001067</td>\n",
              "      <td>-0.001067</td>\n",
              "      <td>-0.000779</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-08-30</th>\n",
              "      <td>-0.000129</td>\n",
              "      <td>-0.001232</td>\n",
              "      <td>-0.000923</td>\n",
              "      <td>-0.001232</td>\n",
              "      <td>-0.000923</td>\n",
              "      <td>-0.001267</td>\n",
              "      <td>-0.000919</td>\n",
              "      <td>-0.001030</td>\n",
              "      <td>-0.001030</td>\n",
              "      <td>-0.001030</td>\n",
              "      <td>-0.001030</td>\n",
              "      <td>-0.001194</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6184 rows Ã— 12 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d3a61926-db4a-48c4-94c8-0cf2cfc95be1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d3a61926-db4a-48c4-94c8-0cf2cfc95be1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d3a61926-db4a-48c4-94c8-0cf2cfc95be1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-dfb1e0e2-208b-41fc-b8e0-c604efef1726\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-dfb1e0e2-208b-41fc-b8e0-c604efef1726')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-dfb1e0e2-208b-41fc-b8e0-c604efef1726 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "GKYZV_data",
              "summary": "{\n  \"name\": \"GKYZV_data\",\n  \"rows\": 6184,\n  \"fields\": [\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2000-02-02 00:00:00\",\n        \"max\": \"2024-08-30 00:00:00\",\n        \"num_unique_values\": 6184,\n        \"samples\": [\n          \"2021-11-18 00:00:00\",\n          \"2016-05-12 00:00:00\",\n          \"2020-09-03 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"log_returns\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0009648019919225629,\n        \"min\": -0.0154354460668793,\n        \"max\": 0.0126865949654366,\n        \"num_unique_values\": 6184,\n        \"samples\": [\n          0.0001628402851209,\n          -8.746858572785523e-05,\n          -0.0008952318382649\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"('GARCH', 'normal', 0)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0010840926437869298,\n        \"min\": -0.0139145487816452,\n        \"max\": 0.0313539597803747,\n        \"num_unique_values\": 6184,\n        \"samples\": [\n          0.0006467445895229,\n          3.086619848237932e-06,\n          -0.0011997261820151\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"('GARCH', 'normal', 1)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0014601292763678525,\n        \"min\": -0.018872084416292,\n        \"max\": 0.0484844973091941,\n        \"num_unique_values\": 6184,\n        \"samples\": [\n          0.0005237948929504,\n          8.505600743886686e-06,\n          -0.0010951341787298\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"('GARCH', 'gaussian', 0)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0010840926437869298,\n        \"min\": -0.0139145487816452,\n        \"max\": 0.0313539597803747,\n        \"num_unique_values\": 6184,\n        \"samples\": [\n          0.0006467445895229,\n          3.086619848237932e-06,\n          -0.0011997261820151\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"('GARCH', 'gaussian', 1)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0014601292763678525,\n        \"min\": -0.018872084416292,\n        \"max\": 0.0484844973091941,\n        \"num_unique_values\": 6184,\n        \"samples\": [\n          0.0005237948929504,\n          8.505600743886686e-06,\n          -0.0010951341787298\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"('GARCH', 'ged', 0)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.001084335179517928,\n        \"min\": -0.01349308964851,\n        \"max\": 0.0291212659398564,\n        \"num_unique_values\": 6184,\n        \"samples\": [\n          0.0006837125935864,\n          -2.265574705191369e-09,\n          -0.0012936334390593\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"('GARCH', 'ged', 1)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.001245162201750965,\n        \"min\": -0.0152308619442143,\n        \"max\": 0.0339104058735364,\n        \"num_unique_values\": 6184,\n        \"samples\": [\n          0.0005969898493282,\n          2.018506313965131e-06,\n          -0.0012285714967469\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"('FIGARCH', 'normal', 0)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0009973269692231104,\n        \"min\": -0.0134531038268778,\n        \"max\": 0.0296227070670571,\n        \"num_unique_values\": 6184,\n        \"samples\": [\n          0.000632831795463,\n          5.007689976999768e-06,\n          -0.0009359679282944\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"('FIGARCH', 'normal', 1)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0009973269692231104,\n        \"min\": -0.0134531038268778,\n        \"max\": 0.0296227070670571,\n        \"num_unique_values\": 6184,\n        \"samples\": [\n          0.000632831795463,\n          5.007689976999768e-06,\n          -0.0009359679282944\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"('FIGARCH', 'gaussian', 0)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0009973269692231104,\n        \"min\": -0.0134531038268778,\n        \"max\": 0.0296227070670571,\n        \"num_unique_values\": 6184,\n        \"samples\": [\n          0.000632831795463,\n          5.007689976999768e-06,\n          -0.0009359679282944\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"('FIGARCH', 'gaussian', 1)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0009973269692231104,\n        \"min\": -0.0134531038268778,\n        \"max\": 0.0296227070670571,\n        \"num_unique_values\": 6184,\n        \"samples\": [\n          0.000632831795463,\n          5.007689976999768e-06,\n          -0.0009359679282944\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"GKYZV\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0003100530643204578,\n        \"min\": -0.0032339052298374,\n        \"max\": 0.0051861080110044,\n        \"num_unique_values\": 6184,\n        \"samples\": [\n          0.000293436743805,\n          9.76602272127097e-07,\n          -0.0001014139893865\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "GKYZV_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NA1Lxf2hi8ye"
      },
      "source": [
        "# Split train, validation and test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WELzACdgipDk"
      },
      "outputs": [],
      "source": [
        "# train_end = datetime(2020, 6, 30)\n",
        "# test_start = datetime(2020, 10, 1)\n",
        "# val_size = 0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6H-uyq2qTCRN"
      },
      "outputs": [],
      "source": [
        "# target = ['GKYZV', 'CCV', 'PV', 'GKV', 'RSV', 'YZV', 'GKYZV']\n",
        "# test_data = data.loc[test_start:]\n",
        "\n",
        "# train_val = data.loc[:train_end]\n",
        "# train_data, val_data = train_test_split(train_val, test_size=val_size, shuffle=False)\n",
        "\n",
        "# X_train = train_data.drop(columns=target)\n",
        "# y_train = train_data[target]\n",
        "\n",
        "# X_val = val_data.drop(columns=target)\n",
        "# y_val = val_data[target]\n",
        "\n",
        "# X_test = test_data.drop(columns=target)\n",
        "# y_test = test_data[target]\n",
        "\n",
        "# X_train = np.array(X_train)\n",
        "# y_train = np.array(y_train)\n",
        "\n",
        "# X_val = np.array(X_val)\n",
        "# y_val = np.array(y_val)\n",
        "\n",
        "# X_test = np.array(X_test)\n",
        "# y_test = np.array(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H7oMfRDtIHl7"
      },
      "outputs": [],
      "source": [
        "def split_data(data, target, train_end =datetime(2022, 5, 30), test_start=datetime(2022, 5, 31), test_size=0.1):\n",
        "  test_data = data.loc[test_start:]\n",
        "\n",
        "  train_val = data.loc[:train_end]\n",
        "  train_data, val_data = train_test_split(train_val, test_size=test_size, shuffle=False)\n",
        "\n",
        "  X_train = train_data.drop(columns=[target])\n",
        "  y_train = train_data[target]\n",
        "\n",
        "  X_val = val_data.drop(columns=[target])\n",
        "  y_val = val_data[target]\n",
        "\n",
        "  X_test = test_data.drop(columns=[target])\n",
        "  y_test = test_data[target]\n",
        "\n",
        "  return np.array(X_train), np.array(y_train), np.array(X_val), np.array(y_val), np.array(X_test), np.array(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2AnhdFq7IHpK"
      },
      "outputs": [],
      "source": [
        "X_train, y_train, X_val, y_val, X_test, y_test = split_data(GKYZV_data, 'GKYZV')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCY0OxyLjQEt"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PCGzie18Cm27"
      },
      "outputs": [],
      "source": [
        "class BDropout(torch.nn.Dropout):\n",
        "\n",
        "    \"\"\"Binary dropout with regularization and resampling.\n",
        "\n",
        "    See: Gal Y., Ghahramani Z., \"Dropout as a Bayesian Approximation:\n",
        "    Representing Model Uncertainty in Deep Learning\", 2016.\n",
        "    \"\"\"\n",
        "\n",
        "    # def __init__(self, rate=0.1, reg=1.0, **kwargs):\n",
        "    #     \"\"\"Constructs a BDropout.\n",
        "\n",
        "    #     Args:\n",
        "    #         rate (float): Dropout probability.\n",
        "    #         reg (float): Regularization scale.\n",
        "    #     \"\"\"\n",
        "    #     super(BDropout, self).__init__(**kwargs)\n",
        "    #     self.register_buffer(\"rate\", torch.tensor(rate))\n",
        "    #     self.p = 1 - self.rate\n",
        "    #     self.register_buffer(\"reg\", torch.tensor(reg))\n",
        "    #     self.register_buffer(\"noise\", torch.bernoulli(self.p))\n",
        "\n",
        "\n",
        "    def __init__(self, rate=0.1, reg=1.0, **kwargs):\n",
        "        \"\"\"Constructs a BDropout.\n",
        "\n",
        "        Args:\n",
        "            rate (float): Dropout probability.\n",
        "            reg (float): Regularization scale.\n",
        "        \"\"\"\n",
        "        super(BDropout, self).__init__(p=rate, **kwargs)\n",
        "        self.register_buffer(\"rate\", torch.tensor(rate))\n",
        "        self.p = 1 - self.rate\n",
        "        self.register_buffer(\"reg\", torch.tensor(reg))\n",
        "        self.register_buffer(\"noise\", torch.bernoulli(self.p))\n",
        "\n",
        "    def regularization(self, weight, bias):\n",
        "        \"\"\"Computes the regularization cost.\n",
        "\n",
        "        Args:\n",
        "            weight (Tensor): Weight tensor.\n",
        "            bias (Tensor): Bias tensor.\n",
        "\n",
        "        Returns:\n",
        "            Regularization cost (Tensor).\n",
        "        \"\"\"\n",
        "        self.p = 1 - self.rate\n",
        "        weight_reg = self.p * (weight**2).sum()\n",
        "        bias_reg = (bias**2).sum() if bias is not None else 0\n",
        "        return self.reg * (weight_reg + bias_reg)\n",
        "\n",
        "    def resample(self):\n",
        "        \"\"\"Resamples the dropout noise.\"\"\"\n",
        "        self._update_noise(self.noise)\n",
        "\n",
        "    def _update_noise(self, x):\n",
        "        \"\"\"Updates the dropout noise.\n",
        "\n",
        "        Args:\n",
        "            x (Tensor): Input.\n",
        "        \"\"\"\n",
        "        self.p = 1 - self.rate\n",
        "        self.noise.data = torch.bernoulli(self.p.expand(x.shape))\n",
        "\n",
        "    def forward(self, x, resample=False, mask_dims=0, **kwargs):\n",
        "        \"\"\"Computes the binary dropout.\n",
        "\n",
        "        Args:\n",
        "            x (Tensor): Input.\n",
        "            resample (bool): Whether to force resample.\n",
        "            mask_dims (int): Number of dimensions to sample noise for\n",
        "                (0 for all).\n",
        "\n",
        "        Returns:\n",
        "            Output (Tensor).\n",
        "        \"\"\"\n",
        "        sample_shape = x.shape[-mask_dims:]\n",
        "        if sample_shape != self.noise.shape:\n",
        "            sample = x.view(-1, *sample_shape)[0]\n",
        "            self._update_noise(sample)\n",
        "        elif resample:\n",
        "            return x * torch.bernoulli(self.p.expand(x.shape))\n",
        "\n",
        "        return x * self.noise\n",
        "\n",
        "    def extra_repr(self):\n",
        "        \"\"\"Formats module representation.\n",
        "\n",
        "        Returns:\n",
        "            Module representation (str).\n",
        "        \"\"\"\n",
        "        return \"rate={}\".format(self.rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6aiACWfS664f"
      },
      "outputs": [],
      "source": [
        "class CDropout(BDropout):\n",
        "\n",
        "    \"\"\"Concrete dropout with regularization and resampling.\n",
        "\n",
        "    See: Gal Y., Hron, J., Kendall, A. \"Concrete Dropout\", 2017.\n",
        "    \"\"\"\n",
        "\n",
        "    # def __init__(self, temperature=0.1, rate=0.5, reg=1.0, **kwargs):\n",
        "    #     \"\"\"Constructs a CDropout.\n",
        "\n",
        "    #     Args:\n",
        "    #         temperature (float): Temperature.\n",
        "    #         rate (float): Initial dropout rate.\n",
        "    #         reg (float): Regularization scale.\n",
        "    #     \"\"\"\n",
        "    #     super(CDropout, self).__init__(rate, reg, **kwargs)\n",
        "    #     self.temperature = Parameter(\n",
        "    #         torch.tensor(temperature), requires_grad=False)\n",
        "\n",
        "    #     # We need to constrain p to [0, 1], so we train logit(p).\n",
        "    #     self.logit_p = Parameter(-torch.log(self.p.reciprocal() - 1.0))\n",
        "\n",
        "    def __init__(self, temperature=0.1, rate=0.5, reg=1.0, **kwargs):\n",
        "        \"\"\"Constructs a CDropout.\n",
        "\n",
        "        Args:\n",
        "            temperature (float): Temperature.\n",
        "            rate (float): Initial dropout rate.\n",
        "            reg (float): Regularization scale.\n",
        "        \"\"\"\n",
        "        super(CDropout, self).__init__(rate, reg, **kwargs)\n",
        "        self.temperature = torch.nn.Parameter(\n",
        "            torch.tensor(temperature), requires_grad=False)\n",
        "\n",
        "        # We need to constrain p to [0, 1], so we train logit(p).\n",
        "        self.logit_p = torch.nn.Parameter(-torch.log(self.p.reciprocal() - 1.0))\n",
        "\n",
        "    def regularization(self, weight, bias):\n",
        "        \"\"\"Computes the regularization cost.\n",
        "\n",
        "        Args:\n",
        "            weight (Tensor): Weight tensor.\n",
        "            bias (Tensor): Bias tensor.\n",
        "\n",
        "        Returns:\n",
        "            Regularization cost (Tensor).\n",
        "        \"\"\"\n",
        "        self.p.data = self.logit_p.sigmoid()\n",
        "        reg = super(CDropout, self).regularization(weight, bias)\n",
        "        reg -= -(1 - self.p) * (1 - self.p).log() - self.p * self.p.log()\n",
        "        return reg\n",
        "\n",
        "    def _update_noise(self, x):\n",
        "        \"\"\"Updates the dropout noise.\n",
        "\n",
        "        Args:\n",
        "            x (Tensor): Input.\n",
        "        \"\"\"\n",
        "        self.noise.data = torch.rand_like(x)\n",
        "\n",
        "    def forward(self, x, resample=False, mask_dims=0, **kwargs):\n",
        "        \"\"\"Computes the concrete dropout.\n",
        "\n",
        "        Args:\n",
        "            x (Tensor): Input.\n",
        "            resample (bool): Whether to force resample.\n",
        "            mask_dims (int): Number of dimensions to sample noise for\n",
        "                (0 for all).\n",
        "\n",
        "        Returns:\n",
        "            Output (Tensor).\n",
        "        \"\"\"\n",
        "        sample_shape = x.shape[-mask_dims:]\n",
        "        noise = self.noise\n",
        "        if sample_shape != noise.shape:\n",
        "            sample = x.view(-1, *sample_shape)[0]\n",
        "            self._update_noise(sample)\n",
        "            noise = self.noise\n",
        "        elif resample:\n",
        "            noise = torch.rand_like(x)\n",
        "\n",
        "        self.p.data = self.logit_p.sigmoid()\n",
        "        concrete_p = self.logit_p + noise.log() - (1 - noise).log()\n",
        "        concrete_noise = (concrete_p / self.temperature).sigmoid()\n",
        "\n",
        "        return x * concrete_noise\n",
        "\n",
        "    def extra_repr(self):\n",
        "        \"\"\"Formats module representation.\n",
        "\n",
        "        Returns:\n",
        "            Module representation (str).\n",
        "        \"\"\"\n",
        "        return \"temperature={}\".format(self.temperature)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xKWpZ-aN5rDg"
      },
      "outputs": [],
      "source": [
        "class BSequential(torch.nn.Sequential):\n",
        "\n",
        "    \"\"\"Extension of Sequential module with regularization and resampling.\"\"\"\n",
        "\n",
        "    def resample(self):\n",
        "        \"\"\"Resample all child modules.\"\"\"\n",
        "        for child in self.children():\n",
        "            if isinstance(child, BDropout):\n",
        "                child.resample()\n",
        "\n",
        "    def regularization(self):\n",
        "        \"\"\"Computes the total regularization cost of all child modules.\n",
        "\n",
        "        Returns:\n",
        "            Total regularization cost (Tensor).\n",
        "        \"\"\"\n",
        "        reg = torch.tensor(0.0)\n",
        "        children = list(self._modules.values())\n",
        "        for i, child in enumerate(children):\n",
        "            if isinstance(child, BSequential):\n",
        "                reg += child.regularization()\n",
        "            elif isinstance(child, BDropout):\n",
        "                for next_child in children[i:]:\n",
        "                    if hasattr(next_child, \"weight\") and hasattr(\n",
        "                            next_child, \"bias\"):\n",
        "                        reg += child.regularization(next_child.weight,\n",
        "                                                    next_child.bias)\n",
        "                        break\n",
        "        return reg\n",
        "\n",
        "    def forward(self, x, resample=False, **kwargs):\n",
        "        \"\"\"Computes the model.\n",
        "\n",
        "        Args:\n",
        "            x (Tensor): Input.\n",
        "            resample (bool): Whether to force resample.\n",
        "\n",
        "        Returns:\n",
        "            Output (Tensor).\n",
        "        \"\"\"\n",
        "        for module in self._modules.values():\n",
        "            if isinstance(module, (BDropout, BSequential)):\n",
        "                x = module(x, resample=resample, **kwargs)\n",
        "            else:\n",
        "                x = module(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6wwsrdDReaGw"
      },
      "outputs": [],
      "source": [
        "def bayesian_model(in_features,\n",
        "                   out_features,\n",
        "                   hidden_features,\n",
        "                   nonlin=nn.ReLU,\n",
        "                   output_nonlin=None,\n",
        "                   weight_initializer=partial(\n",
        "                       nn.init.xavier_normal_,\n",
        "                       gain=nn.init.calculate_gain(\"relu\")),\n",
        "                   bias_initializer=partial(\n",
        "                       nn.init.uniform_, a=-1.0, b=1.0),\n",
        "                   dropout_layers=CDropout,\n",
        "                   input_dropout=None):\n",
        "    \"\"\"Constructs and initializes a Bayesian neural network with dropout.\"\"\"\n",
        "    dims = [in_features] + hidden_features\n",
        "    if not isinstance(dropout_layers, Iterable):\n",
        "        dropout_layers = [dropout_layers] * len(hidden_features)\n",
        "\n",
        "    modules = OrderedDict()\n",
        "\n",
        "    if inspect.isclass(input_dropout):\n",
        "        input_dropout = input_dropout()\n",
        "    if input_dropout is not None:\n",
        "        modules[\"drop_in\"] = input_dropout\n",
        "\n",
        "    for i, (din, dout) in enumerate(zip(dims[:-1], dims[1:])):\n",
        "        drop_i = dropout_layers[i]\n",
        "        if inspect.isclass(drop_i):\n",
        "            drop_i = drop_i()\n",
        "\n",
        "        modules[\"fc_{}\".format(i)] = nn.Linear(din, dout)\n",
        "        if drop_i is not None:\n",
        "            modules[\"drop_{}\".format(i)] = drop_i\n",
        "        modules[\"nonlin_{}\".format(i)] = nonlin()\n",
        "\n",
        "    modules[\"fc_out\"] = nn.Linear(dims[-1], out_features)\n",
        "    if output_nonlin is not None:\n",
        "        modules[\"nonlin_out\"] = output_nonlin()\n",
        "\n",
        "    def init(module):\n",
        "        if callable(weight_initializer) and hasattr(module, \"weight\"):\n",
        "            weight_initializer(module.weight)\n",
        "        if callable(bias_initializer) and hasattr(module, \"bias\"):\n",
        "            if module.bias is not None:\n",
        "                bias_initializer(module.bias)\n",
        "\n",
        "    net = BSequential(modules)\n",
        "    net.apply(init)\n",
        "\n",
        "    return net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QuIBbFj4qeC-"
      },
      "outputs": [],
      "source": [
        "# Convert NumPy arrays to PyTorch tensors\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
        "X_val = torch.tensor(X_val, dtype=torch.float32)\n",
        "y_val = torch.tensor(y_val, dtype=torch.float32)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test = torch.tensor(y_test, dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_q_Sbwt4crQx"
      },
      "outputs": [],
      "source": [
        "# Early stopping implementation\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=10, min_delta=0.0):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.best_val_loss = None\n",
        "        self.counter = 0\n",
        "        self.early_stop = False\n",
        "\n",
        "    def __call__(self, val_loss):\n",
        "        if self.best_val_loss is None:\n",
        "            self.best_val_loss = val_loss\n",
        "        elif val_loss < self.best_val_loss - self.min_delta:\n",
        "            self.best_val_loss = val_loss\n",
        "            self.counter = 0\n",
        "        else:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KNnvVxI-cmS9"
      },
      "outputs": [],
      "source": [
        "# Define parameter bounds\n",
        "def parameter_bounds():\n",
        "    # Number of layers: 1 to 5\n",
        "    num_layers_bounds = (1, 5)\n",
        "\n",
        "    # Number of neurons per layer: 10 to 200\n",
        "    num_neurons_bounds = (10, 200)\n",
        "\n",
        "    # Dropout rate: 0 to 0.5\n",
        "    dropout_rate_bounds = (0.0, 0.5)\n",
        "\n",
        "    # Learning rate: 0.0001 to 0.01\n",
        "    learning_rate_bounds = (0.0001, 0.01)\n",
        "\n",
        "    # Number of epochs: 50 to 500\n",
        "    num_epochs_bounds = (150, 500)\n",
        "\n",
        "    return num_layers_bounds, num_neurons_bounds, dropout_rate_bounds, learning_rate_bounds, num_epochs_bounds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yO6roRjoegbU"
      },
      "outputs": [],
      "source": [
        "def objective_function(params):\n",
        "    # Unpack parameters from PSO\n",
        "    num_layers, num_neurons, dropout_rate, learning_rate, num_epochs = params\n",
        "\n",
        "    # Define the model with the given parameters\n",
        "    model = bayesian_model(\n",
        "        in_features=X_train.shape[1],\n",
        "        out_features=1,\n",
        "        hidden_features=[int(num_neurons)] * int(num_layers),\n",
        "        nonlin=nn.ReLU,\n",
        "        output_nonlin=None,\n",
        "        dropout_layers=CDropout,\n",
        "        input_dropout=CDropout(temperature=0.1, rate=dropout_rate, reg=1.0)\n",
        "    )\n",
        "\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    # Initialize early stopping\n",
        "    early_stopping = EarlyStopping(patience=10, min_delta=0.01)\n",
        "\n",
        "    # Track the best validation loss\n",
        "    best_val_loss = float('inf')\n",
        "\n",
        "    # Training loop with the number of epochs specified in the params\n",
        "    for epoch in range(int(num_epochs)):\n",
        "        model.train()\n",
        "        outputs = model(X_train)\n",
        "        loss = criterion(outputs, y_train)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Validation phase (after each epoch)\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_outputs = model(X_val)\n",
        "            val_loss = criterion(val_outputs, y_val)\n",
        "\n",
        "        # Check and update the best validation loss\n",
        "        if val_loss.item() < best_val_loss:\n",
        "            best_val_loss = val_loss.item()\n",
        "\n",
        "        # Early stopping condition\n",
        "        early_stopping(val_loss.item())\n",
        "        if early_stopping.early_stop:\n",
        "            print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
        "            break\n",
        "\n",
        "    # Return the best validation loss for PSO optimization\n",
        "    return best_val_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7hHofSXf1zf0"
      },
      "outputs": [],
      "source": [
        "# Define the bounds for each parameter\n",
        "def get_bounds():\n",
        "    num_layers_bounds, num_neurons_bounds, dropout_rate_bounds, learning_rate_bounds, num_epochs_bounds = parameter_bounds()\n",
        "    return [\n",
        "        [num_layers_bounds[0], num_neurons_bounds[0], dropout_rate_bounds[0], learning_rate_bounds[0], num_epochs_bounds[0]],\n",
        "        [num_layers_bounds[1], num_neurons_bounds[1], dropout_rate_bounds[1], learning_rate_bounds[1], num_epochs_bounds[1]]\n",
        "    ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c5gdgVxHeqws"
      },
      "outputs": [],
      "source": [
        "bounds = get_bounds()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mPy3prWsemB6"
      },
      "outputs": [],
      "source": [
        "lower_bounds = bounds[0]\n",
        "upper_bounds = bounds[1]\n",
        "\n",
        "swarmsize = 20\n",
        "maxiter = 50"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "\n",
        "best_params, best_val = pso(objective_function, lb=lower_bounds, ub=upper_bounds, swarmsize=swarmsize, maxiter=maxiter, debug=True)\n",
        "\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKEf9ZOtBkd5",
        "outputId": "639c5243-cae5-4a22-a55f-42f69792b86d"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No constraints given.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([5055])) that is different to the input size (torch.Size([5055, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([562])) that is different to the input size (torch.Size([562, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping triggered at epoch 68\n",
            "Early stopping triggered at epoch 18\n",
            "Early stopping triggered at epoch 27\n",
            "Early stopping triggered at epoch 47\n",
            "Early stopping triggered at epoch 45\n",
            "Early stopping triggered at epoch 36\n",
            "Early stopping triggered at epoch 40\n",
            "Early stopping triggered at epoch 39\n",
            "Early stopping triggered at epoch 49\n",
            "Early stopping triggered at epoch 34\n",
            "Early stopping triggered at epoch 14\n",
            "Early stopping triggered at epoch 50\n",
            "Early stopping triggered at epoch 30\n",
            "Early stopping triggered at epoch 43\n",
            "Early stopping triggered at epoch 48\n",
            "Early stopping triggered at epoch 36\n",
            "Early stopping triggered at epoch 46\n",
            "Early stopping triggered at epoch 31\n",
            "Early stopping triggered at epoch 27\n",
            "Early stopping triggered at epoch 73\n",
            "Early stopping triggered at epoch 53\n",
            "Early stopping triggered at epoch 36\n",
            "Early stopping triggered at epoch 59\n",
            "Early stopping triggered at epoch 47\n",
            "Early stopping triggered at epoch 52\n",
            "Early stopping triggered at epoch 48\n",
            "Early stopping triggered at epoch 42\n",
            "Early stopping triggered at epoch 45\n",
            "Early stopping triggered at epoch 40\n",
            "Early stopping triggered at epoch 61\n",
            "Early stopping triggered at epoch 59\n",
            "Early stopping triggered at epoch 50\n",
            "Early stopping triggered at epoch 37\n",
            "Early stopping triggered at epoch 34\n",
            "Early stopping triggered at epoch 50\n",
            "Early stopping triggered at epoch 41\n",
            "Early stopping triggered at epoch 34\n",
            "Early stopping triggered at epoch 50\n",
            "Early stopping triggered at epoch 41\n",
            "Early stopping triggered at epoch 43\n",
            "Best after iteration 1: [3.56618698e+00 9.21436318e+01 2.65069085e-01 9.50434211e-03\n",
            " 2.03826224e+02] 0.0008725710795260966\n",
            "Early stopping triggered at epoch 41\n",
            "Early stopping triggered at epoch 44\n",
            "Early stopping triggered at epoch 63\n",
            "Early stopping triggered at epoch 54\n",
            "Early stopping triggered at epoch 20\n",
            "Early stopping triggered at epoch 49\n",
            "Early stopping triggered at epoch 41\n",
            "Early stopping triggered at epoch 22\n",
            "Early stopping triggered at epoch 53\n",
            "Early stopping triggered at epoch 49\n",
            "Early stopping triggered at epoch 76\n",
            "Early stopping triggered at epoch 47\n",
            "Early stopping triggered at epoch 28\n",
            "Early stopping triggered at epoch 24\n",
            "Early stopping triggered at epoch 34\n",
            "Early stopping triggered at epoch 33\n",
            "Early stopping triggered at epoch 56\n",
            "Early stopping triggered at epoch 50\n",
            "Early stopping triggered at epoch 39\n",
            "Early stopping triggered at epoch 53\n",
            "Best after iteration 2: [3.56618698e+00 9.21436318e+01 2.65069085e-01 9.50434211e-03\n",
            " 2.03826224e+02] 0.0008725710795260966\n",
            "Early stopping triggered at epoch 47\n",
            "Early stopping triggered at epoch 40\n",
            "Early stopping triggered at epoch 26\n",
            "Early stopping triggered at epoch 30\n",
            "Early stopping triggered at epoch 37\n",
            "Early stopping triggered at epoch 35\n",
            "Early stopping triggered at epoch 37\n",
            "Early stopping triggered at epoch 40\n",
            "Early stopping triggered at epoch 23\n",
            "Early stopping triggered at epoch 43\n",
            "Early stopping triggered at epoch 80\n",
            "Early stopping triggered at epoch 42\n",
            "Early stopping triggered at epoch 36\n",
            "Early stopping triggered at epoch 41\n",
            "Early stopping triggered at epoch 37\n",
            "Early stopping triggered at epoch 39\n",
            "Early stopping triggered at epoch 41\n",
            "Early stopping triggered at epoch 43\n",
            "Early stopping triggered at epoch 52\n",
            "Early stopping triggered at epoch 28\n",
            "Best after iteration 3: [3.56618698e+00 9.21436318e+01 2.65069085e-01 9.50434211e-03\n",
            " 2.03826224e+02] 0.0008725710795260966\n",
            "Early stopping triggered at epoch 41\n",
            "Early stopping triggered at epoch 27\n",
            "Early stopping triggered at epoch 50\n",
            "Early stopping triggered at epoch 34\n",
            "Early stopping triggered at epoch 38\n",
            "Early stopping triggered at epoch 33\n",
            "Early stopping triggered at epoch 37\n",
            "Early stopping triggered at epoch 29\n",
            "Early stopping triggered at epoch 48\n",
            "Early stopping triggered at epoch 45\n",
            "Early stopping triggered at epoch 37\n",
            "Early stopping triggered at epoch 41\n",
            "Early stopping triggered at epoch 63\n",
            "Early stopping triggered at epoch 40\n",
            "Early stopping triggered at epoch 39\n",
            "Early stopping triggered at epoch 40\n",
            "Early stopping triggered at epoch 42\n",
            "Early stopping triggered at epoch 34\n",
            "Early stopping triggered at epoch 40\n",
            "Early stopping triggered at epoch 34\n",
            "Best after iteration 4: [3.56618698e+00 9.21436318e+01 2.65069085e-01 9.50434211e-03\n",
            " 2.03826224e+02] 0.0008725710795260966\n",
            "Early stopping triggered at epoch 33\n",
            "Early stopping triggered at epoch 28\n",
            "Early stopping triggered at epoch 48\n",
            "Early stopping triggered at epoch 48\n",
            "Early stopping triggered at epoch 43\n",
            "Early stopping triggered at epoch 45\n",
            "Early stopping triggered at epoch 30\n",
            "Early stopping triggered at epoch 33\n",
            "Early stopping triggered at epoch 58\n",
            "Early stopping triggered at epoch 42\n",
            "Early stopping triggered at epoch 31\n",
            "Early stopping triggered at epoch 40\n",
            "Early stopping triggered at epoch 37\n",
            "Early stopping triggered at epoch 40\n",
            "Early stopping triggered at epoch 33\n",
            "Early stopping triggered at epoch 33\n",
            "Early stopping triggered at epoch 43\n",
            "Early stopping triggered at epoch 26\n",
            "Early stopping triggered at epoch 36\n",
            "Early stopping triggered at epoch 54\n",
            "Best after iteration 5: [3.56618698e+00 9.21436318e+01 2.65069085e-01 9.50434211e-03\n",
            " 2.03826224e+02] 0.0008725710795260966\n",
            "Early stopping triggered at epoch 28\n",
            "Early stopping triggered at epoch 42\n",
            "Early stopping triggered at epoch 31\n",
            "Early stopping triggered at epoch 46\n",
            "Early stopping triggered at epoch 35\n",
            "Early stopping triggered at epoch 45\n",
            "Early stopping triggered at epoch 36\n",
            "Early stopping triggered at epoch 32\n",
            "Early stopping triggered at epoch 27\n",
            "Early stopping triggered at epoch 39\n",
            "Early stopping triggered at epoch 44\n",
            "Early stopping triggered at epoch 41\n",
            "Early stopping triggered at epoch 40\n",
            "Early stopping triggered at epoch 46\n",
            "Early stopping triggered at epoch 35\n",
            "Early stopping triggered at epoch 46\n",
            "Early stopping triggered at epoch 25\n",
            "Early stopping triggered at epoch 49\n",
            "Early stopping triggered at epoch 33\n",
            "Early stopping triggered at epoch 40\n",
            "Best after iteration 6: [3.56618698e+00 9.21436318e+01 2.65069085e-01 9.50434211e-03\n",
            " 2.03826224e+02] 0.0008725710795260966\n",
            "Early stopping triggered at epoch 47\n",
            "Early stopping triggered at epoch 25\n",
            "Early stopping triggered at epoch 35\n",
            "Early stopping triggered at epoch 37\n",
            "Early stopping triggered at epoch 43\n",
            "Early stopping triggered at epoch 41\n",
            "Early stopping triggered at epoch 44\n",
            "Early stopping triggered at epoch 25\n",
            "Early stopping triggered at epoch 64\n",
            "Early stopping triggered at epoch 32\n",
            "Early stopping triggered at epoch 37\n",
            "Early stopping triggered at epoch 26\n",
            "Early stopping triggered at epoch 22\n",
            "Early stopping triggered at epoch 42\n",
            "Early stopping triggered at epoch 22\n",
            "Early stopping triggered at epoch 34\n",
            "Early stopping triggered at epoch 38\n",
            "Early stopping triggered at epoch 36\n",
            "Early stopping triggered at epoch 37\n",
            "Early stopping triggered at epoch 42\n",
            "Best after iteration 7: [3.56618698e+00 9.21436318e+01 2.65069085e-01 9.50434211e-03\n",
            " 2.03826224e+02] 0.0008725710795260966\n",
            "Early stopping triggered at epoch 31\n",
            "Early stopping triggered at epoch 21\n",
            "Early stopping triggered at epoch 34\n",
            "Early stopping triggered at epoch 44\n",
            "Early stopping triggered at epoch 45\n",
            "Early stopping triggered at epoch 53\n",
            "Early stopping triggered at epoch 44\n",
            "Early stopping triggered at epoch 40\n",
            "Early stopping triggered at epoch 35\n",
            "Early stopping triggered at epoch 31\n",
            "Early stopping triggered at epoch 43\n",
            "Early stopping triggered at epoch 28\n",
            "Early stopping triggered at epoch 37\n",
            "Early stopping triggered at epoch 36\n",
            "Early stopping triggered at epoch 41\n",
            "Early stopping triggered at epoch 31\n",
            "Early stopping triggered at epoch 36\n",
            "Early stopping triggered at epoch 44\n",
            "Early stopping triggered at epoch 57\n",
            "Early stopping triggered at epoch 72\n",
            "Best after iteration 8: [3.56618698e+00 9.21436318e+01 2.65069085e-01 9.50434211e-03\n",
            " 2.03826224e+02] 0.0008725710795260966\n",
            "Early stopping triggered at epoch 35\n",
            "Early stopping triggered at epoch 46\n",
            "Early stopping triggered at epoch 49\n",
            "Early stopping triggered at epoch 30\n",
            "Early stopping triggered at epoch 27\n",
            "Early stopping triggered at epoch 45\n",
            "Early stopping triggered at epoch 32\n",
            "Early stopping triggered at epoch 35\n",
            "Early stopping triggered at epoch 28\n",
            "Early stopping triggered at epoch 35\n",
            "Early stopping triggered at epoch 44\n",
            "Early stopping triggered at epoch 37\n",
            "Early stopping triggered at epoch 39\n",
            "Early stopping triggered at epoch 32\n",
            "Early stopping triggered at epoch 30\n",
            "Early stopping triggered at epoch 33\n",
            "Early stopping triggered at epoch 35\n",
            "Early stopping triggered at epoch 31\n",
            "Early stopping triggered at epoch 31\n",
            "Early stopping triggered at epoch 38\n",
            "Best after iteration 9: [3.56618698e+00 9.21436318e+01 2.65069085e-01 9.50434211e-03\n",
            " 2.03826224e+02] 0.0008725710795260966\n",
            "Early stopping triggered at epoch 40\n",
            "Early stopping triggered at epoch 35\n",
            "Early stopping triggered at epoch 38\n",
            "Early stopping triggered at epoch 50\n",
            "Early stopping triggered at epoch 35\n",
            "Early stopping triggered at epoch 45\n",
            "Early stopping triggered at epoch 41\n",
            "Early stopping triggered at epoch 31\n",
            "Early stopping triggered at epoch 36\n",
            "Early stopping triggered at epoch 34\n",
            "Early stopping triggered at epoch 35\n",
            "Early stopping triggered at epoch 39\n",
            "Early stopping triggered at epoch 32\n",
            "Early stopping triggered at epoch 37\n",
            "Early stopping triggered at epoch 30\n",
            "Early stopping triggered at epoch 34\n",
            "Early stopping triggered at epoch 42\n",
            "Early stopping triggered at epoch 38\n",
            "Early stopping triggered at epoch 41\n",
            "Early stopping triggered at epoch 55\n",
            "Best after iteration 10: [3.56618698e+00 9.21436318e+01 2.65069085e-01 9.50434211e-03\n",
            " 2.03826224e+02] 0.0008725710795260966\n",
            "Early stopping triggered at epoch 20\n",
            "Early stopping triggered at epoch 30\n",
            "Early stopping triggered at epoch 41\n",
            "Early stopping triggered at epoch 35\n",
            "Early stopping triggered at epoch 19\n",
            "New best for swarm at iteration 11: [3.45883532e+00 9.50375308e+01 2.67458605e-01 9.58336464e-03\n",
            " 2.17120909e+02] 0.00012746900029014796\n",
            "Early stopping triggered at epoch 30\n",
            "Early stopping triggered at epoch 45\n",
            "Early stopping triggered at epoch 49\n",
            "Early stopping triggered at epoch 30\n",
            "Early stopping triggered at epoch 37\n",
            "Early stopping triggered at epoch 30\n",
            "Early stopping triggered at epoch 18\n",
            "Early stopping triggered at epoch 45\n",
            "Early stopping triggered at epoch 25\n",
            "Early stopping triggered at epoch 36\n",
            "Early stopping triggered at epoch 48\n",
            "Early stopping triggered at epoch 46\n",
            "Early stopping triggered at epoch 29\n",
            "Early stopping triggered at epoch 40\n",
            "Early stopping triggered at epoch 25\n",
            "Best after iteration 11: [3.45883532e+00 9.50375308e+01 2.67458605e-01 9.58336464e-03\n",
            " 2.17120909e+02] 0.00012746900029014796\n",
            "Early stopping triggered at epoch 36\n",
            "Early stopping triggered at epoch 30\n",
            "Early stopping triggered at epoch 36\n",
            "Early stopping triggered at epoch 33\n",
            "Early stopping triggered at epoch 34\n",
            "Early stopping triggered at epoch 52\n",
            "Early stopping triggered at epoch 31\n",
            "Early stopping triggered at epoch 28\n",
            "Early stopping triggered at epoch 42\n",
            "Early stopping triggered at epoch 43\n",
            "Early stopping triggered at epoch 35\n",
            "Early stopping triggered at epoch 29\n",
            "Early stopping triggered at epoch 30\n",
            "Early stopping triggered at epoch 34\n",
            "Early stopping triggered at epoch 35\n",
            "Early stopping triggered at epoch 41\n",
            "Early stopping triggered at epoch 36\n",
            "Early stopping triggered at epoch 30\n",
            "Early stopping triggered at epoch 30\n",
            "Early stopping triggered at epoch 46\n",
            "Best after iteration 12: [3.45883532e+00 9.50375308e+01 2.67458605e-01 9.58336464e-03\n",
            " 2.17120909e+02] 0.00012746900029014796\n",
            "Early stopping triggered at epoch 42\n",
            "Early stopping triggered at epoch 43\n",
            "Early stopping triggered at epoch 34\n",
            "Early stopping triggered at epoch 56\n",
            "Early stopping triggered at epoch 33\n",
            "Early stopping triggered at epoch 30\n",
            "Early stopping triggered at epoch 43\n",
            "Early stopping triggered at epoch 46\n",
            "Early stopping triggered at epoch 40\n",
            "Early stopping triggered at epoch 32\n",
            "Early stopping triggered at epoch 34\n",
            "Early stopping triggered at epoch 45\n",
            "Early stopping triggered at epoch 51\n",
            "Early stopping triggered at epoch 48\n",
            "Early stopping triggered at epoch 38\n",
            "Early stopping triggered at epoch 28\n",
            "Early stopping triggered at epoch 42\n",
            "Early stopping triggered at epoch 34\n",
            "Early stopping triggered at epoch 56\n",
            "Early stopping triggered at epoch 47\n",
            "Best after iteration 13: [3.45883532e+00 9.50375308e+01 2.67458605e-01 9.58336464e-03\n",
            " 2.17120909e+02] 0.00012746900029014796\n",
            "Early stopping triggered at epoch 45\n",
            "Early stopping triggered at epoch 43\n",
            "Early stopping triggered at epoch 28\n",
            "Early stopping triggered at epoch 44\n",
            "Early stopping triggered at epoch 48\n",
            "Early stopping triggered at epoch 41\n",
            "Early stopping triggered at epoch 33\n",
            "Early stopping triggered at epoch 36\n",
            "Early stopping triggered at epoch 42\n",
            "Early stopping triggered at epoch 48\n",
            "Early stopping triggered at epoch 48\n",
            "Early stopping triggered at epoch 33\n",
            "Early stopping triggered at epoch 42\n",
            "Early stopping triggered at epoch 33\n",
            "Early stopping triggered at epoch 34\n",
            "Early stopping triggered at epoch 29\n",
            "Early stopping triggered at epoch 29\n",
            "Early stopping triggered at epoch 27\n",
            "Early stopping triggered at epoch 34\n",
            "Early stopping triggered at epoch 45\n",
            "Best after iteration 14: [3.45883532e+00 9.50375308e+01 2.67458605e-01 9.58336464e-03\n",
            " 2.17120909e+02] 0.00012746900029014796\n",
            "Early stopping triggered at epoch 27\n",
            "Early stopping triggered at epoch 35\n",
            "Early stopping triggered at epoch 42\n",
            "Early stopping triggered at epoch 41\n",
            "Early stopping triggered at epoch 46\n",
            "Early stopping triggered at epoch 41\n",
            "Early stopping triggered at epoch 26\n",
            "Early stopping triggered at epoch 54\n",
            "Early stopping triggered at epoch 50\n",
            "Early stopping triggered at epoch 24\n",
            "Early stopping triggered at epoch 36\n",
            "Early stopping triggered at epoch 40\n",
            "Early stopping triggered at epoch 42\n",
            "Early stopping triggered at epoch 36\n",
            "Early stopping triggered at epoch 31\n",
            "Early stopping triggered at epoch 29\n",
            "Early stopping triggered at epoch 39\n",
            "Early stopping triggered at epoch 34\n",
            "Early stopping triggered at epoch 34\n",
            "Early stopping triggered at epoch 34\n",
            "Best after iteration 15: [3.45883532e+00 9.50375308e+01 2.67458605e-01 9.58336464e-03\n",
            " 2.17120909e+02] 0.00012746900029014796\n",
            "Early stopping triggered at epoch 32\n",
            "Early stopping triggered at epoch 35\n",
            "Early stopping triggered at epoch 37\n",
            "Early stopping triggered at epoch 64\n",
            "Early stopping triggered at epoch 39\n",
            "Early stopping triggered at epoch 38\n",
            "Early stopping triggered at epoch 22\n",
            "Early stopping triggered at epoch 20\n",
            "Early stopping triggered at epoch 34\n",
            "Early stopping triggered at epoch 36\n",
            "Early stopping triggered at epoch 44\n",
            "Early stopping triggered at epoch 28\n",
            "Early stopping triggered at epoch 37\n",
            "Early stopping triggered at epoch 27\n",
            "Early stopping triggered at epoch 35\n",
            "Early stopping triggered at epoch 48\n",
            "Early stopping triggered at epoch 37\n",
            "Early stopping triggered at epoch 34\n",
            "Early stopping triggered at epoch 42\n",
            "Early stopping triggered at epoch 30\n",
            "Best after iteration 16: [3.45883532e+00 9.50375308e+01 2.67458605e-01 9.58336464e-03\n",
            " 2.17120909e+02] 0.00012746900029014796\n",
            "Early stopping triggered at epoch 33\n",
            "Early stopping triggered at epoch 41\n",
            "Early stopping triggered at epoch 45\n",
            "Early stopping triggered at epoch 38\n",
            "Early stopping triggered at epoch 38\n",
            "Early stopping triggered at epoch 40\n",
            "Early stopping triggered at epoch 44\n",
            "Early stopping triggered at epoch 37\n",
            "Early stopping triggered at epoch 21\n",
            "Early stopping triggered at epoch 39\n",
            "Early stopping triggered at epoch 33\n",
            "Early stopping triggered at epoch 33\n",
            "Early stopping triggered at epoch 41\n",
            "Early stopping triggered at epoch 34\n",
            "Early stopping triggered at epoch 36\n",
            "Early stopping triggered at epoch 38\n",
            "Early stopping triggered at epoch 47\n",
            "Early stopping triggered at epoch 19\n",
            "Early stopping triggered at epoch 31\n",
            "Early stopping triggered at epoch 57\n",
            "Best after iteration 17: [3.45883532e+00 9.50375308e+01 2.67458605e-01 9.58336464e-03\n",
            " 2.17120909e+02] 0.00012746900029014796\n",
            "Early stopping triggered at epoch 41\n",
            "Early stopping triggered at epoch 33\n",
            "Early stopping triggered at epoch 34\n",
            "Early stopping triggered at epoch 36\n",
            "Early stopping triggered at epoch 36\n",
            "Early stopping triggered at epoch 43\n",
            "Early stopping triggered at epoch 39\n",
            "Early stopping triggered at epoch 38\n",
            "Early stopping triggered at epoch 40\n",
            "Early stopping triggered at epoch 27\n",
            "Early stopping triggered at epoch 38\n",
            "Early stopping triggered at epoch 27\n",
            "Early stopping triggered at epoch 34\n",
            "Early stopping triggered at epoch 38\n",
            "Early stopping triggered at epoch 42\n",
            "Early stopping triggered at epoch 41\n",
            "Early stopping triggered at epoch 28\n",
            "Early stopping triggered at epoch 38\n",
            "Early stopping triggered at epoch 44\n",
            "Early stopping triggered at epoch 44\n",
            "Best after iteration 18: [3.45883532e+00 9.50375308e+01 2.67458605e-01 9.58336464e-03\n",
            " 2.17120909e+02] 0.00012746900029014796\n",
            "Early stopping triggered at epoch 27\n",
            "Early stopping triggered at epoch 43\n",
            "Early stopping triggered at epoch 18\n",
            "Early stopping triggered at epoch 28\n",
            "Early stopping triggered at epoch 42\n",
            "Early stopping triggered at epoch 43\n",
            "Early stopping triggered at epoch 37\n",
            "Early stopping triggered at epoch 47\n",
            "Early stopping triggered at epoch 47\n",
            "Early stopping triggered at epoch 36\n",
            "Early stopping triggered at epoch 42\n",
            "Early stopping triggered at epoch 40\n",
            "Early stopping triggered at epoch 46\n",
            "Early stopping triggered at epoch 21\n",
            "Early stopping triggered at epoch 42\n",
            "Early stopping triggered at epoch 29\n",
            "Early stopping triggered at epoch 35\n",
            "Early stopping triggered at epoch 30\n",
            "Early stopping triggered at epoch 40\n",
            "Early stopping triggered at epoch 44\n",
            "Best after iteration 19: [3.45883532e+00 9.50375308e+01 2.67458605e-01 9.58336464e-03\n",
            " 2.17120909e+02] 0.00012746900029014796\n",
            "Early stopping triggered at epoch 32\n",
            "Early stopping triggered at epoch 38\n",
            "Early stopping triggered at epoch 34\n",
            "Early stopping triggered at epoch 39\n",
            "Early stopping triggered at epoch 48\n",
            "Early stopping triggered at epoch 34\n",
            "Early stopping triggered at epoch 33\n",
            "Early stopping triggered at epoch 44\n",
            "Early stopping triggered at epoch 30\n",
            "Early stopping triggered at epoch 32\n",
            "Early stopping triggered at epoch 32\n",
            "Early stopping triggered at epoch 44\n",
            "Early stopping triggered at epoch 41\n",
            "Early stopping triggered at epoch 34\n",
            "Early stopping triggered at epoch 38\n",
            "Early stopping triggered at epoch 44\n",
            "Early stopping triggered at epoch 39\n",
            "Early stopping triggered at epoch 21\n",
            "Early stopping triggered at epoch 40\n",
            "Early stopping triggered at epoch 23\n",
            "Best after iteration 20: [3.45883532e+00 9.50375308e+01 2.67458605e-01 9.58336464e-03\n",
            " 2.17120909e+02] 0.00012746900029014796\n",
            "Early stopping triggered at epoch 34\n",
            "Early stopping triggered at epoch 33\n",
            "Early stopping triggered at epoch 38\n",
            "Early stopping triggered at epoch 37\n",
            "Early stopping triggered at epoch 26\n",
            "Early stopping triggered at epoch 32\n",
            "Early stopping triggered at epoch 38\n",
            "Early stopping triggered at epoch 28\n",
            "Early stopping triggered at epoch 22\n",
            "Early stopping triggered at epoch 34\n",
            "Early stopping triggered at epoch 29\n",
            "Early stopping triggered at epoch 33\n",
            "Early stopping triggered at epoch 36\n",
            "Early stopping triggered at epoch 31\n",
            "Early stopping triggered at epoch 37\n",
            "Early stopping triggered at epoch 22\n",
            "Early stopping triggered at epoch 46\n",
            "Early stopping triggered at epoch 45\n",
            "Early stopping triggered at epoch 38\n",
            "Early stopping triggered at epoch 35\n",
            "Best after iteration 21: [3.45883532e+00 9.50375308e+01 2.67458605e-01 9.58336464e-03\n",
            " 2.17120909e+02] 0.00012746900029014796\n",
            "Early stopping triggered at epoch 34\n",
            "Early stopping triggered at epoch 36\n",
            "Early stopping triggered at epoch 35\n",
            "Early stopping triggered at epoch 33\n",
            "Early stopping triggered at epoch 33\n",
            "Early stopping triggered at epoch 41\n",
            "Early stopping triggered at epoch 34\n",
            "Early stopping triggered at epoch 38\n",
            "Early stopping triggered at epoch 34\n",
            "Early stopping triggered at epoch 34\n",
            "Early stopping triggered at epoch 33\n",
            "Early stopping triggered at epoch 36\n",
            "Early stopping triggered at epoch 42\n",
            "Early stopping triggered at epoch 26\n",
            "Early stopping triggered at epoch 35\n",
            "Early stopping triggered at epoch 33\n",
            "Early stopping triggered at epoch 40\n",
            "Early stopping triggered at epoch 40\n",
            "Early stopping triggered at epoch 39\n",
            "Early stopping triggered at epoch 46\n",
            "Best after iteration 22: [3.45883532e+00 9.50375308e+01 2.67458605e-01 9.58336464e-03\n",
            " 2.17120909e+02] 0.00012746900029014796\n",
            "Early stopping triggered at epoch 37\n",
            "Early stopping triggered at epoch 37\n",
            "Early stopping triggered at epoch 42\n",
            "Early stopping triggered at epoch 40\n",
            "Early stopping triggered at epoch 25\n",
            "Early stopping triggered at epoch 35\n",
            "Early stopping triggered at epoch 41\n",
            "Early stopping triggered at epoch 25\n",
            "Early stopping triggered at epoch 22\n",
            "Early stopping triggered at epoch 33\n",
            "Early stopping triggered at epoch 32\n",
            "Early stopping triggered at epoch 35\n",
            "Early stopping triggered at epoch 22\n",
            "Early stopping triggered at epoch 42\n",
            "Early stopping triggered at epoch 33\n",
            "Early stopping triggered at epoch 50\n",
            "Early stopping triggered at epoch 41\n",
            "Early stopping triggered at epoch 44\n",
            "Early stopping triggered at epoch 41\n",
            "Early stopping triggered at epoch 37\n",
            "Best after iteration 23: [3.45883532e+00 9.50375308e+01 2.67458605e-01 9.58336464e-03\n",
            " 2.17120909e+02] 0.00012746900029014796\n",
            "Early stopping triggered at epoch 37\n",
            "Early stopping triggered at epoch 34\n",
            "Early stopping triggered at epoch 55\n",
            "Early stopping triggered at epoch 45\n",
            "Early stopping triggered at epoch 39\n",
            "Early stopping triggered at epoch 46\n",
            "Early stopping triggered at epoch 34\n",
            "Early stopping triggered at epoch 39\n",
            "Early stopping triggered at epoch 34\n",
            "Early stopping triggered at epoch 44\n",
            "Early stopping triggered at epoch 37\n",
            "Early stopping triggered at epoch 34\n",
            "Early stopping triggered at epoch 37\n",
            "Early stopping triggered at epoch 21\n",
            "Early stopping triggered at epoch 42\n",
            "Early stopping triggered at epoch 37\n",
            "Early stopping triggered at epoch 33\n",
            "Early stopping triggered at epoch 36\n",
            "Early stopping triggered at epoch 27\n",
            "Early stopping triggered at epoch 46\n",
            "Best after iteration 24: [3.45883532e+00 9.50375308e+01 2.67458605e-01 9.58336464e-03\n",
            " 2.17120909e+02] 0.00012746900029014796\n",
            "Early stopping triggered at epoch 46\n",
            "Early stopping triggered at epoch 31\n",
            "Early stopping triggered at epoch 32\n",
            "Early stopping triggered at epoch 33\n",
            "Early stopping triggered at epoch 32\n",
            "Early stopping triggered at epoch 29\n",
            "Early stopping triggered at epoch 54\n",
            "Early stopping triggered at epoch 42\n",
            "Early stopping triggered at epoch 35\n",
            "Early stopping triggered at epoch 35\n",
            "Early stopping triggered at epoch 41\n",
            "Early stopping triggered at epoch 52\n",
            "Early stopping triggered at epoch 44\n",
            "Early stopping triggered at epoch 29\n",
            "Early stopping triggered at epoch 27\n",
            "Early stopping triggered at epoch 44\n",
            "Early stopping triggered at epoch 33\n",
            "Early stopping triggered at epoch 42\n",
            "Early stopping triggered at epoch 27\n",
            "Early stopping triggered at epoch 30\n",
            "Best after iteration 25: [3.45883532e+00 9.50375308e+01 2.67458605e-01 9.58336464e-03\n",
            " 2.17120909e+02] 0.00012746900029014796\n",
            "Early stopping triggered at epoch 54\n",
            "Early stopping triggered at epoch 30\n",
            "Early stopping triggered at epoch 39\n",
            "Early stopping triggered at epoch 39\n",
            "Early stopping triggered at epoch 27\n",
            "Early stopping triggered at epoch 30\n",
            "Early stopping triggered at epoch 39\n",
            "Early stopping triggered at epoch 37\n",
            "Early stopping triggered at epoch 38\n",
            "Early stopping triggered at epoch 33\n",
            "Early stopping triggered at epoch 44\n",
            "Early stopping triggered at epoch 26\n",
            "Early stopping triggered at epoch 21\n",
            "Early stopping triggered at epoch 48\n",
            "Early stopping triggered at epoch 36\n",
            "Early stopping triggered at epoch 44\n",
            "Early stopping triggered at epoch 27\n",
            "Early stopping triggered at epoch 32\n",
            "Early stopping triggered at epoch 30\n",
            "Early stopping triggered at epoch 33\n",
            "Best after iteration 26: [3.45883532e+00 9.50375308e+01 2.67458605e-01 9.58336464e-03\n",
            " 2.17120909e+02] 0.00012746900029014796\n",
            "Early stopping triggered at epoch 46\n",
            "Early stopping triggered at epoch 25\n",
            "Early stopping triggered at epoch 40\n",
            "Early stopping triggered at epoch 51\n",
            "Early stopping triggered at epoch 31\n",
            "Early stopping triggered at epoch 36\n",
            "Early stopping triggered at epoch 39\n",
            "Early stopping triggered at epoch 28\n",
            "Early stopping triggered at epoch 33\n",
            "Early stopping triggered at epoch 35\n",
            "Early stopping triggered at epoch 36\n",
            "Early stopping triggered at epoch 41\n",
            "Early stopping triggered at epoch 38\n",
            "Early stopping triggered at epoch 25\n",
            "Early stopping triggered at epoch 51\n",
            "Early stopping triggered at epoch 51\n",
            "Early stopping triggered at epoch 36\n",
            "Early stopping triggered at epoch 34\n",
            "Early stopping triggered at epoch 31\n",
            "Early stopping triggered at epoch 32\n",
            "Best after iteration 27: [3.45883532e+00 9.50375308e+01 2.67458605e-01 9.58336464e-03\n",
            " 2.17120909e+02] 0.00012746900029014796\n",
            "Early stopping triggered at epoch 27\n",
            "Early stopping triggered at epoch 34\n",
            "Early stopping triggered at epoch 32\n",
            "Early stopping triggered at epoch 42\n",
            "Early stopping triggered at epoch 34\n",
            "Early stopping triggered at epoch 45\n",
            "Early stopping triggered at epoch 38\n",
            "Early stopping triggered at epoch 31\n",
            "Early stopping triggered at epoch 47\n",
            "Early stopping triggered at epoch 31\n",
            "Early stopping triggered at epoch 32\n",
            "Early stopping triggered at epoch 49\n",
            "Early stopping triggered at epoch 20\n",
            "Early stopping triggered at epoch 30\n",
            "Early stopping triggered at epoch 41\n",
            "Early stopping triggered at epoch 38\n",
            "Early stopping triggered at epoch 35\n",
            "Early stopping triggered at epoch 33\n",
            "Early stopping triggered at epoch 39\n",
            "Early stopping triggered at epoch 32\n",
            "Best after iteration 28: [3.45883532e+00 9.50375308e+01 2.67458605e-01 9.58336464e-03\n",
            " 2.17120909e+02] 0.00012746900029014796\n",
            "Early stopping triggered at epoch 48\n",
            "Early stopping triggered at epoch 43\n",
            "Early stopping triggered at epoch 42\n",
            "Early stopping triggered at epoch 37\n",
            "Early stopping triggered at epoch 26\n",
            "Early stopping triggered at epoch 32\n",
            "Early stopping triggered at epoch 40\n",
            "Early stopping triggered at epoch 31\n",
            "Early stopping triggered at epoch 40\n",
            "Early stopping triggered at epoch 38\n",
            "Early stopping triggered at epoch 37\n",
            "Early stopping triggered at epoch 37\n",
            "Early stopping triggered at epoch 38\n",
            "Early stopping triggered at epoch 30\n",
            "Early stopping triggered at epoch 27\n",
            "Early stopping triggered at epoch 41\n",
            "Early stopping triggered at epoch 32\n",
            "Early stopping triggered at epoch 43\n",
            "Early stopping triggered at epoch 32\n",
            "Early stopping triggered at epoch 44\n",
            "Best after iteration 29: [3.45883532e+00 9.50375308e+01 2.67458605e-01 9.58336464e-03\n",
            " 2.17120909e+02] 0.00012746900029014796\n",
            "Early stopping triggered at epoch 31\n",
            "Early stopping triggered at epoch 35\n",
            "Early stopping triggered at epoch 50\n",
            "Early stopping triggered at epoch 33\n",
            "Early stopping triggered at epoch 32\n",
            "Early stopping triggered at epoch 41\n",
            "Early stopping triggered at epoch 54\n",
            "Early stopping triggered at epoch 25\n",
            "Early stopping triggered at epoch 43\n",
            "Early stopping triggered at epoch 27\n",
            "Early stopping triggered at epoch 32\n",
            "Early stopping triggered at epoch 34\n",
            "Early stopping triggered at epoch 31\n",
            "Early stopping triggered at epoch 40\n",
            "Early stopping triggered at epoch 36\n",
            "Early stopping triggered at epoch 35\n",
            "Early stopping triggered at epoch 29\n",
            "Early stopping triggered at epoch 38\n",
            "Early stopping triggered at epoch 35\n",
            "Early stopping triggered at epoch 40\n",
            "Best after iteration 30: [3.45883532e+00 9.50375308e+01 2.67458605e-01 9.58336464e-03\n",
            " 2.17120909e+02] 0.00012746900029014796\n",
            "Early stopping triggered at epoch 33\n",
            "Early stopping triggered at epoch 34\n",
            "Early stopping triggered at epoch 42\n",
            "Early stopping triggered at epoch 26\n",
            "Early stopping triggered at epoch 26\n",
            "Early stopping triggered at epoch 36\n",
            "Early stopping triggered at epoch 44\n",
            "Early stopping triggered at epoch 41\n",
            "Early stopping triggered at epoch 29\n",
            "Early stopping triggered at epoch 35\n",
            "Early stopping triggered at epoch 28\n",
            "Early stopping triggered at epoch 45\n",
            "Early stopping triggered at epoch 32\n",
            "Early stopping triggered at epoch 31\n",
            "Early stopping triggered at epoch 27\n",
            "Early stopping triggered at epoch 33\n",
            "Early stopping triggered at epoch 33\n",
            "Early stopping triggered at epoch 40\n",
            "Early stopping triggered at epoch 38\n",
            "Early stopping triggered at epoch 32\n",
            "Best after iteration 31: [3.45883532e+00 9.50375308e+01 2.67458605e-01 9.58336464e-03\n",
            " 2.17120909e+02] 0.00012746900029014796\n",
            "Early stopping triggered at epoch 44\n",
            "Early stopping triggered at epoch 51\n",
            "Early stopping triggered at epoch 36\n",
            "Early stopping triggered at epoch 44\n",
            "Early stopping triggered at epoch 40\n",
            "Early stopping triggered at epoch 16\n",
            "Early stopping triggered at epoch 48\n",
            "Early stopping triggered at epoch 33\n",
            "Early stopping triggered at epoch 33\n",
            "Early stopping triggered at epoch 32\n",
            "Early stopping triggered at epoch 25\n",
            "Early stopping triggered at epoch 57\n",
            "Early stopping triggered at epoch 35\n",
            "Early stopping triggered at epoch 39\n",
            "Early stopping triggered at epoch 35\n",
            "Early stopping triggered at epoch 42\n",
            "Early stopping triggered at epoch 42\n",
            "Early stopping triggered at epoch 24\n",
            "Early stopping triggered at epoch 43\n",
            "Early stopping triggered at epoch 46\n",
            "Best after iteration 32: [3.45883532e+00 9.50375308e+01 2.67458605e-01 9.58336464e-03\n",
            " 2.17120909e+02] 0.00012746900029014796\n",
            "Early stopping triggered at epoch 36\n",
            "Early stopping triggered at epoch 34\n",
            "Early stopping triggered at epoch 50\n",
            "Early stopping triggered at epoch 32\n",
            "Early stopping triggered at epoch 26\n",
            "Early stopping triggered at epoch 28\n",
            "Early stopping triggered at epoch 30\n",
            "Early stopping triggered at epoch 30\n",
            "Early stopping triggered at epoch 36\n",
            "Early stopping triggered at epoch 29\n",
            "Early stopping triggered at epoch 46\n",
            "Early stopping triggered at epoch 27\n",
            "Early stopping triggered at epoch 31\n",
            "Early stopping triggered at epoch 24\n",
            "Early stopping triggered at epoch 20\n",
            "Early stopping triggered at epoch 28\n",
            "Early stopping triggered at epoch 36\n",
            "Early stopping triggered at epoch 32\n",
            "Early stopping triggered at epoch 28\n",
            "Early stopping triggered at epoch 35\n",
            "Best after iteration 33: [3.45883532e+00 9.50375308e+01 2.67458605e-01 9.58336464e-03\n",
            " 2.17120909e+02] 0.00012746900029014796\n",
            "Early stopping triggered at epoch 32\n",
            "Early stopping triggered at epoch 35\n",
            "Early stopping triggered at epoch 24\n",
            "Early stopping triggered at epoch 38\n",
            "Early stopping triggered at epoch 26\n",
            "Early stopping triggered at epoch 24\n",
            "Early stopping triggered at epoch 32\n",
            "Early stopping triggered at epoch 32\n",
            "Early stopping triggered at epoch 30\n",
            "Early stopping triggered at epoch 33\n",
            "Early stopping triggered at epoch 46\n",
            "Early stopping triggered at epoch 38\n",
            "Early stopping triggered at epoch 36\n",
            "Early stopping triggered at epoch 33\n",
            "Early stopping triggered at epoch 34\n",
            "Early stopping triggered at epoch 34\n",
            "Early stopping triggered at epoch 38\n",
            "Early stopping triggered at epoch 35\n",
            "Early stopping triggered at epoch 53\n",
            "Early stopping triggered at epoch 30\n",
            "Best after iteration 34: [3.45883532e+00 9.50375308e+01 2.67458605e-01 9.58336464e-03\n",
            " 2.17120909e+02] 0.00012746900029014796\n",
            "Early stopping triggered at epoch 32\n",
            "Early stopping triggered at epoch 33\n",
            "Early stopping triggered at epoch 39\n",
            "Early stopping triggered at epoch 33\n",
            "Early stopping triggered at epoch 38\n",
            "Early stopping triggered at epoch 38\n",
            "Early stopping triggered at epoch 46\n",
            "Early stopping triggered at epoch 45\n",
            "Early stopping triggered at epoch 29\n",
            "Early stopping triggered at epoch 45\n",
            "Early stopping triggered at epoch 36\n",
            "Early stopping triggered at epoch 33\n",
            "Early stopping triggered at epoch 43\n",
            "Early stopping triggered at epoch 38\n",
            "Early stopping triggered at epoch 36\n",
            "Early stopping triggered at epoch 37\n",
            "Early stopping triggered at epoch 40\n",
            "Early stopping triggered at epoch 28\n",
            "Early stopping triggered at epoch 39\n",
            "Early stopping triggered at epoch 30\n",
            "Best after iteration 35: [3.45883532e+00 9.50375308e+01 2.67458605e-01 9.58336464e-03\n",
            " 2.17120909e+02] 0.00012746900029014796\n",
            "Early stopping triggered at epoch 22\n",
            "Early stopping triggered at epoch 45\n",
            "Early stopping triggered at epoch 39\n",
            "Early stopping triggered at epoch 40\n",
            "Early stopping triggered at epoch 31\n",
            "Early stopping triggered at epoch 32\n",
            "Early stopping triggered at epoch 52\n",
            "Early stopping triggered at epoch 23\n",
            "Early stopping triggered at epoch 37\n",
            "Early stopping triggered at epoch 41\n",
            "Early stopping triggered at epoch 23\n",
            "Early stopping triggered at epoch 36\n",
            "Early stopping triggered at epoch 25\n",
            "Early stopping triggered at epoch 36\n",
            "Early stopping triggered at epoch 32\n",
            "Early stopping triggered at epoch 33\n",
            "Early stopping triggered at epoch 34\n",
            "Early stopping triggered at epoch 38\n",
            "Early stopping triggered at epoch 36\n",
            "Early stopping triggered at epoch 50\n",
            "Best after iteration 36: [3.45883532e+00 9.50375308e+01 2.67458605e-01 9.58336464e-03\n",
            " 2.17120909e+02] 0.00012746900029014796\n",
            "Early stopping triggered at epoch 35\n",
            "Early stopping triggered at epoch 42\n",
            "Early stopping triggered at epoch 33\n",
            "Early stopping triggered at epoch 27\n",
            "Early stopping triggered at epoch 34\n",
            "Early stopping triggered at epoch 42\n",
            "Early stopping triggered at epoch 35\n",
            "Early stopping triggered at epoch 35\n",
            "Early stopping triggered at epoch 34\n",
            "Early stopping triggered at epoch 36\n",
            "Early stopping triggered at epoch 38\n",
            "Early stopping triggered at epoch 54\n",
            "Early stopping triggered at epoch 37\n",
            "Early stopping triggered at epoch 43\n",
            "Early stopping triggered at epoch 39\n",
            "Early stopping triggered at epoch 38\n",
            "Early stopping triggered at epoch 26\n",
            "Early stopping triggered at epoch 46\n",
            "Early stopping triggered at epoch 24\n",
            "Early stopping triggered at epoch 40\n",
            "Best after iteration 37: [3.45883532e+00 9.50375308e+01 2.67458605e-01 9.58336464e-03\n",
            " 2.17120909e+02] 0.00012746900029014796\n",
            "Early stopping triggered at epoch 39\n",
            "Early stopping triggered at epoch 37\n",
            "Early stopping triggered at epoch 37\n",
            "Early stopping triggered at epoch 55\n",
            "Early stopping triggered at epoch 28\n",
            "Early stopping triggered at epoch 33\n",
            "Early stopping triggered at epoch 35\n",
            "Early stopping triggered at epoch 33\n",
            "Early stopping triggered at epoch 27\n",
            "Early stopping triggered at epoch 38\n",
            "Early stopping triggered at epoch 37\n",
            "Early stopping triggered at epoch 32\n",
            "Early stopping triggered at epoch 43\n",
            "Early stopping triggered at epoch 31\n",
            "Early stopping triggered at epoch 38\n",
            "Early stopping triggered at epoch 35\n",
            "Early stopping triggered at epoch 41\n",
            "Early stopping triggered at epoch 34\n",
            "Early stopping triggered at epoch 40\n",
            "Early stopping triggered at epoch 59\n",
            "Best after iteration 38: [3.45883532e+00 9.50375308e+01 2.67458605e-01 9.58336464e-03\n",
            " 2.17120909e+02] 0.00012746900029014796\n",
            "Early stopping triggered at epoch 46\n",
            "Early stopping triggered at epoch 49\n",
            "Early stopping triggered at epoch 39\n",
            "Early stopping triggered at epoch 33\n",
            "Early stopping triggered at epoch 30\n",
            "Early stopping triggered at epoch 34\n",
            "Early stopping triggered at epoch 31\n",
            "Early stopping triggered at epoch 38\n",
            "Early stopping triggered at epoch 32\n",
            "Early stopping triggered at epoch 37\n",
            "Early stopping triggered at epoch 29\n",
            "Early stopping triggered at epoch 41\n",
            "Early stopping triggered at epoch 26\n",
            "Early stopping triggered at epoch 43\n",
            "Early stopping triggered at epoch 31\n",
            "Early stopping triggered at epoch 47\n",
            "Early stopping triggered at epoch 37\n",
            "Early stopping triggered at epoch 36\n",
            "Early stopping triggered at epoch 24\n",
            "Early stopping triggered at epoch 19\n",
            "Best after iteration 39: [3.45883532e+00 9.50375308e+01 2.67458605e-01 9.58336464e-03\n",
            " 2.17120909e+02] 0.00012746900029014796\n",
            "Early stopping triggered at epoch 34\n",
            "Early stopping triggered at epoch 35\n",
            "Early stopping triggered at epoch 29\n",
            "Early stopping triggered at epoch 34\n",
            "Early stopping triggered at epoch 37\n",
            "Early stopping triggered at epoch 37\n",
            "Early stopping triggered at epoch 42\n",
            "Early stopping triggered at epoch 25\n",
            "Early stopping triggered at epoch 44\n",
            "Early stopping triggered at epoch 32\n",
            "Early stopping triggered at epoch 34\n",
            "Early stopping triggered at epoch 38\n",
            "Early stopping triggered at epoch 45\n",
            "Early stopping triggered at epoch 42\n",
            "Early stopping triggered at epoch 36\n",
            "Early stopping triggered at epoch 24\n",
            "Early stopping triggered at epoch 45\n",
            "Early stopping triggered at epoch 40\n",
            "Early stopping triggered at epoch 43\n",
            "Early stopping triggered at epoch 42\n",
            "Best after iteration 40: [3.45883532e+00 9.50375308e+01 2.67458605e-01 9.58336464e-03\n",
            " 2.17120909e+02] 0.00012746900029014796\n",
            "Early stopping triggered at epoch 39\n",
            "Early stopping triggered at epoch 31\n",
            "Early stopping triggered at epoch 40\n",
            "Early stopping triggered at epoch 38\n",
            "Early stopping triggered at epoch 38\n",
            "Early stopping triggered at epoch 22\n",
            "Early stopping triggered at epoch 32\n",
            "Early stopping triggered at epoch 34\n",
            "Early stopping triggered at epoch 32\n",
            "Early stopping triggered at epoch 40\n",
            "Early stopping triggered at epoch 36\n",
            "Early stopping triggered at epoch 39\n",
            "Early stopping triggered at epoch 38\n",
            "Early stopping triggered at epoch 51\n",
            "Early stopping triggered at epoch 46\n",
            "Early stopping triggered at epoch 35\n",
            "Early stopping triggered at epoch 32\n",
            "Early stopping triggered at epoch 38\n",
            "Early stopping triggered at epoch 38\n",
            "Early stopping triggered at epoch 27\n",
            "Best after iteration 41: [3.45883532e+00 9.50375308e+01 2.67458605e-01 9.58336464e-03\n",
            " 2.17120909e+02] 0.00012746900029014796\n",
            "Early stopping triggered at epoch 31\n",
            "Early stopping triggered at epoch 42\n",
            "Early stopping triggered at epoch 29\n",
            "Early stopping triggered at epoch 47\n",
            "Early stopping triggered at epoch 26\n",
            "Early stopping triggered at epoch 30\n",
            "Early stopping triggered at epoch 45\n",
            "Early stopping triggered at epoch 44\n",
            "Early stopping triggered at epoch 28\n",
            "Early stopping triggered at epoch 37\n",
            "Early stopping triggered at epoch 34\n",
            "Early stopping triggered at epoch 33\n",
            "Early stopping triggered at epoch 37\n",
            "Early stopping triggered at epoch 41\n",
            "Early stopping triggered at epoch 34\n",
            "Early stopping triggered at epoch 36\n",
            "Early stopping triggered at epoch 31\n",
            "Early stopping triggered at epoch 29\n",
            "Early stopping triggered at epoch 40\n",
            "Early stopping triggered at epoch 38\n",
            "Best after iteration 42: [3.45883532e+00 9.50375308e+01 2.67458605e-01 9.58336464e-03\n",
            " 2.17120909e+02] 0.00012746900029014796\n",
            "Early stopping triggered at epoch 39\n",
            "Early stopping triggered at epoch 41\n",
            "Early stopping triggered at epoch 31\n",
            "Early stopping triggered at epoch 43\n",
            "Early stopping triggered at epoch 38\n",
            "Early stopping triggered at epoch 33\n",
            "Early stopping triggered at epoch 35\n",
            "Early stopping triggered at epoch 36\n",
            "Early stopping triggered at epoch 25\n",
            "Early stopping triggered at epoch 38\n",
            "Early stopping triggered at epoch 36\n",
            "Early stopping triggered at epoch 37\n",
            "Early stopping triggered at epoch 33\n",
            "Early stopping triggered at epoch 28\n",
            "Early stopping triggered at epoch 41\n",
            "Early stopping triggered at epoch 41\n",
            "Early stopping triggered at epoch 35\n",
            "Early stopping triggered at epoch 35\n",
            "Early stopping triggered at epoch 38\n",
            "Early stopping triggered at epoch 44\n",
            "Best after iteration 43: [3.45883532e+00 9.50375308e+01 2.67458605e-01 9.58336464e-03\n",
            " 2.17120909e+02] 0.00012746900029014796\n",
            "Early stopping triggered at epoch 22\n",
            "Early stopping triggered at epoch 33\n",
            "Early stopping triggered at epoch 49\n",
            "Early stopping triggered at epoch 27\n",
            "Early stopping triggered at epoch 40\n",
            "Early stopping triggered at epoch 35\n",
            "Early stopping triggered at epoch 31\n",
            "Early stopping triggered at epoch 41\n",
            "Early stopping triggered at epoch 29\n",
            "Early stopping triggered at epoch 42\n",
            "Early stopping triggered at epoch 34\n",
            "Early stopping triggered at epoch 36\n",
            "Early stopping triggered at epoch 52\n",
            "Early stopping triggered at epoch 40\n",
            "Early stopping triggered at epoch 22\n",
            "Early stopping triggered at epoch 33\n",
            "Early stopping triggered at epoch 37\n",
            "Early stopping triggered at epoch 41\n",
            "Early stopping triggered at epoch 39\n",
            "Early stopping triggered at epoch 29\n",
            "Best after iteration 44: [3.45883532e+00 9.50375308e+01 2.67458605e-01 9.58336464e-03\n",
            " 2.17120909e+02] 0.00012746900029014796\n",
            "Early stopping triggered at epoch 18\n",
            "Early stopping triggered at epoch 36\n",
            "Early stopping triggered at epoch 22\n",
            "Early stopping triggered at epoch 42\n",
            "Early stopping triggered at epoch 30\n",
            "Early stopping triggered at epoch 39\n",
            "Early stopping triggered at epoch 28\n",
            "Early stopping triggered at epoch 35\n",
            "Early stopping triggered at epoch 26\n",
            "Early stopping triggered at epoch 37\n",
            "Early stopping triggered at epoch 38\n",
            "Early stopping triggered at epoch 34\n",
            "Early stopping triggered at epoch 29\n",
            "Early stopping triggered at epoch 41\n",
            "Early stopping triggered at epoch 38\n",
            "Early stopping triggered at epoch 25\n",
            "Early stopping triggered at epoch 43\n",
            "Early stopping triggered at epoch 25\n",
            "Early stopping triggered at epoch 43\n",
            "Early stopping triggered at epoch 42\n",
            "Best after iteration 45: [3.45883532e+00 9.50375308e+01 2.67458605e-01 9.58336464e-03\n",
            " 2.17120909e+02] 0.00012746900029014796\n",
            "Early stopping triggered at epoch 31\n",
            "Early stopping triggered at epoch 26\n",
            "Early stopping triggered at epoch 31\n",
            "Early stopping triggered at epoch 31\n",
            "Early stopping triggered at epoch 43\n",
            "Early stopping triggered at epoch 43\n",
            "Early stopping triggered at epoch 35\n",
            "Early stopping triggered at epoch 35\n",
            "Early stopping triggered at epoch 46\n",
            "Early stopping triggered at epoch 41\n",
            "Early stopping triggered at epoch 34\n",
            "Early stopping triggered at epoch 48\n",
            "Early stopping triggered at epoch 45\n",
            "Early stopping triggered at epoch 42\n",
            "Early stopping triggered at epoch 40\n",
            "Early stopping triggered at epoch 43\n",
            "Early stopping triggered at epoch 33\n",
            "Early stopping triggered at epoch 24\n",
            "Early stopping triggered at epoch 19\n",
            "Early stopping triggered at epoch 44\n",
            "Best after iteration 46: [3.45883532e+00 9.50375308e+01 2.67458605e-01 9.58336464e-03\n",
            " 2.17120909e+02] 0.00012746900029014796\n",
            "Early stopping triggered at epoch 27\n",
            "Early stopping triggered at epoch 40\n",
            "Early stopping triggered at epoch 38\n",
            "Early stopping triggered at epoch 41\n",
            "Early stopping triggered at epoch 28\n",
            "Early stopping triggered at epoch 59\n",
            "Early stopping triggered at epoch 44\n",
            "Early stopping triggered at epoch 29\n",
            "Early stopping triggered at epoch 35\n",
            "Early stopping triggered at epoch 40\n",
            "Early stopping triggered at epoch 36\n",
            "Early stopping triggered at epoch 37\n",
            "Early stopping triggered at epoch 55\n",
            "Early stopping triggered at epoch 29\n",
            "Early stopping triggered at epoch 25\n",
            "Early stopping triggered at epoch 40\n",
            "Early stopping triggered at epoch 36\n",
            "Early stopping triggered at epoch 48\n",
            "Early stopping triggered at epoch 25\n",
            "Early stopping triggered at epoch 41\n",
            "Best after iteration 47: [3.45883532e+00 9.50375308e+01 2.67458605e-01 9.58336464e-03\n",
            " 2.17120909e+02] 0.00012746900029014796\n",
            "Early stopping triggered at epoch 53\n",
            "Early stopping triggered at epoch 34\n",
            "Early stopping triggered at epoch 39\n",
            "Early stopping triggered at epoch 39\n",
            "Early stopping triggered at epoch 35\n",
            "Early stopping triggered at epoch 30\n",
            "Early stopping triggered at epoch 40\n",
            "Early stopping triggered at epoch 47\n",
            "Early stopping triggered at epoch 33\n",
            "Early stopping triggered at epoch 40\n",
            "Early stopping triggered at epoch 37\n",
            "Early stopping triggered at epoch 38\n",
            "Early stopping triggered at epoch 23\n",
            "Early stopping triggered at epoch 31\n",
            "Early stopping triggered at epoch 34\n",
            "Early stopping triggered at epoch 32\n",
            "Early stopping triggered at epoch 36\n",
            "Early stopping triggered at epoch 42\n",
            "Early stopping triggered at epoch 35\n",
            "Early stopping triggered at epoch 41\n",
            "Best after iteration 48: [3.45883532e+00 9.50375308e+01 2.67458605e-01 9.58336464e-03\n",
            " 2.17120909e+02] 0.00012746900029014796\n",
            "Early stopping triggered at epoch 30\n",
            "Early stopping triggered at epoch 30\n",
            "Early stopping triggered at epoch 27\n",
            "Early stopping triggered at epoch 52\n",
            "Early stopping triggered at epoch 41\n",
            "Early stopping triggered at epoch 38\n",
            "Early stopping triggered at epoch 34\n",
            "Early stopping triggered at epoch 37\n",
            "Early stopping triggered at epoch 39\n",
            "Early stopping triggered at epoch 35\n",
            "Early stopping triggered at epoch 41\n",
            "Early stopping triggered at epoch 36\n",
            "Early stopping triggered at epoch 46\n",
            "Early stopping triggered at epoch 27\n",
            "Early stopping triggered at epoch 34\n",
            "Early stopping triggered at epoch 38\n",
            "Early stopping triggered at epoch 40\n",
            "Early stopping triggered at epoch 24\n",
            "Early stopping triggered at epoch 37\n",
            "Early stopping triggered at epoch 39\n",
            "Best after iteration 49: [3.45883532e+00 9.50375308e+01 2.67458605e-01 9.58336464e-03\n",
            " 2.17120909e+02] 0.00012746900029014796\n",
            "Early stopping triggered at epoch 39\n",
            "Early stopping triggered at epoch 34\n",
            "Early stopping triggered at epoch 38\n",
            "Early stopping triggered at epoch 37\n",
            "Early stopping triggered at epoch 22\n",
            "Early stopping triggered at epoch 36\n",
            "Early stopping triggered at epoch 39\n",
            "Early stopping triggered at epoch 36\n",
            "Early stopping triggered at epoch 38\n",
            "Early stopping triggered at epoch 34\n",
            "Early stopping triggered at epoch 45\n",
            "Early stopping triggered at epoch 37\n",
            "Early stopping triggered at epoch 46\n",
            "Early stopping triggered at epoch 41\n",
            "Early stopping triggered at epoch 23\n",
            "Early stopping triggered at epoch 43\n",
            "Early stopping triggered at epoch 40\n",
            "Early stopping triggered at epoch 38\n",
            "Early stopping triggered at epoch 40\n",
            "Early stopping triggered at epoch 39\n",
            "Best after iteration 50: [3.45883532e+00 9.50375308e+01 2.67458605e-01 9.58336464e-03\n",
            " 2.17120909e+02] 0.00012746900029014796\n",
            "Stopping search: maximum iterations reached --> 50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "execution_time"
      ],
      "metadata": {
        "id": "OwNc_18pByAX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00a0c8e4-16e9-48d1-fea6-52c9d0253df8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11032.199305534363"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_params"
      ],
      "metadata": {
        "id": "XBEFG0ZABzDv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ce8862d-afcf-4838-c462-2594b1141348"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3.45883532e+00, 9.50375308e+01, 2.67458605e-01, 9.58336464e-03,\n",
              "       2.17120909e+02])"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "Y1Lzqooyt5rY"
      },
      "outputs": [],
      "source": [
        "# Function to train and evaluate the model with given hyperparameters\n",
        "def train_and_evaluate_model(params):\n",
        "    n_layers, n_neurons, drop_rate, learning_rate, epochs = params\n",
        "\n",
        "    # Define the model\n",
        "    hidden_features = [int(n_neurons)] * int(n_layers)\n",
        "    model = bayesian_model(\n",
        "        in_features=X_train.shape[1],\n",
        "        out_features=1,\n",
        "        hidden_features=hidden_features,\n",
        "        dropout_layers=CDropout(rate=drop_rate),  # Dropout layer without partial\n",
        "    )\n",
        "\n",
        "    # Define optimizer and loss function\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    # Early stopping\n",
        "    early_stopping = EarlyStopping(patience=10, min_delta=1e-4)\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(int(epochs)):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = model(X_train)\n",
        "        loss = criterion(output, y_train)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        model.eval()\n",
        "        val_output = model(X_val)\n",
        "        val_loss = criterion(val_output, y_val)\n",
        "\n",
        "        print(f'Epoch {epoch+1}/{int(epochs)}, Loss: {loss.item()}, Val Loss: {val_loss.item()}')\n",
        "\n",
        "        early_stopping(val_loss.item())\n",
        "        if early_stopping.early_stop:\n",
        "            print(\"Early stopping triggered\")\n",
        "            break\n",
        "\n",
        "    # Test the model\n",
        "    model.eval()\n",
        "    test_output = model(X_test)\n",
        "    mse = criterion(test_output, y_test)\n",
        "    rmse = mse ** 0.5\n",
        "    mae = nn.L1Loss()(y_test, test_output).item()\n",
        "    mape = torch.mean(torch.abs((y_test - test_output) / y_test)) * 100\n",
        "\n",
        "    print(f'Test Loss: {mse.item()}')\n",
        "    print(f'RMSE: {rmse}')\n",
        "    print(f'MAE: {mae}')\n",
        "    print(f'MAPE: {mape.item()}%')\n",
        "\n",
        "    return mse, rmse, mae, mape, test_output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# best_params = [3.62253629e+00, 1.12321717e+02, 2.77934900e-01, 5.49072091e-03, 2.22486413e+02]"
      ],
      "metadata": {
        "id": "CXZ9OiSS8Mt-"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mse, rmse, mae, mape, test_output = train_and_evaluate_model(best_params)"
      ],
      "metadata": {
        "id": "3gc40IlVC2A2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ac4379d-177a-4f15-d716-80257cd69630"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/217, Loss: 0.4480665326118469, Val Loss: 2.4375600814819336\n",
            "Epoch 2/217, Loss: 2.4921984672546387, Val Loss: 0.4732680022716522\n",
            "Epoch 3/217, Loss: 0.5126733183860779, Val Loss: 0.3239002525806427\n",
            "Epoch 4/217, Loss: 0.2966645658016205, Val Loss: 0.6854788064956665\n",
            "Epoch 5/217, Loss: 0.7038601040840149, Val Loss: 0.6899814605712891\n",
            "Epoch 6/217, Loss: 0.687865674495697, Val Loss: 0.38812363147735596\n",
            "Epoch 7/217, Loss: 0.3802584111690521, Val Loss: 0.16585767269134521\n",
            "Epoch 8/217, Loss: 0.16018086671829224, Val Loss: 0.09008194506168365\n",
            "Epoch 9/217, Loss: 0.09846585988998413, Val Loss: 0.13995704054832458\n",
            "Epoch 10/217, Loss: 0.14005962014198303, Val Loss: 0.18974857032299042\n",
            "Epoch 11/217, Loss: 0.18526731431484222, Val Loss: 0.2088460624217987\n",
            "Epoch 12/217, Loss: 0.1935596764087677, Val Loss: 0.15627245604991913\n",
            "Epoch 13/217, Loss: 0.16813185811042786, Val Loss: 0.12113477289676666\n",
            "Epoch 14/217, Loss: 0.13178357481956482, Val Loss: 0.1019698977470398\n",
            "Epoch 15/217, Loss: 0.09624755382537842, Val Loss: 0.0745590403676033\n",
            "Epoch 16/217, Loss: 0.07293438911437988, Val Loss: 0.06295782327651978\n",
            "Epoch 17/217, Loss: 0.05822031572461128, Val Loss: 0.05632753670215607\n",
            "Epoch 18/217, Loss: 0.05673186108469963, Val Loss: 0.0749310702085495\n",
            "Epoch 19/217, Loss: 0.06343387812376022, Val Loss: 0.06603388488292694\n",
            "Epoch 20/217, Loss: 0.06891640275716782, Val Loss: 0.06764969974756241\n",
            "Epoch 21/217, Loss: 0.07326797395944595, Val Loss: 0.06612169742584229\n",
            "Epoch 22/217, Loss: 0.07212640345096588, Val Loss: 0.07024643570184708\n",
            "Epoch 23/217, Loss: 0.06839168816804886, Val Loss: 0.05573032796382904\n",
            "Epoch 24/217, Loss: 0.061802852898836136, Val Loss: 0.048816196620464325\n",
            "Epoch 25/217, Loss: 0.054016005247831345, Val Loss: 0.04830621927976608\n",
            "Epoch 26/217, Loss: 0.048616923391819, Val Loss: 0.04637434333562851\n",
            "Epoch 27/217, Loss: 0.04322284460067749, Val Loss: 0.04428822919726372\n",
            "Epoch 28/217, Loss: 0.041322629898786545, Val Loss: 0.04140603914856911\n",
            "Epoch 29/217, Loss: 0.041109900921583176, Val Loss: 0.03924969211220741\n",
            "Epoch 30/217, Loss: 0.04221649467945099, Val Loss: 0.04105289652943611\n",
            "Epoch 31/217, Loss: 0.04255183786153793, Val Loss: 0.03681086376309395\n",
            "Epoch 32/217, Loss: 0.0440702848136425, Val Loss: 0.04028359800577164\n",
            "Epoch 33/217, Loss: 0.0443643219769001, Val Loss: 0.0418984517455101\n",
            "Epoch 34/217, Loss: 0.04150782525539398, Val Loss: 0.03772012144327164\n",
            "Epoch 35/217, Loss: 0.04024151712656021, Val Loss: 0.03657307103276253\n",
            "Epoch 36/217, Loss: 0.03810913860797882, Val Loss: 0.03864547982811928\n",
            "Epoch 37/217, Loss: 0.03670239821076393, Val Loss: 0.03446931019425392\n",
            "Epoch 38/217, Loss: 0.03447582945227623, Val Loss: 0.03214003145694733\n",
            "Epoch 39/217, Loss: 0.03469338268041611, Val Loss: 0.03587653487920761\n",
            "Epoch 40/217, Loss: 0.032745759934186935, Val Loss: 0.03002273663878441\n",
            "Epoch 41/217, Loss: 0.034535132348537445, Val Loss: 0.0342075377702713\n",
            "Epoch 42/217, Loss: 0.03280318155884743, Val Loss: 0.031046254560351372\n",
            "Epoch 43/217, Loss: 0.0320376418530941, Val Loss: 0.029894458130002022\n",
            "Epoch 44/217, Loss: 0.032529473304748535, Val Loss: 0.03143077716231346\n",
            "Epoch 45/217, Loss: 0.03203853219747543, Val Loss: 0.029692141339182854\n",
            "Epoch 46/217, Loss: 0.029988229274749756, Val Loss: 0.029328394681215286\n",
            "Epoch 47/217, Loss: 0.030459251254796982, Val Loss: 0.027612140402197838\n",
            "Epoch 48/217, Loss: 0.029051803052425385, Val Loss: 0.02809942327439785\n",
            "Epoch 49/217, Loss: 0.027101168408989906, Val Loss: 0.028125040233135223\n",
            "Epoch 50/217, Loss: 0.02714492380619049, Val Loss: 0.02751753479242325\n",
            "Epoch 51/217, Loss: 0.02713264524936676, Val Loss: 0.027135679498314857\n",
            "Epoch 52/217, Loss: 0.026563463732600212, Val Loss: 0.025672301650047302\n",
            "Epoch 53/217, Loss: 0.02548217959702015, Val Loss: 0.026340089738368988\n",
            "Epoch 54/217, Loss: 0.024504732340574265, Val Loss: 0.024090509861707687\n",
            "Epoch 55/217, Loss: 0.023920118808746338, Val Loss: 0.02476217783987522\n",
            "Epoch 56/217, Loss: 0.02349836565554142, Val Loss: 0.0230348389595747\n",
            "Epoch 57/217, Loss: 0.022213246673345566, Val Loss: 0.022581206634640694\n",
            "Epoch 58/217, Loss: 0.020836034789681435, Val Loss: 0.01846693642437458\n",
            "Epoch 59/217, Loss: 0.0197250097990036, Val Loss: 0.020665530115365982\n",
            "Epoch 60/217, Loss: 0.01976676471531391, Val Loss: 0.01790725812315941\n",
            "Epoch 61/217, Loss: 0.01837593875825405, Val Loss: 0.017578203231096268\n",
            "Epoch 62/217, Loss: 0.017688950523734093, Val Loss: 0.016209915280342102\n",
            "Epoch 63/217, Loss: 0.017505113035440445, Val Loss: 0.016574673354625702\n",
            "Epoch 64/217, Loss: 0.017041435465216637, Val Loss: 0.014555812813341618\n",
            "Epoch 65/217, Loss: 0.01602434180676937, Val Loss: 0.014908314682543278\n",
            "Epoch 66/217, Loss: 0.015477748587727547, Val Loss: 0.01569991372525692\n",
            "Epoch 67/217, Loss: 0.015280396677553654, Val Loss: 0.013040836900472641\n",
            "Epoch 68/217, Loss: 0.01402343064546585, Val Loss: 0.014256569556891918\n",
            "Epoch 69/217, Loss: 0.013560649938881397, Val Loss: 0.012878051958978176\n",
            "Epoch 70/217, Loss: 0.012554886750876904, Val Loss: 0.011991671286523342\n",
            "Epoch 71/217, Loss: 0.012428821064531803, Val Loss: 0.011110379360616207\n",
            "Epoch 72/217, Loss: 0.012105623260140419, Val Loss: 0.010352683253586292\n",
            "Epoch 73/217, Loss: 0.011716214008629322, Val Loss: 0.011176804080605507\n",
            "Epoch 74/217, Loss: 0.010854407213628292, Val Loss: 0.00959106720983982\n",
            "Epoch 75/217, Loss: 0.010566694661974907, Val Loss: 0.009716927073895931\n",
            "Epoch 76/217, Loss: 0.009844223037362099, Val Loss: 0.010426617227494717\n",
            "Epoch 77/217, Loss: 0.009401143528521061, Val Loss: 0.009254682809114456\n",
            "Epoch 78/217, Loss: 0.00966650154441595, Val Loss: 0.00896258745342493\n",
            "Epoch 79/217, Loss: 0.008833024650812149, Val Loss: 0.007677287328988314\n",
            "Epoch 80/217, Loss: 0.008575170300900936, Val Loss: 0.008286304771900177\n",
            "Epoch 81/217, Loss: 0.008526413701474667, Val Loss: 0.008128834888339043\n",
            "Epoch 82/217, Loss: 0.00792292132973671, Val Loss: 0.007042135577648878\n",
            "Epoch 83/217, Loss: 0.007299219258129597, Val Loss: 0.006211554631590843\n",
            "Epoch 84/217, Loss: 0.0072777159512043, Val Loss: 0.008215216919779778\n",
            "Epoch 85/217, Loss: 0.007034050766378641, Val Loss: 0.00750907976180315\n",
            "Epoch 86/217, Loss: 0.006800610106438398, Val Loss: 0.006408012472093105\n",
            "Epoch 87/217, Loss: 0.0069146123714745045, Val Loss: 0.007245839573442936\n",
            "Epoch 88/217, Loss: 0.006466518621891737, Val Loss: 0.006266143172979355\n",
            "Epoch 89/217, Loss: 0.0059650675393640995, Val Loss: 0.005482894368469715\n",
            "Epoch 90/217, Loss: 0.005885153077542782, Val Loss: 0.005429607350379229\n",
            "Epoch 91/217, Loss: 0.0061008865013718605, Val Loss: 0.004673636984080076\n",
            "Epoch 92/217, Loss: 0.005633428227156401, Val Loss: 0.005699442699551582\n",
            "Epoch 93/217, Loss: 0.005686818156391382, Val Loss: 0.0057590557262301445\n",
            "Epoch 94/217, Loss: 0.005504339933395386, Val Loss: 0.0051299799233675\n",
            "Epoch 95/217, Loss: 0.0053432113490998745, Val Loss: 0.005112694576382637\n",
            "Epoch 96/217, Loss: 0.0050183432176709175, Val Loss: 0.005133529659360647\n",
            "Epoch 97/217, Loss: 0.005050836130976677, Val Loss: 0.005477356258779764\n",
            "Epoch 98/217, Loss: 0.004733947571367025, Val Loss: 0.005258786026388407\n",
            "Epoch 99/217, Loss: 0.0050024352967739105, Val Loss: 0.004177433904260397\n",
            "Epoch 100/217, Loss: 0.00474401842802763, Val Loss: 0.0044515784829854965\n",
            "Epoch 101/217, Loss: 0.004443659912794828, Val Loss: 0.004742233082652092\n",
            "Epoch 102/217, Loss: 0.004501738585531712, Val Loss: 0.003755948506295681\n",
            "Epoch 103/217, Loss: 0.004527300596237183, Val Loss: 0.006167934276163578\n",
            "Epoch 104/217, Loss: 0.0042455485090613365, Val Loss: 0.0042498414404690266\n",
            "Epoch 105/217, Loss: 0.004638000391423702, Val Loss: 0.003580942749977112\n",
            "Epoch 106/217, Loss: 0.004209655337035656, Val Loss: 0.004110647365450859\n",
            "Epoch 107/217, Loss: 0.004406716208904982, Val Loss: 0.0040796613320708275\n",
            "Epoch 108/217, Loss: 0.003954784013330936, Val Loss: 0.0035835932940244675\n",
            "Epoch 109/217, Loss: 0.0036883042193949223, Val Loss: 0.0037402829620987177\n",
            "Epoch 110/217, Loss: 0.003695064689964056, Val Loss: 0.003918018192052841\n",
            "Epoch 111/217, Loss: 0.0038209271151572466, Val Loss: 0.004372456111013889\n",
            "Epoch 112/217, Loss: 0.003838140284642577, Val Loss: 0.003148276126012206\n",
            "Epoch 113/217, Loss: 0.00366452569141984, Val Loss: 0.0033697665203362703\n",
            "Epoch 114/217, Loss: 0.0035423876252025366, Val Loss: 0.004253080114722252\n",
            "Epoch 115/217, Loss: 0.003547336906194687, Val Loss: 0.0030549841467291117\n",
            "Epoch 116/217, Loss: 0.0036037336103618145, Val Loss: 0.003139841603115201\n",
            "Epoch 117/217, Loss: 0.0036770962178707123, Val Loss: 0.0035102940164506435\n",
            "Epoch 118/217, Loss: 0.003554845228791237, Val Loss: 0.003848867956548929\n",
            "Epoch 119/217, Loss: 0.003680316498503089, Val Loss: 0.003834696253761649\n",
            "Epoch 120/217, Loss: 0.003499053418636322, Val Loss: 0.0035611619241535664\n",
            "Epoch 121/217, Loss: 0.003317825263366103, Val Loss: 0.0027765175327658653\n",
            "Epoch 122/217, Loss: 0.003525626612827182, Val Loss: 0.0034720769617706537\n",
            "Epoch 123/217, Loss: 0.003551055444404483, Val Loss: 0.0032035151962190866\n",
            "Epoch 124/217, Loss: 0.003404726041480899, Val Loss: 0.0030536288395524025\n",
            "Epoch 125/217, Loss: 0.003450400661677122, Val Loss: 0.004327807109802961\n",
            "Epoch 126/217, Loss: 0.0035914939362555742, Val Loss: 0.002835536142811179\n",
            "Epoch 127/217, Loss: 0.0031782363075762987, Val Loss: 0.0034541492350399494\n",
            "Epoch 128/217, Loss: 0.0033954386599361897, Val Loss: 0.002897389465942979\n",
            "Epoch 129/217, Loss: 0.0033768389839679003, Val Loss: 0.0025943871587514877\n",
            "Epoch 130/217, Loss: 0.0033686005044728518, Val Loss: 0.00300253601744771\n",
            "Epoch 131/217, Loss: 0.003362534800544381, Val Loss: 0.0027778653893619776\n",
            "Epoch 132/217, Loss: 0.0031943253707140684, Val Loss: 0.002697305055335164\n",
            "Epoch 133/217, Loss: 0.0034956305753439665, Val Loss: 0.003556559095159173\n",
            "Epoch 134/217, Loss: 0.003297679126262665, Val Loss: 0.003535762894898653\n",
            "Epoch 135/217, Loss: 0.0034802283626049757, Val Loss: 0.003449596231803298\n",
            "Epoch 136/217, Loss: 0.003114682622253895, Val Loss: 0.003680609865114093\n",
            "Epoch 137/217, Loss: 0.0032958732917904854, Val Loss: 0.0034660561941564083\n",
            "Epoch 138/217, Loss: 0.0029402587097138166, Val Loss: 0.0029168061446398497\n",
            "Epoch 139/217, Loss: 0.002979585900902748, Val Loss: 0.003176975529640913\n",
            "Early stopping triggered\n",
            "Test Loss: 0.0027107272762805223\n",
            "RMSE: 0.052064646035432816\n",
            "MAE: 0.03021499142050743\n",
            "MAPE: 899931.0625%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Final Test Metrics -> MSE: {mse}, RMSE: {rmse}, MAE: {mae}, MAPE: {mape.item()}%')"
      ],
      "metadata": {
        "id": "vwUMaOV3IC4D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2015d629-6ac7-4c6e-d6c6-2a0dcbea7fae"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Test Metrics -> MSE: 0.0027107272762805223, RMSE: 0.052064646035432816, MAE: 0.03021499142050743, MAPE: 899931.0625%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# path_1 = '/content/drive/MyDrive/Volatility/New_data_2000_2024/New_predictions/GKYZV/'\n",
        "\n",
        "# df_pred = pd.DataFrame(test_output.detach().numpy().flatten(), columns=['bnn_pred'])\n",
        "# filename = 'BNN_pred.csv'\n",
        "# df_pred.to_csv(path_1 + filename)"
      ],
      "metadata": {
        "id": "GiKQx-_R80Le"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Lfj9Y75n80Nz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0JVZWmY480qu"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "g6a-XZWUjJLT",
        "NA1Lxf2hi8ye"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}