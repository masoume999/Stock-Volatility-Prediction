{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "f31d2QX72Q-8",
        "AIQfC7oiLhnU",
        "UiS7McIrLmEd",
        "b1e3A5gvPzR6",
        "b4HabdZkeZeL"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8Bmw42Ki0AU8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "from google.colab import drive\n",
        "import yfinance as yf\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, GRU, Dense, Dropout, Flatten, Bidirectional\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from math import sqrt\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "path = '/content/drive/MyDrive/Volatility/New_data_2000_2024/Not_normal_wd/'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uif3K8sx1zgI",
        "outputId": "1b805bea-af97-4b3f-e885-5b57aa8dbfa9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def set_index(df):\n",
        "  df.index = pd.to_datetime(df['Date'])\n",
        "  df.drop(columns=['Date'], inplace=True)"
      ],
      "metadata": {
        "id": "IEBT-saF1ziO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filename = 'CCV_data.csv'\n",
        "HV_data = pd.read_csv(path + filename)"
      ],
      "metadata": {
        "id": "4L7n--ks1-w1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_index(HV_data)"
      ],
      "metadata": {
        "id": "X3ZS5AqFz6_F"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tm_data = HV_data"
      ],
      "metadata": {
        "id": "lloFEkMfzjuu"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "HV_data = HV_data.drop(columns=['CCV'])"
      ],
      "metadata": {
        "id": "GC0utU9by2MH"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "HV_data['CCV'] = tm_data['CCV']"
      ],
      "metadata": {
        "id": "RpBiNwXFz4rd"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "HV_data"
      ],
      "metadata": {
        "id": "2L4kSCVl2LAW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "outputId": "431fe9e2-3f47-419e-c49d-d44055cf1625"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            ('GARCH', 'normal', 0)  ('GARCH', 'normal', 1)  \\\n",
              "Date                                                         \n",
              "2000-02-02                0.039601                0.038301   \n",
              "2000-02-03                0.037979                0.038355   \n",
              "2000-02-04                0.036791                0.037755   \n",
              "2000-02-07                0.046593                0.055072   \n",
              "2000-02-08                0.049131                0.041984   \n",
              "...                            ...                     ...   \n",
              "2024-08-26                0.000120               -0.000665   \n",
              "2024-08-27               -0.003889               -0.004798   \n",
              "2024-08-28                0.000280               -0.001148   \n",
              "2024-08-29               -0.000182               -0.000395   \n",
              "2024-08-30               -0.000978               -0.000269   \n",
              "\n",
              "            ('GARCH', 'gaussian', 0)  ('GARCH', 'gaussian', 1)  \\\n",
              "Date                                                             \n",
              "2000-02-02                  0.039601                  0.038301   \n",
              "2000-02-03                  0.037979                  0.038355   \n",
              "2000-02-04                  0.036791                  0.037755   \n",
              "2000-02-07                  0.046593                  0.055072   \n",
              "2000-02-08                  0.049131                  0.041984   \n",
              "...                              ...                       ...   \n",
              "2024-08-26                  0.000120                 -0.000665   \n",
              "2024-08-27                 -0.003889                 -0.004798   \n",
              "2024-08-28                  0.000280                 -0.001148   \n",
              "2024-08-29                 -0.000182                 -0.000395   \n",
              "2024-08-30                 -0.000978                 -0.000269   \n",
              "\n",
              "            ('GARCH', 'ged', 0)  ('GARCH', 'ged', 1)  \\\n",
              "Date                                                   \n",
              "2000-02-02             0.040044             0.039199   \n",
              "2000-02-03             0.041000             0.040608   \n",
              "2000-02-04             0.038214             0.040159   \n",
              "2000-02-07             0.047968             0.057512   \n",
              "2000-02-08             0.049560             0.042487   \n",
              "...                         ...                  ...   \n",
              "2024-08-26             0.000456            -0.000424   \n",
              "2024-08-27            -0.003539            -0.002953   \n",
              "2024-08-28             0.000449            -0.000383   \n",
              "2024-08-29            -0.000122             0.000615   \n",
              "2024-08-30            -0.000987             0.000618   \n",
              "\n",
              "            ('FIGARCH', 'normal', 0)  ('FIGARCH', 'normal', 1)  \\\n",
              "Date                                                             \n",
              "2000-02-02                  0.038388                  0.038388   \n",
              "2000-02-03                  0.038633                  0.038633   \n",
              "2000-02-04                  0.036990                  0.036990   \n",
              "2000-02-07                  0.046474                  0.046474   \n",
              "2000-02-08                  0.046711                  0.046711   \n",
              "...                              ...                       ...   \n",
              "2024-08-26                  0.000121                  0.000121   \n",
              "2024-08-27                 -0.004368                 -0.004368   \n",
              "2024-08-28                  0.000483                  0.000483   \n",
              "2024-08-29                 -0.000352                 -0.000352   \n",
              "2024-08-30                 -0.000533                 -0.000533   \n",
              "\n",
              "            ('FIGARCH', 'gaussian', 0)  ('FIGARCH', 'gaussian', 1)  ...  \\\n",
              "Date                                                                ...   \n",
              "2000-02-02                    0.038388                    0.038388  ...   \n",
              "2000-02-03                    0.038633                    0.038633  ...   \n",
              "2000-02-04                    0.036990                    0.036990  ...   \n",
              "2000-02-07                    0.046474                    0.046474  ...   \n",
              "2000-02-08                    0.046711                    0.046711  ...   \n",
              "...                                ...                         ...  ...   \n",
              "2024-08-26                    0.000121                    0.000121  ...   \n",
              "2024-08-27                   -0.004368                   -0.004368  ...   \n",
              "2024-08-28                    0.000483                    0.000483  ...   \n",
              "2024-08-29                   -0.000352                   -0.000352  ...   \n",
              "2024-08-30                   -0.000533                   -0.000533  ...   \n",
              "\n",
              "            unemployment_rate   usd_eur     usd_jpy   usd_gbp    usd_cny  \\\n",
              "Date                                                                       \n",
              "2000-02-02          11.596551  2.781970  307.252039  4.529620  23.415205   \n",
              "2000-02-03          11.596551  2.799436  311.491144  4.529266  23.412659   \n",
              "2000-02-04          11.419775  2.728548  306.262089  4.474254  23.415452   \n",
              "2000-02-07          11.313708  2.733357  299.491542  4.460147  23.414391   \n",
              "2000-02-08          11.313708  2.730104  301.761354  4.470789  23.415982   \n",
              "...                       ...       ...         ...       ...        ...   \n",
              "2024-08-26           0.000000 -0.002546    0.509117 -0.003041   0.005162   \n",
              "2024-08-27           0.000000  0.002051   -0.551543 -0.001202  -0.006788   \n",
              "2024-08-28           0.000000  0.000849    0.247487  0.000849   0.002263   \n",
              "2024-08-29           0.000000  0.002333   -0.148492  0.002404  -0.000071   \n",
              "2024-08-30           0.000000  0.001838   -0.685894  0.003818   0.005091   \n",
              "\n",
              "             usd_cad    usd_mxn     gt_data  log_returns       CCV  \n",
              "Date                                                                \n",
              "2000-02-02  4.090860  26.750733  209.303607    -0.005604  0.038529  \n",
              "2000-02-03  4.119569  26.561052  209.303607    -0.008693  0.039312  \n",
              "2000-02-04  4.106629  26.433950  209.303607     0.000572  0.037268  \n",
              "2000-02-07  4.140641  26.339020  209.303607     0.027307  0.043409  \n",
              "2000-02-08  4.142338  26.135551  209.303607     0.010478  0.049799  \n",
              "...              ...        ...         ...          ...       ...  \n",
              "2024-08-26  0.001980  -0.105925    0.404061     0.008246  0.000132  \n",
              "2024-08-27 -0.001556  -0.173948    0.404061     0.009336  0.000613  \n",
              "2024-08-28  0.002051  -0.219910    0.707107     0.010307  0.000140  \n",
              "2024-08-29 -0.000566   0.084711   -0.101015     0.005365 -0.000016  \n",
              "2024-08-30 -0.002333   0.092207   -0.101015    -0.007129  0.000139  \n",
              "\n",
              "[6184 rows x 34 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7919bd76-eb9e-4599-802e-b2224329142e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>('GARCH', 'normal', 0)</th>\n",
              "      <th>('GARCH', 'normal', 1)</th>\n",
              "      <th>('GARCH', 'gaussian', 0)</th>\n",
              "      <th>('GARCH', 'gaussian', 1)</th>\n",
              "      <th>('GARCH', 'ged', 0)</th>\n",
              "      <th>('GARCH', 'ged', 1)</th>\n",
              "      <th>('FIGARCH', 'normal', 0)</th>\n",
              "      <th>('FIGARCH', 'normal', 1)</th>\n",
              "      <th>('FIGARCH', 'gaussian', 0)</th>\n",
              "      <th>('FIGARCH', 'gaussian', 1)</th>\n",
              "      <th>...</th>\n",
              "      <th>unemployment_rate</th>\n",
              "      <th>usd_eur</th>\n",
              "      <th>usd_jpy</th>\n",
              "      <th>usd_gbp</th>\n",
              "      <th>usd_cny</th>\n",
              "      <th>usd_cad</th>\n",
              "      <th>usd_mxn</th>\n",
              "      <th>gt_data</th>\n",
              "      <th>log_returns</th>\n",
              "      <th>CCV</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2000-02-02</th>\n",
              "      <td>0.039601</td>\n",
              "      <td>0.038301</td>\n",
              "      <td>0.039601</td>\n",
              "      <td>0.038301</td>\n",
              "      <td>0.040044</td>\n",
              "      <td>0.039199</td>\n",
              "      <td>0.038388</td>\n",
              "      <td>0.038388</td>\n",
              "      <td>0.038388</td>\n",
              "      <td>0.038388</td>\n",
              "      <td>...</td>\n",
              "      <td>11.596551</td>\n",
              "      <td>2.781970</td>\n",
              "      <td>307.252039</td>\n",
              "      <td>4.529620</td>\n",
              "      <td>23.415205</td>\n",
              "      <td>4.090860</td>\n",
              "      <td>26.750733</td>\n",
              "      <td>209.303607</td>\n",
              "      <td>-0.005604</td>\n",
              "      <td>0.038529</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-02-03</th>\n",
              "      <td>0.037979</td>\n",
              "      <td>0.038355</td>\n",
              "      <td>0.037979</td>\n",
              "      <td>0.038355</td>\n",
              "      <td>0.041000</td>\n",
              "      <td>0.040608</td>\n",
              "      <td>0.038633</td>\n",
              "      <td>0.038633</td>\n",
              "      <td>0.038633</td>\n",
              "      <td>0.038633</td>\n",
              "      <td>...</td>\n",
              "      <td>11.596551</td>\n",
              "      <td>2.799436</td>\n",
              "      <td>311.491144</td>\n",
              "      <td>4.529266</td>\n",
              "      <td>23.412659</td>\n",
              "      <td>4.119569</td>\n",
              "      <td>26.561052</td>\n",
              "      <td>209.303607</td>\n",
              "      <td>-0.008693</td>\n",
              "      <td>0.039312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-02-04</th>\n",
              "      <td>0.036791</td>\n",
              "      <td>0.037755</td>\n",
              "      <td>0.036791</td>\n",
              "      <td>0.037755</td>\n",
              "      <td>0.038214</td>\n",
              "      <td>0.040159</td>\n",
              "      <td>0.036990</td>\n",
              "      <td>0.036990</td>\n",
              "      <td>0.036990</td>\n",
              "      <td>0.036990</td>\n",
              "      <td>...</td>\n",
              "      <td>11.419775</td>\n",
              "      <td>2.728548</td>\n",
              "      <td>306.262089</td>\n",
              "      <td>4.474254</td>\n",
              "      <td>23.415452</td>\n",
              "      <td>4.106629</td>\n",
              "      <td>26.433950</td>\n",
              "      <td>209.303607</td>\n",
              "      <td>0.000572</td>\n",
              "      <td>0.037268</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-02-07</th>\n",
              "      <td>0.046593</td>\n",
              "      <td>0.055072</td>\n",
              "      <td>0.046593</td>\n",
              "      <td>0.055072</td>\n",
              "      <td>0.047968</td>\n",
              "      <td>0.057512</td>\n",
              "      <td>0.046474</td>\n",
              "      <td>0.046474</td>\n",
              "      <td>0.046474</td>\n",
              "      <td>0.046474</td>\n",
              "      <td>...</td>\n",
              "      <td>11.313708</td>\n",
              "      <td>2.733357</td>\n",
              "      <td>299.491542</td>\n",
              "      <td>4.460147</td>\n",
              "      <td>23.414391</td>\n",
              "      <td>4.140641</td>\n",
              "      <td>26.339020</td>\n",
              "      <td>209.303607</td>\n",
              "      <td>0.027307</td>\n",
              "      <td>0.043409</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-02-08</th>\n",
              "      <td>0.049131</td>\n",
              "      <td>0.041984</td>\n",
              "      <td>0.049131</td>\n",
              "      <td>0.041984</td>\n",
              "      <td>0.049560</td>\n",
              "      <td>0.042487</td>\n",
              "      <td>0.046711</td>\n",
              "      <td>0.046711</td>\n",
              "      <td>0.046711</td>\n",
              "      <td>0.046711</td>\n",
              "      <td>...</td>\n",
              "      <td>11.313708</td>\n",
              "      <td>2.730104</td>\n",
              "      <td>301.761354</td>\n",
              "      <td>4.470789</td>\n",
              "      <td>23.415982</td>\n",
              "      <td>4.142338</td>\n",
              "      <td>26.135551</td>\n",
              "      <td>209.303607</td>\n",
              "      <td>0.010478</td>\n",
              "      <td>0.049799</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-08-26</th>\n",
              "      <td>0.000120</td>\n",
              "      <td>-0.000665</td>\n",
              "      <td>0.000120</td>\n",
              "      <td>-0.000665</td>\n",
              "      <td>0.000456</td>\n",
              "      <td>-0.000424</td>\n",
              "      <td>0.000121</td>\n",
              "      <td>0.000121</td>\n",
              "      <td>0.000121</td>\n",
              "      <td>0.000121</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.002546</td>\n",
              "      <td>0.509117</td>\n",
              "      <td>-0.003041</td>\n",
              "      <td>0.005162</td>\n",
              "      <td>0.001980</td>\n",
              "      <td>-0.105925</td>\n",
              "      <td>0.404061</td>\n",
              "      <td>0.008246</td>\n",
              "      <td>0.000132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-08-27</th>\n",
              "      <td>-0.003889</td>\n",
              "      <td>-0.004798</td>\n",
              "      <td>-0.003889</td>\n",
              "      <td>-0.004798</td>\n",
              "      <td>-0.003539</td>\n",
              "      <td>-0.002953</td>\n",
              "      <td>-0.004368</td>\n",
              "      <td>-0.004368</td>\n",
              "      <td>-0.004368</td>\n",
              "      <td>-0.004368</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.002051</td>\n",
              "      <td>-0.551543</td>\n",
              "      <td>-0.001202</td>\n",
              "      <td>-0.006788</td>\n",
              "      <td>-0.001556</td>\n",
              "      <td>-0.173948</td>\n",
              "      <td>0.404061</td>\n",
              "      <td>0.009336</td>\n",
              "      <td>0.000613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-08-28</th>\n",
              "      <td>0.000280</td>\n",
              "      <td>-0.001148</td>\n",
              "      <td>0.000280</td>\n",
              "      <td>-0.001148</td>\n",
              "      <td>0.000449</td>\n",
              "      <td>-0.000383</td>\n",
              "      <td>0.000483</td>\n",
              "      <td>0.000483</td>\n",
              "      <td>0.000483</td>\n",
              "      <td>0.000483</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000849</td>\n",
              "      <td>0.247487</td>\n",
              "      <td>0.000849</td>\n",
              "      <td>0.002263</td>\n",
              "      <td>0.002051</td>\n",
              "      <td>-0.219910</td>\n",
              "      <td>0.707107</td>\n",
              "      <td>0.010307</td>\n",
              "      <td>0.000140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-08-29</th>\n",
              "      <td>-0.000182</td>\n",
              "      <td>-0.000395</td>\n",
              "      <td>-0.000182</td>\n",
              "      <td>-0.000395</td>\n",
              "      <td>-0.000122</td>\n",
              "      <td>0.000615</td>\n",
              "      <td>-0.000352</td>\n",
              "      <td>-0.000352</td>\n",
              "      <td>-0.000352</td>\n",
              "      <td>-0.000352</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.002333</td>\n",
              "      <td>-0.148492</td>\n",
              "      <td>0.002404</td>\n",
              "      <td>-0.000071</td>\n",
              "      <td>-0.000566</td>\n",
              "      <td>0.084711</td>\n",
              "      <td>-0.101015</td>\n",
              "      <td>0.005365</td>\n",
              "      <td>-0.000016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-08-30</th>\n",
              "      <td>-0.000978</td>\n",
              "      <td>-0.000269</td>\n",
              "      <td>-0.000978</td>\n",
              "      <td>-0.000269</td>\n",
              "      <td>-0.000987</td>\n",
              "      <td>0.000618</td>\n",
              "      <td>-0.000533</td>\n",
              "      <td>-0.000533</td>\n",
              "      <td>-0.000533</td>\n",
              "      <td>-0.000533</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001838</td>\n",
              "      <td>-0.685894</td>\n",
              "      <td>0.003818</td>\n",
              "      <td>0.005091</td>\n",
              "      <td>-0.002333</td>\n",
              "      <td>0.092207</td>\n",
              "      <td>-0.101015</td>\n",
              "      <td>-0.007129</td>\n",
              "      <td>0.000139</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6184 rows × 34 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7919bd76-eb9e-4599-802e-b2224329142e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7919bd76-eb9e-4599-802e-b2224329142e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7919bd76-eb9e-4599-802e-b2224329142e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d75762f7-7490-4ac2-8f58-a335e9641d7a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d75762f7-7490-4ac2-8f58-a335e9641d7a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d75762f7-7490-4ac2-8f58-a335e9641d7a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "HV_data"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split train, validation and test data"
      ],
      "metadata": {
        "id": "f31d2QX72Q-8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_data(data, target, train_end =datetime(2022, 5, 30), test_start=datetime(2022, 5, 31), test_size=0.1):\n",
        "  test_data = data.loc[test_start:]\n",
        "\n",
        "  train_val = data.loc[:train_end]\n",
        "  train_data, val_data = train_test_split(train_val, test_size=test_size, shuffle=False)\n",
        "\n",
        "  return train_data, val_data, test_data"
      ],
      "metadata": {
        "id": "3ZBlldE1h1rw"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sliding_window_transform(X, y, timesteps):\n",
        "  X_windows = []\n",
        "  y_windows = []\n",
        "  for i in range(len(X) - timesteps + 1):\n",
        "    X_window = X[i:i + timesteps]\n",
        "    y_window = y[i + timesteps - 1]\n",
        "    X_windows.append(X_window)\n",
        "    y_windows.append(y_window)\n",
        "\n",
        "  return np.array(X_windows), np.array(y_windows)"
      ],
      "metadata": {
        "id": "x-xBiOOU2LEc"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the rolling window function\n",
        "def rolling_window(df, in_sample_window_size, out_of_sample_size):\n",
        "  X, y = [], []\n",
        "  for i in range(in_sample_window_size, len(df) - out_of_sample_size):\n",
        "    X.append(df.iloc[i - in_sample_window_size:i, :-1].values)  # All features except the target column\n",
        "    y.append(df.iloc[i:i + out_of_sample_size, -1].values)  # Target column\n",
        "\n",
        "  return np.array(X), np.array(y)"
      ],
      "metadata": {
        "id": "H4oEdogIh6PT"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "x2Pa23Ux2Ynt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_mape(actual, predicted):\n",
        "  actual, predicted = np.array(actual), np.array(predicted)\n",
        "  return np.mean(np.abs((actual - predicted) / actual)) * 100"
      ],
      "metadata": {
        "id": "coiUqSlqjI50"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CCV"
      ],
      "metadata": {
        "id": "2Ak0aCvF2bqR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "daily_train, daily_val, daily_test = split_data(HV_data, 'CCV')"
      ],
      "metadata": {
        "id": "9Me1cu3q2LH6"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "in_sam_win_sz = 25\n",
        "out_sam_win_sz = 5"
      ],
      "metadata": {
        "id": "wbIoahpP-zBI"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "HV_X_train, HV_y_train = rolling_window(daily_train, in_sam_win_sz, out_sam_win_sz)\n",
        "HV_X_val, HV_y_val = rolling_window(daily_val, in_sam_win_sz, out_sam_win_sz)\n",
        "HV_X_test, HV_y_test = rolling_window(daily_test, in_sam_win_sz, out_sam_win_sz)"
      ],
      "metadata": {
        "id": "hxzzyyCR-1_m"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# HV_X_train = HV_X_train.reshape(HV_X_train.shape[0], win_sz, -1)\n",
        "# HV_X_val = HV_X_val.reshape(HV_X_val.shape[0], win_sz, -1)\n",
        "# HV_X_test = HV_X_test.reshape(HV_X_test.shape[0], win_sz, -1)"
      ],
      "metadata": {
        "id": "ns46ckgGA42H"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LSTM"
      ],
      "metadata": {
        "id": "AIQfC7oiLhnU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_garch_model = Sequential()\n",
        "lstm_garch_model.add(LSTM(48, input_shape=(HV_X_train.shape[1], HV_X_train.shape[2]), return_sequences=True))\n",
        "lstm_garch_model.add(Dropout(0.1))\n",
        "lstm_garch_model.add(LSTM(16))\n",
        "lstm_garch_model.add(Dropout(0.1))\n",
        "lstm_garch_model.add(Dense(5))\n",
        "\n",
        "lstm_garch_model.compile(optimizer=Adam(learning_rate=0.01), loss='mse')"
      ],
      "metadata": {
        "id": "Zf6h10cy1zlx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef9359ba-c1aa-4fce-cf26-0bea9b11f5a5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_garch_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "Zpm8uSZJ3ESB",
        "outputId": "5cea5f29-7eec-4752-8d66-d9b961ec6f6a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m48\u001b[0m)              │          \u001b[38;5;34m15,744\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m48\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │           \u001b[38;5;34m4,160\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │              \u001b[38;5;34m85\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">15,744</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">85</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m19,989\u001b[0m (78.08 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,989</span> (78.08 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m19,989\u001b[0m (78.08 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,989</span> (78.08 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_history = lstm_garch_model.fit(HV_X_train, HV_y_train, epochs=80, batch_size=32, validation_data=(HV_X_val, HV_y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FcrtK-L3NgU",
        "outputId": "513b89bc-32a6-418b-c557-080a6bb8024c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 33ms/step - loss: 0.0139 - val_loss: 9.0341e-06\n",
            "Epoch 2/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 28ms/step - loss: 1.8411e-04 - val_loss: 4.9880e-06\n",
            "Epoch 3/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 1.2086e-04 - val_loss: 3.3087e-06\n",
            "Epoch 4/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - loss: 1.1040e-04 - val_loss: 3.2199e-06\n",
            "Epoch 5/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - loss: 8.7245e-05 - val_loss: 4.7495e-06\n",
            "Epoch 6/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - loss: 9.3587e-05 - val_loss: 1.9687e-06\n",
            "Epoch 7/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - loss: 6.3937e-05 - val_loss: 1.7988e-06\n",
            "Epoch 8/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 7.1140e-05 - val_loss: 1.8823e-06\n",
            "Epoch 9/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - loss: 6.7853e-05 - val_loss: 1.5741e-06\n",
            "Epoch 10/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - loss: 6.9979e-05 - val_loss: 3.5597e-06\n",
            "Epoch 11/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 7.2046e-05 - val_loss: 1.6127e-06\n",
            "Epoch 12/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 27ms/step - loss: 5.9813e-05 - val_loss: 2.9666e-06\n",
            "Epoch 13/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - loss: 6.9128e-05 - val_loss: 3.0054e-06\n",
            "Epoch 14/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - loss: 7.0677e-05 - val_loss: 1.7409e-06\n",
            "Epoch 15/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - loss: 5.9199e-05 - val_loss: 5.8533e-06\n",
            "Epoch 16/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 6.9026e-05 - val_loss: 1.7933e-06\n",
            "Epoch 17/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - loss: 4.9251e-05 - val_loss: 1.8565e-06\n",
            "Epoch 18/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - loss: 6.4489e-05 - val_loss: 2.0104e-05\n",
            "Epoch 19/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 6.9111e-05 - val_loss: 2.7864e-06\n",
            "Epoch 20/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - loss: 5.5228e-05 - val_loss: 1.5844e-06\n",
            "Epoch 21/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 37ms/step - loss: 6.3453e-05 - val_loss: 5.1501e-06\n",
            "Epoch 22/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 8.3814e-05 - val_loss: 1.3355e-06\n",
            "Epoch 23/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - loss: 5.3746e-05 - val_loss: 1.4068e-06\n",
            "Epoch 24/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - loss: 4.8105e-05 - val_loss: 1.1488e-06\n",
            "Epoch 25/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - loss: 6.2731e-05 - val_loss: 8.8390e-06\n",
            "Epoch 26/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - loss: 6.4116e-05 - val_loss: 1.9428e-06\n",
            "Epoch 27/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - loss: 6.4156e-05 - val_loss: 2.4665e-06\n",
            "Epoch 28/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 6.0989e-05 - val_loss: 2.6621e-06\n",
            "Epoch 29/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 7.3264e-05 - val_loss: 9.8819e-07\n",
            "Epoch 30/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - loss: 6.4067e-05 - val_loss: 7.3569e-06\n",
            "Epoch 31/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 6.9061e-05 - val_loss: 1.0382e-06\n",
            "Epoch 32/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 6.1667e-05 - val_loss: 1.7878e-05\n",
            "Epoch 33/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 9.1421e-05 - val_loss: 2.7036e-07\n",
            "Epoch 34/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - loss: 6.5771e-05 - val_loss: 2.4555e-06\n",
            "Epoch 35/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 6.6025e-05 - val_loss: 2.1280e-06\n",
            "Epoch 36/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - loss: 6.2956e-05 - val_loss: 9.5436e-07\n",
            "Epoch 37/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - loss: 6.2538e-05 - val_loss: 1.1429e-06\n",
            "Epoch 38/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 8.5477e-05 - val_loss: 3.1695e-05\n",
            "Epoch 39/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - loss: 5.6258e-05 - val_loss: 5.1917e-06\n",
            "Epoch 40/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - loss: 6.5888e-05 - val_loss: 1.4532e-05\n",
            "Epoch 41/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 7.2270e-05 - val_loss: 1.4785e-05\n",
            "Epoch 42/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 6.8339e-05 - val_loss: 1.2926e-06\n",
            "Epoch 43/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - loss: 6.9067e-05 - val_loss: 2.4193e-06\n",
            "Epoch 44/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 6.6253e-05 - val_loss: 1.8314e-05\n",
            "Epoch 45/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 7.0341e-05 - val_loss: 6.9883e-07\n",
            "Epoch 46/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - loss: 6.5801e-05 - val_loss: 1.4897e-06\n",
            "Epoch 47/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 5.9346e-05 - val_loss: 1.0429e-05\n",
            "Epoch 48/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 6.0521e-05 - val_loss: 1.4648e-05\n",
            "Epoch 49/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - loss: 6.2773e-05 - val_loss: 2.0539e-04\n",
            "Epoch 50/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - loss: 1.9158e-04 - val_loss: 2.3711e-05\n",
            "Epoch 51/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 6.6712e-05 - val_loss: 1.2075e-06\n",
            "Epoch 52/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - loss: 5.2421e-05 - val_loss: 3.8776e-06\n",
            "Epoch 53/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - loss: 6.0999e-05 - val_loss: 1.2811e-05\n",
            "Epoch 54/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 6.1818e-05 - val_loss: 4.2442e-06\n",
            "Epoch 55/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - loss: 6.7462e-05 - val_loss: 2.0552e-06\n",
            "Epoch 56/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - loss: 6.9784e-05 - val_loss: 4.3838e-06\n",
            "Epoch 57/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 5.9307e-05 - val_loss: 6.9765e-07\n",
            "Epoch 58/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 27ms/step - loss: 6.4331e-05 - val_loss: 6.5759e-07\n",
            "Epoch 59/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - loss: 5.6824e-05 - val_loss: 8.6881e-06\n",
            "Epoch 60/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 7.0177e-05 - val_loss: 7.3749e-06\n",
            "Epoch 61/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 7.3286e-05 - val_loss: 1.6149e-06\n",
            "Epoch 62/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 33ms/step - loss: 6.2792e-05 - val_loss: 9.1833e-07\n",
            "Epoch 63/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 5.9778e-05 - val_loss: 2.9225e-06\n",
            "Epoch 64/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 4.7264e-05 - val_loss: 1.3420e-05\n",
            "Epoch 65/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 35ms/step - loss: 6.4933e-05 - val_loss: 1.8265e-06\n",
            "Epoch 66/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 5.1665e-05 - val_loss: 4.3891e-06\n",
            "Epoch 67/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 6.9329e-05 - val_loss: 1.0165e-06\n",
            "Epoch 68/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 35ms/step - loss: 7.0840e-05 - val_loss: 3.5045e-06\n",
            "Epoch 69/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - loss: 5.3598e-05 - val_loss: 4.5072e-06\n",
            "Epoch 70/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - loss: 6.0717e-05 - val_loss: 9.0242e-07\n",
            "Epoch 71/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - loss: 6.7404e-05 - val_loss: 1.4000e-06\n",
            "Epoch 72/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 6.2852e-05 - val_loss: 2.9508e-06\n",
            "Epoch 73/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 5.8694e-05 - val_loss: 3.0178e-06\n",
            "Epoch 74/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - loss: 6.7538e-05 - val_loss: 4.1700e-06\n",
            "Epoch 75/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 7.0339e-05 - val_loss: 2.3034e-06\n",
            "Epoch 76/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 6.3728e-05 - val_loss: 6.2027e-07\n",
            "Epoch 77/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - loss: 4.9176e-05 - val_loss: 6.8255e-06\n",
            "Epoch 78/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - loss: 7.0025e-05 - val_loss: 1.9573e-05\n",
            "Epoch 79/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 6.2433e-05 - val_loss: 7.8635e-07\n",
            "Epoch 80/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - loss: 6.6044e-05 - val_loss: 1.9203e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions\n",
        "HV_lstm_predictions = lstm_garch_model.predict(HV_X_test)"
      ],
      "metadata": {
        "id": "A-zmdwqm_6_e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c74a7ca2-e4ee-44c2-ebf3-9d6c61bdd67f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mse = mean_squared_error(HV_y_test, HV_lstm_predictions)\n",
        "print(f'MSE: {mse}')\n",
        "\n",
        "rmse = np.sqrt(mse)\n",
        "print(f'RMSE: {rmse}')\n",
        "\n",
        "mae = mean_absolute_error(HV_y_test, HV_lstm_predictions)\n",
        "print(f'MAE: {mae}')\n",
        "\n",
        "mape = calculate_mape(HV_y_test, HV_lstm_predictions)\n",
        "print(f'MAPE: {mape}%')"
      ],
      "metadata": {
        "id": "Y8BUSWddHo1Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41576add-a3f1-4470-8420-726e7104b54e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 1.981313807535636e-06\n",
            "RMSE: 0.001407591491710445\n",
            "MAE: 0.0011690879876635556\n",
            "MAPE: 11675.706783958583%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GRU"
      ],
      "metadata": {
        "id": "UiS7McIrLmEd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gru_model = Sequential()\n",
        "gru_model.add(GRU(48, input_shape=(HV_X_train.shape[1], HV_X_train.shape[2]), return_sequences=True))\n",
        "gru_model.add(Dropout(0.1))\n",
        "gru_model.add(GRU(16))\n",
        "gru_model.add(Dropout(0.1))\n",
        "gru_model.add(Dense(5))\n",
        "\n",
        "gru_model.compile(optimizer=Adam(learning_rate=0.01), loss='mse')"
      ],
      "metadata": {
        "id": "2fd5ZZjRH2dD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13b3a6e1-6e0e-4af0-9cce-166590feaecd"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gru_model.summary()"
      ],
      "metadata": {
        "id": "fi7nCfJRL0nz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "6c5a7dc3-27da-4c2d-ad56-49a19e4e2d92"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ gru (\u001b[38;5;33mGRU\u001b[0m)                            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m48\u001b[0m)              │          \u001b[38;5;34m11,952\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m48\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_1 (\u001b[38;5;33mGRU\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │           \u001b[38;5;34m3,168\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │              \u001b[38;5;34m85\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">11,952</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,168</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">85</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m15,205\u001b[0m (59.39 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,205</span> (59.39 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m15,205\u001b[0m (59.39 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,205</span> (59.39 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gru_history = gru_model.fit(HV_X_train, HV_y_train, epochs=80, batch_size=32, validation_data=(HV_X_val, HV_y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAo9MoSmNg_1",
        "outputId": "0110a1e1-3b01-45b2-890a-cc729f9acdce"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 44ms/step - loss: 0.0892 - val_loss: 3.9494e-05\n",
            "Epoch 2/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - loss: 2.0435e-04 - val_loss: 8.1876e-06\n",
            "Epoch 3/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - loss: 1.3753e-04 - val_loss: 4.4246e-06\n",
            "Epoch 4/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 8.9880e-05 - val_loss: 2.9807e-06\n",
            "Epoch 5/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - loss: 9.2069e-05 - val_loss: 2.7315e-06\n",
            "Epoch 6/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 34ms/step - loss: 1.0107e-04 - val_loss: 2.7633e-06\n",
            "Epoch 7/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 30ms/step - loss: 8.5644e-05 - val_loss: 2.4262e-06\n",
            "Epoch 8/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 39ms/step - loss: 8.9879e-05 - val_loss: 2.2636e-06\n",
            "Epoch 9/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - loss: 7.9197e-05 - val_loss: 2.4190e-06\n",
            "Epoch 10/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 7.2458e-05 - val_loss: 1.9036e-06\n",
            "Epoch 11/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - loss: 6.5228e-05 - val_loss: 2.7332e-06\n",
            "Epoch 12/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 6.8464e-05 - val_loss: 3.2568e-06\n",
            "Epoch 13/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - loss: 6.4399e-05 - val_loss: 3.5096e-06\n",
            "Epoch 14/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - loss: 6.8747e-05 - val_loss: 2.2144e-06\n",
            "Epoch 15/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 6.2321e-05 - val_loss: 1.8972e-06\n",
            "Epoch 16/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - loss: 7.5109e-05 - val_loss: 1.8740e-06\n",
            "Epoch 17/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 43ms/step - loss: 7.2415e-05 - val_loss: 3.2100e-06\n",
            "Epoch 18/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - loss: 6.0702e-05 - val_loss: 2.5409e-06\n",
            "Epoch 19/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 46ms/step - loss: 6.8018e-05 - val_loss: 2.9446e-06\n",
            "Epoch 20/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 40ms/step - loss: 6.4875e-05 - val_loss: 3.3479e-06\n",
            "Epoch 21/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 40ms/step - loss: 5.3933e-05 - val_loss: 3.5315e-06\n",
            "Epoch 22/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - loss: 6.2948e-05 - val_loss: 6.1409e-06\n",
            "Epoch 23/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 40ms/step - loss: 5.8016e-05 - val_loss: 2.7932e-06\n",
            "Epoch 24/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - loss: 6.3037e-05 - val_loss: 3.9071e-06\n",
            "Epoch 25/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 6.6428e-05 - val_loss: 6.8851e-06\n",
            "Epoch 26/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - loss: 5.8355e-05 - val_loss: 5.8009e-06\n",
            "Epoch 27/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 6.7505e-05 - val_loss: 3.2343e-06\n",
            "Epoch 28/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - loss: 5.7004e-05 - val_loss: 2.1998e-06\n",
            "Epoch 29/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - loss: 6.4054e-05 - val_loss: 3.9384e-06\n",
            "Epoch 30/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 43ms/step - loss: 6.4029e-05 - val_loss: 1.1903e-05\n",
            "Epoch 31/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - loss: 9.2174e-05 - val_loss: 3.3232e-06\n",
            "Epoch 32/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 43ms/step - loss: 6.2917e-05 - val_loss: 4.8394e-06\n",
            "Epoch 33/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - loss: 5.6773e-05 - val_loss: 4.2769e-06\n",
            "Epoch 34/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - loss: 7.3910e-05 - val_loss: 3.7415e-06\n",
            "Epoch 35/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - loss: 6.8475e-05 - val_loss: 4.3019e-06\n",
            "Epoch 36/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - loss: 6.7081e-05 - val_loss: 2.3189e-06\n",
            "Epoch 37/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 41ms/step - loss: 7.1532e-05 - val_loss: 3.3262e-06\n",
            "Epoch 38/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - loss: 6.7963e-05 - val_loss: 6.3225e-06\n",
            "Epoch 39/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 40ms/step - loss: 6.5870e-05 - val_loss: 5.0337e-06\n",
            "Epoch 40/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - loss: 6.3336e-05 - val_loss: 3.5840e-06\n",
            "Epoch 41/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 41ms/step - loss: 6.4986e-05 - val_loss: 7.2743e-06\n",
            "Epoch 42/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - loss: 7.8852e-05 - val_loss: 6.9653e-06\n",
            "Epoch 43/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - loss: 7.9227e-05 - val_loss: 6.3424e-06\n",
            "Epoch 44/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 5.7242e-05 - val_loss: 8.6813e-06\n",
            "Epoch 45/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - loss: 7.8545e-05 - val_loss: 4.0522e-06\n",
            "Epoch 46/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - loss: 6.2705e-05 - val_loss: 2.9920e-05\n",
            "Epoch 47/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 44ms/step - loss: 6.8179e-05 - val_loss: 2.0540e-05\n",
            "Epoch 48/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - loss: 6.8664e-05 - val_loss: 3.5694e-06\n",
            "Epoch 49/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - loss: 5.7771e-05 - val_loss: 3.2923e-06\n",
            "Epoch 50/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 7.8204e-05 - val_loss: 4.8377e-06\n",
            "Epoch 51/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - loss: 6.8318e-05 - val_loss: 4.2681e-06\n",
            "Epoch 52/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 43ms/step - loss: 6.2495e-05 - val_loss: 7.9633e-05\n",
            "Epoch 53/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - loss: 8.3707e-05 - val_loss: 2.7828e-06\n",
            "Epoch 54/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 34ms/step - loss: 7.4400e-05 - val_loss: 4.2144e-05\n",
            "Epoch 55/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 30ms/step - loss: 9.4822e-05 - val_loss: 9.2156e-06\n",
            "Epoch 56/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - loss: 6.1899e-05 - val_loss: 1.2281e-05\n",
            "Epoch 57/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - loss: 7.4298e-05 - val_loss: 6.1962e-06\n",
            "Epoch 58/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - loss: 7.2880e-05 - val_loss: 4.9931e-06\n",
            "Epoch 59/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - loss: 6.8375e-05 - val_loss: 8.5243e-06\n",
            "Epoch 60/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 44ms/step - loss: 7.0325e-05 - val_loss: 1.1634e-05\n",
            "Epoch 61/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - loss: 7.0407e-05 - val_loss: 4.5193e-06\n",
            "Epoch 62/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - loss: 7.3670e-05 - val_loss: 5.3642e-06\n",
            "Epoch 63/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 7.2618e-05 - val_loss: 3.5194e-06\n",
            "Epoch 64/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - loss: 6.4917e-05 - val_loss: 2.3947e-05\n",
            "Epoch 65/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - loss: 8.0486e-05 - val_loss: 1.1869e-05\n",
            "Epoch 66/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 7.4826e-05 - val_loss: 1.4041e-04\n",
            "Epoch 67/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - loss: 1.1391e-04 - val_loss: 1.0110e-05\n",
            "Epoch 68/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - loss: 9.5141e-05 - val_loss: 2.2975e-06\n",
            "Epoch 69/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 30ms/step - loss: 6.1278e-05 - val_loss: 2.8849e-06\n",
            "Epoch 70/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - loss: 7.0056e-05 - val_loss: 6.6223e-06\n",
            "Epoch 71/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - loss: 6.7361e-05 - val_loss: 7.8559e-06\n",
            "Epoch 72/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 6.0171e-05 - val_loss: 6.6922e-05\n",
            "Epoch 73/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - loss: 7.2764e-05 - val_loss: 1.7690e-06\n",
            "Epoch 74/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 5.3216e-05 - val_loss: 2.5052e-06\n",
            "Epoch 75/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - loss: 6.8284e-05 - val_loss: 2.4422e-06\n",
            "Epoch 76/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 42ms/step - loss: 7.2001e-05 - val_loss: 6.0644e-06\n",
            "Epoch 77/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - loss: 8.8974e-05 - val_loss: 8.1278e-06\n",
            "Epoch 78/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - loss: 7.1713e-05 - val_loss: 2.6826e-06\n",
            "Epoch 79/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 4.5991e-05 - val_loss: 5.2936e-05\n",
            "Epoch 80/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - loss: 6.7350e-05 - val_loss: 1.5806e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions\n",
        "HV_gru_predictions = gru_model.predict(HV_X_test)"
      ],
      "metadata": {
        "id": "jed591XqNhSM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6af1e084-8b7b-40aa-b460-6d4f95f99c6f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mse = mean_squared_error(HV_y_test, HV_gru_predictions)\n",
        "print(f'MSE: {mse}')\n",
        "\n",
        "rmse = np.sqrt(mse)\n",
        "print(f'RMSE: {rmse}')\n",
        "\n",
        "mae = mean_absolute_error(HV_y_test, HV_gru_predictions)\n",
        "print(f'MAE: {mae}')\n",
        "\n",
        "mape = calculate_mape(HV_y_test, HV_gru_predictions)\n",
        "print(f'MAPE: {mape}%')"
      ],
      "metadata": {
        "id": "WeZeC001NhcB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f99a345-6642-4786-cb33-c87321af7189"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 1.5650252823252884e-05\n",
            "RMSE: 0.003956040043181171\n",
            "MAE: 0.0037157592221555924\n",
            "MAPE: 36377.196991913086%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LSTM_GRU"
      ],
      "metadata": {
        "id": "b1e3A5gvPzR6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_gru_model = Sequential()\n",
        "lstm_gru_model.add(LSTM(48, input_shape=(HV_X_train.shape[1], HV_X_train.shape[2]), return_sequences=True))\n",
        "lstm_gru_model.add(Dropout(0.1))\n",
        "lstm_gru_model.add(GRU(16))\n",
        "lstm_gru_model.add(Dropout(0.1))\n",
        "lstm_gru_model.add(Dense(5))\n",
        "\n",
        "lstm_gru_model.compile(optimizer=Adam(learning_rate=0.01), loss='mse')"
      ],
      "metadata": {
        "id": "M4sDHB06Nhfb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86972d9d-b7ec-47f4-d1e3-e63a1954de59"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_gru_model.summary()"
      ],
      "metadata": {
        "id": "OihmLvRzQWlV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "0dc575ce-d4f8-4405-9343-55b9bc36a5a4"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m48\u001b[0m)              │          \u001b[38;5;34m15,744\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m48\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_2 (\u001b[38;5;33mGRU\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │           \u001b[38;5;34m3,168\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │              \u001b[38;5;34m85\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">15,744</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,168</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">85</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m18,997\u001b[0m (74.21 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">18,997</span> (74.21 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m18,997\u001b[0m (74.21 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">18,997</span> (74.21 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_gru_history = lstm_gru_model.fit(HV_X_train, HV_y_train, epochs=80, batch_size=32, validation_data=(HV_X_val, HV_y_val))"
      ],
      "metadata": {
        "id": "_6UxHjRWQWnn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e50cb226-1151-4dd7-dc38-a7098d08ce7c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - loss: 0.0171 - val_loss: 2.4399e-05\n",
            "Epoch 2/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 3.2078e-04 - val_loss: 3.2629e-05\n",
            "Epoch 3/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - loss: 1.7682e-04 - val_loss: 3.9629e-06\n",
            "Epoch 4/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 40ms/step - loss: 1.2313e-04 - val_loss: 2.0971e-05\n",
            "Epoch 5/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - loss: 1.0141e-04 - val_loss: 3.9283e-06\n",
            "Epoch 6/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 9.7540e-05 - val_loss: 1.9277e-05\n",
            "Epoch 7/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 7.6769e-05 - val_loss: 9.8635e-06\n",
            "Epoch 8/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - loss: 7.5258e-05 - val_loss: 2.1794e-06\n",
            "Epoch 9/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 37ms/step - loss: 6.5678e-05 - val_loss: 1.2028e-06\n",
            "Epoch 10/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - loss: 7.5470e-05 - val_loss: 7.0458e-07\n",
            "Epoch 11/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 38ms/step - loss: 6.9784e-05 - val_loss: 1.1042e-06\n",
            "Epoch 12/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - loss: 8.2928e-05 - val_loss: 8.5920e-06\n",
            "Epoch 13/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - loss: 7.6448e-05 - val_loss: 1.4519e-06\n",
            "Epoch 14/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - loss: 6.3552e-05 - val_loss: 4.7272e-06\n",
            "Epoch 15/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - loss: 5.7935e-05 - val_loss: 5.0350e-06\n",
            "Epoch 16/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - loss: 6.8267e-05 - val_loss: 3.9963e-06\n",
            "Epoch 17/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 34ms/step - loss: 7.8275e-05 - val_loss: 9.6530e-07\n",
            "Epoch 18/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - loss: 5.0300e-05 - val_loss: 6.7191e-06\n",
            "Epoch 19/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 37ms/step - loss: 5.7890e-05 - val_loss: 2.8998e-06\n",
            "Epoch 20/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 5.5587e-05 - val_loss: 2.7356e-06\n",
            "Epoch 21/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 35ms/step - loss: 6.4199e-05 - val_loss: 9.2998e-07\n",
            "Epoch 22/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - loss: 5.4479e-05 - val_loss: 2.0941e-05\n",
            "Epoch 23/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 34ms/step - loss: 7.1578e-05 - val_loss: 1.0627e-05\n",
            "Epoch 24/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 6.1019e-05 - val_loss: 2.0334e-06\n",
            "Epoch 25/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 6.3061e-05 - val_loss: 5.0002e-06\n",
            "Epoch 26/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - loss: 6.9757e-05 - val_loss: 7.8769e-06\n",
            "Epoch 27/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - loss: 6.6297e-05 - val_loss: 7.4183e-06\n",
            "Epoch 28/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 4.9515e-05 - val_loss: 2.7248e-06\n",
            "Epoch 29/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 6.6291e-05 - val_loss: 1.2992e-06\n",
            "Epoch 30/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 6.5063e-05 - val_loss: 2.9315e-06\n",
            "Epoch 31/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 37ms/step - loss: 6.3281e-05 - val_loss: 2.2606e-06\n",
            "Epoch 32/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - loss: 6.0957e-05 - val_loss: 1.1825e-06\n",
            "Epoch 33/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 39ms/step - loss: 6.2581e-05 - val_loss: 2.0087e-05\n",
            "Epoch 34/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 6.2933e-05 - val_loss: 3.1128e-06\n",
            "Epoch 35/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 6.0615e-05 - val_loss: 1.0048e-06\n",
            "Epoch 36/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - loss: 5.9583e-05 - val_loss: 6.0862e-06\n",
            "Epoch 37/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 6.8671e-05 - val_loss: 3.2784e-06\n",
            "Epoch 38/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - loss: 6.0174e-05 - val_loss: 2.6543e-06\n",
            "Epoch 39/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 7.4302e-05 - val_loss: 2.1603e-05\n",
            "Epoch 40/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - loss: 8.0593e-05 - val_loss: 1.7825e-06\n",
            "Epoch 41/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - loss: 6.3148e-05 - val_loss: 1.6804e-05\n",
            "Epoch 42/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 4.9996e-05 - val_loss: 5.8516e-06\n",
            "Epoch 43/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 34ms/step - loss: 7.6630e-05 - val_loss: 8.7496e-06\n",
            "Epoch 44/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - loss: 6.7008e-05 - val_loss: 3.4312e-05\n",
            "Epoch 45/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 6.6531e-05 - val_loss: 1.5235e-05\n",
            "Epoch 46/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 5.6965e-05 - val_loss: 2.3916e-06\n",
            "Epoch 47/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 6.5192e-05 - val_loss: 6.2896e-06\n",
            "Epoch 48/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 38ms/step - loss: 6.9062e-05 - val_loss: 1.5666e-05\n",
            "Epoch 49/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 6.4024e-05 - val_loss: 1.1635e-06\n",
            "Epoch 50/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 6.3984e-05 - val_loss: 2.4754e-06\n",
            "Epoch 51/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 39ms/step - loss: 6.3319e-05 - val_loss: 1.3328e-06\n",
            "Epoch 52/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - loss: 5.5636e-05 - val_loss: 3.3916e-06\n",
            "Epoch 53/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 38ms/step - loss: 7.0742e-05 - val_loss: 4.4106e-06\n",
            "Epoch 54/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - loss: 5.7735e-05 - val_loss: 1.2095e-06\n",
            "Epoch 55/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 37ms/step - loss: 5.6148e-05 - val_loss: 3.1390e-05\n",
            "Epoch 56/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - loss: 6.2168e-05 - val_loss: 3.0804e-06\n",
            "Epoch 57/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 6.1705e-05 - val_loss: 2.6944e-06\n",
            "Epoch 58/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - loss: 6.7442e-05 - val_loss: 4.0726e-06\n",
            "Epoch 59/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 25ms/step - loss: 5.1266e-05 - val_loss: 3.5666e-06\n",
            "Epoch 60/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - loss: 5.5549e-05 - val_loss: 2.8493e-06\n",
            "Epoch 61/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - loss: 6.1401e-05 - val_loss: 1.4493e-05\n",
            "Epoch 62/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 7.0076e-05 - val_loss: 1.8092e-06\n",
            "Epoch 63/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 35ms/step - loss: 6.3972e-05 - val_loss: 8.0221e-06\n",
            "Epoch 64/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 6.6857e-05 - val_loss: 1.9925e-05\n",
            "Epoch 65/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 37ms/step - loss: 8.3705e-05 - val_loss: 2.7358e-06\n",
            "Epoch 66/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - loss: 6.0500e-05 - val_loss: 3.2427e-06\n",
            "Epoch 67/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 6.3650e-05 - val_loss: 2.4754e-06\n",
            "Epoch 68/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - loss: 6.8010e-05 - val_loss: 4.0786e-06\n",
            "Epoch 69/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - loss: 8.1270e-05 - val_loss: 1.0970e-06\n",
            "Epoch 70/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 6.7931e-05 - val_loss: 1.8600e-05\n",
            "Epoch 71/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - loss: 6.5748e-05 - val_loss: 7.8345e-06\n",
            "Epoch 72/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - loss: 6.7725e-05 - val_loss: 3.5424e-06\n",
            "Epoch 73/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 6.7997e-05 - val_loss: 4.0759e-06\n",
            "Epoch 74/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - loss: 6.0752e-05 - val_loss: 2.4410e-06\n",
            "Epoch 75/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 34ms/step - loss: 7.9049e-05 - val_loss: 2.3944e-06\n",
            "Epoch 76/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - loss: 6.1728e-05 - val_loss: 1.0853e-05\n",
            "Epoch 77/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - loss: 6.5771e-05 - val_loss: 4.2436e-06\n",
            "Epoch 78/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 6.3522e-05 - val_loss: 2.8959e-06\n",
            "Epoch 79/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 28ms/step - loss: 7.2459e-05 - val_loss: 2.1338e-06\n",
            "Epoch 80/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - loss: 4.8610e-05 - val_loss: 7.5907e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions\n",
        "HV_lstm_gru_predictions = lstm_gru_model.predict(HV_X_test)"
      ],
      "metadata": {
        "id": "HQLIfgQ5QWsf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a6c4a67-a911-42fd-a8ed-99c0a704f5a3"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mse = mean_squared_error(HV_y_test, HV_lstm_gru_predictions)\n",
        "print(f'MSE: {mse}')\n",
        "\n",
        "rmse = np.sqrt(mse)\n",
        "print(f'RMSE: {rmse}')\n",
        "\n",
        "mae = mean_absolute_error(HV_y_test, HV_lstm_gru_predictions)\n",
        "print(f'MAE: {mae}')\n",
        "\n",
        "mape = calculate_mape(HV_y_test, HV_lstm_gru_predictions)\n",
        "print(f'MAPE: {mape}%')"
      ],
      "metadata": {
        "id": "ieo5NKO1QWvw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20defa83-bba8-46eb-89d9-b88cf25a15a7"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 7.692500232221643e-05\n",
            "RMSE: 0.008770689957022562\n",
            "MAE: 0.008653026187063066\n",
            "MAPE: 95842.56285407873%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# path_1 = '/content/drive/MyDrive/Volatility/Predictions/GKV/'\n",
        "\n",
        "# df_pred = pd.DataFrame(HV_lstm_gru_predictions[:,0], columns=['lstm_gru_pred'])\n",
        "# filename = 'LSTM_GRU_pred.csv'\n",
        "# df_pred.to_csv(path_1 + filename)"
      ],
      "metadata": {
        "id": "JkEaO8zCvpvp"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BiLSTM"
      ],
      "metadata": {
        "id": "JgH4xoeTU2xa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bilstm_model = Sequential()\n",
        "bilstm_model.add(Bidirectional(LSTM(48, return_sequences=True), input_shape=(HV_X_train.shape[1], HV_X_train.shape[2])))\n",
        "bilstm_model.add(Dropout(0.1))\n",
        "bilstm_model.add(Bidirectional(LSTM(16)))\n",
        "bilstm_model.add(Dropout(0.1))\n",
        "bilstm_model.add(Dense(5))\n",
        "\n",
        "bilstm_model.compile(optimizer=Adam(learning_rate=0.01), loss='mse')"
      ],
      "metadata": {
        "id": "OWUQwJo7QWyz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1da3808-c7dc-4d8a-81c4-527c56c43fb8"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bilstm_model.summary()"
      ],
      "metadata": {
        "id": "HnknoIEUcfdt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "17dc2dc3-f78e-48e1-cc8d-06f528885e68"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m96\u001b[0m)              │          \u001b[38;5;34m31,488\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m96\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │          \u001b[38;5;34m14,464\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │             \u001b[38;5;34m165\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">31,488</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">14,464</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">165</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m46,117\u001b[0m (180.14 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">46,117</span> (180.14 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m46,117\u001b[0m (180.14 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">46,117</span> (180.14 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bilstm_history = bilstm_model.fit(HV_X_train, HV_y_train, epochs=80, batch_size=32, validation_data=(HV_X_val, HV_y_val))"
      ],
      "metadata": {
        "id": "4bc45pjEatbC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4ff21b9-b478-4b74-9a80-a47d0c71c204"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 45ms/step - loss: 0.0129 - val_loss: 1.4676e-05\n",
            "Epoch 2/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 51ms/step - loss: 1.4473e-04 - val_loss: 4.9899e-06\n",
            "Epoch 3/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 43ms/step - loss: 9.9396e-05 - val_loss: 2.5442e-06\n",
            "Epoch 4/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 40ms/step - loss: 9.7577e-05 - val_loss: 5.1423e-06\n",
            "Epoch 5/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 50ms/step - loss: 8.6915e-05 - val_loss: 1.6165e-06\n",
            "Epoch 6/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - loss: 8.6390e-05 - val_loss: 6.7181e-06\n",
            "Epoch 7/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 40ms/step - loss: 7.7597e-05 - val_loss: 2.4398e-06\n",
            "Epoch 8/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 56ms/step - loss: 7.2766e-05 - val_loss: 3.8500e-06\n",
            "Epoch 9/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 40ms/step - loss: 8.1579e-05 - val_loss: 5.2682e-06\n",
            "Epoch 10/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 55ms/step - loss: 6.2436e-05 - val_loss: 1.7094e-06\n",
            "Epoch 11/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 40ms/step - loss: 5.8102e-05 - val_loss: 1.5253e-06\n",
            "Epoch 12/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 57ms/step - loss: 7.1477e-05 - val_loss: 4.8820e-06\n",
            "Epoch 13/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 40ms/step - loss: 6.5066e-05 - val_loss: 1.9797e-06\n",
            "Epoch 14/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 59ms/step - loss: 5.9146e-05 - val_loss: 1.7723e-06\n",
            "Epoch 15/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 42ms/step - loss: 7.1708e-05 - val_loss: 7.5032e-07\n",
            "Epoch 16/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 42ms/step - loss: 5.6055e-05 - val_loss: 2.2101e-06\n",
            "Epoch 17/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 49ms/step - loss: 7.5335e-05 - val_loss: 1.5000e-05\n",
            "Epoch 18/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 59ms/step - loss: 5.8931e-05 - val_loss: 1.5617e-05\n",
            "Epoch 19/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 42ms/step - loss: 6.3936e-05 - val_loss: 1.3013e-06\n",
            "Epoch 20/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 58ms/step - loss: 6.0436e-05 - val_loss: 4.0683e-05\n",
            "Epoch 21/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 7.6083e-05 - val_loss: 1.6432e-06\n",
            "Epoch 22/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 61ms/step - loss: 5.5826e-05 - val_loss: 8.9464e-07\n",
            "Epoch 23/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 6.1375e-05 - val_loss: 7.2106e-07\n",
            "Epoch 24/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 41ms/step - loss: 5.7541e-05 - val_loss: 7.9062e-06\n",
            "Epoch 25/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 55ms/step - loss: 6.7645e-05 - val_loss: 3.2778e-06\n",
            "Epoch 26/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 41ms/step - loss: 5.9561e-05 - val_loss: 3.2060e-06\n",
            "Epoch 27/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 58ms/step - loss: 6.6474e-05 - val_loss: 1.7572e-06\n",
            "Epoch 28/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 6.2441e-05 - val_loss: 3.9705e-06\n",
            "Epoch 29/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 60ms/step - loss: 6.9318e-05 - val_loss: 1.6140e-04\n",
            "Epoch 30/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 1.2707e-04 - val_loss: 6.2266e-07\n",
            "Epoch 31/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 57ms/step - loss: 6.4828e-05 - val_loss: 1.2563e-06\n",
            "Epoch 32/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 6.4425e-05 - val_loss: 2.7837e-06\n",
            "Epoch 33/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 41ms/step - loss: 4.7909e-05 - val_loss: 1.6827e-06\n",
            "Epoch 34/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 58ms/step - loss: 5.6196e-05 - val_loss: 6.5713e-06\n",
            "Epoch 35/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 41ms/step - loss: 6.5086e-05 - val_loss: 8.4516e-06\n",
            "Epoch 36/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 47ms/step - loss: 6.8200e-05 - val_loss: 3.2582e-06\n",
            "Epoch 37/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 59ms/step - loss: 6.4966e-05 - val_loss: 4.3893e-06\n",
            "Epoch 38/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 5.8568e-05 - val_loss: 3.4965e-06\n",
            "Epoch 39/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 59ms/step - loss: 5.7935e-05 - val_loss: 7.2490e-06\n",
            "Epoch 40/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 43ms/step - loss: 5.9770e-05 - val_loss: 7.0982e-06\n",
            "Epoch 41/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 61ms/step - loss: 7.8708e-05 - val_loss: 3.5957e-05\n",
            "Epoch 42/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 49ms/step - loss: 7.2175e-05 - val_loss: 2.1508e-06\n",
            "Epoch 43/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 48ms/step - loss: 5.0986e-05 - val_loss: 3.1577e-06\n",
            "Epoch 44/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 63ms/step - loss: 6.7155e-05 - val_loss: 1.1916e-06\n",
            "Epoch 45/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 61ms/step - loss: 5.2783e-05 - val_loss: 3.2372e-06\n",
            "Epoch 46/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 43ms/step - loss: 6.4892e-05 - val_loss: 5.1817e-07\n",
            "Epoch 47/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - loss: 6.4925e-05 - val_loss: 2.9781e-05\n",
            "Epoch 48/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 45ms/step - loss: 9.5414e-05 - val_loss: 6.2211e-06\n",
            "Epoch 49/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 56ms/step - loss: 6.9536e-05 - val_loss: 4.8294e-06\n",
            "Epoch 50/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 57ms/step - loss: 6.6135e-05 - val_loss: 8.2975e-06\n",
            "Epoch 51/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 42ms/step - loss: 5.6444e-05 - val_loss: 1.1006e-05\n",
            "Epoch 52/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 58ms/step - loss: 6.5187e-05 - val_loss: 6.4596e-07\n",
            "Epoch 53/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 42ms/step - loss: 5.9923e-05 - val_loss: 8.8214e-06\n",
            "Epoch 54/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 47ms/step - loss: 6.7011e-05 - val_loss: 3.8639e-07\n",
            "Epoch 55/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 61ms/step - loss: 5.1015e-05 - val_loss: 9.4343e-06\n",
            "Epoch 56/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 46ms/step - loss: 6.5582e-05 - val_loss: 7.4602e-07\n",
            "Epoch 57/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 58ms/step - loss: 8.1844e-05 - val_loss: 3.1032e-06\n",
            "Epoch 58/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 43ms/step - loss: 6.9933e-05 - val_loss: 3.0911e-06\n",
            "Epoch 59/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 41ms/step - loss: 6.9708e-05 - val_loss: 6.0234e-06\n",
            "Epoch 60/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 50ms/step - loss: 6.6789e-05 - val_loss: 7.1994e-05\n",
            "Epoch 61/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - loss: 8.8301e-05 - val_loss: 2.7202e-06\n",
            "Epoch 62/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 52ms/step - loss: 6.1226e-05 - val_loss: 1.0138e-06\n",
            "Epoch 63/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 50ms/step - loss: 5.8330e-05 - val_loss: 5.0399e-07\n",
            "Epoch 64/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 42ms/step - loss: 5.7811e-05 - val_loss: 3.0648e-06\n",
            "Epoch 65/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 52ms/step - loss: 6.8808e-05 - val_loss: 9.3466e-06\n",
            "Epoch 66/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - loss: 6.1304e-05 - val_loss: 1.1783e-06\n",
            "Epoch 67/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 42ms/step - loss: 5.4133e-05 - val_loss: 1.5279e-06\n",
            "Epoch 68/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 51ms/step - loss: 6.5110e-05 - val_loss: 1.2806e-06\n",
            "Epoch 69/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 53ms/step - loss: 7.2246e-05 - val_loss: 1.7907e-06\n",
            "Epoch 70/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 42ms/step - loss: 5.6548e-05 - val_loss: 1.0341e-06\n",
            "Epoch 71/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 53ms/step - loss: 6.4707e-05 - val_loss: 3.0781e-06\n",
            "Epoch 72/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 55ms/step - loss: 7.5294e-05 - val_loss: 2.4533e-06\n",
            "Epoch 73/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 42ms/step - loss: 7.7858e-05 - val_loss: 6.3291e-06\n",
            "Epoch 74/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 51ms/step - loss: 6.1243e-05 - val_loss: 5.4521e-07\n",
            "Epoch 75/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 59ms/step - loss: 7.3613e-05 - val_loss: 6.0906e-06\n",
            "Epoch 76/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 42ms/step - loss: 6.8374e-05 - val_loss: 1.7498e-06\n",
            "Epoch 77/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 51ms/step - loss: 7.1054e-05 - val_loss: 1.1413e-05\n",
            "Epoch 78/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 50ms/step - loss: 5.9218e-05 - val_loss: 1.3018e-06\n",
            "Epoch 79/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 43ms/step - loss: 7.1389e-05 - val_loss: 2.0667e-06\n",
            "Epoch 80/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 53ms/step - loss: 5.2496e-05 - val_loss: 1.7843e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions\n",
        "HV_bilstm_predictions = bilstm_model.predict(HV_X_test)"
      ],
      "metadata": {
        "id": "tSQQeKmCatdG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3060d20d-6a8d-4446-def8-55a0eb59390f"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mse = mean_squared_error(HV_y_test, HV_bilstm_predictions)\n",
        "print(f'MSE: {mse}')\n",
        "\n",
        "rmse = np.sqrt(mse)\n",
        "print(f'RMSE: {rmse}')\n",
        "\n",
        "mae = mean_absolute_error(HV_y_test, HV_bilstm_predictions)\n",
        "print(f'MAE: {mae}')\n",
        "\n",
        "mape = calculate_mape(HV_y_test, HV_bilstm_predictions)\n",
        "print(f'MAPE: {mape}%')"
      ],
      "metadata": {
        "id": "GQwOXFU3atgm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94d0aa5d-ef32-4df3-84a5-6701305dcec7"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 1.7843651030291774e-05\n",
            "RMSE: 0.00422417459751509\n",
            "MAE: 0.0033460824019105988\n",
            "MAPE: 35183.68710648045%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BiLSTM_GRU"
      ],
      "metadata": {
        "id": "b4HabdZkeZeL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bilstm_gru_model = Sequential()\n",
        "bilstm_gru_model.add(Bidirectional(LSTM(48, return_sequences=True), input_shape=(HV_X_train.shape[1], HV_X_train.shape[2])))\n",
        "bilstm_gru_model.add(Dropout(0.1))\n",
        "bilstm_gru_model.add(GRU(16))\n",
        "bilstm_gru_model.add(Dropout(0.1))\n",
        "bilstm_gru_model.add(Dense(5))\n",
        "\n",
        "bilstm_gru_model.compile(optimizer=Adam(learning_rate=0.01), loss='mse')"
      ],
      "metadata": {
        "id": "39zUotTIc80l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8aae4a29-cea9-4398-fa12-7905be84be85"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bilstm_gru_model.summary()"
      ],
      "metadata": {
        "id": "ueo7IuG1eqcL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "4596e7e0-730e-44b7-9ba6-8273540b539c"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m96\u001b[0m)              │          \u001b[38;5;34m31,488\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m96\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_3 (\u001b[38;5;33mGRU\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │           \u001b[38;5;34m5,472\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │              \u001b[38;5;34m85\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">31,488</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">5,472</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">85</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m37,045\u001b[0m (144.71 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">37,045</span> (144.71 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m37,045\u001b[0m (144.71 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">37,045</span> (144.71 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bilstm_gru_history = bilstm_gru_model.fit(HV_X_train, HV_y_train, epochs=80, batch_size=32, validation_data=(HV_X_val, HV_y_val))"
      ],
      "metadata": {
        "id": "UrcF0MvXeqeh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "464466fb-631f-4adb-9622-e43836ff7c9c"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 54ms/step - loss: 0.0263 - val_loss: 5.4966e-05\n",
            "Epoch 2/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - loss: 4.0683e-04 - val_loss: 5.3069e-05\n",
            "Epoch 3/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 45ms/step - loss: 1.9827e-04 - val_loss: 1.2242e-05\n",
            "Epoch 4/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 48ms/step - loss: 1.4711e-04 - val_loss: 8.9403e-06\n",
            "Epoch 5/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 40ms/step - loss: 1.0122e-04 - val_loss: 8.1192e-06\n",
            "Epoch 6/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 51ms/step - loss: 9.1022e-05 - val_loss: 1.2489e-05\n",
            "Epoch 7/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 35ms/step - loss: 1.0384e-04 - val_loss: 4.7384e-06\n",
            "Epoch 8/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 50ms/step - loss: 9.6571e-05 - val_loss: 1.6458e-06\n",
            "Epoch 9/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - loss: 7.6385e-05 - val_loss: 2.6635e-06\n",
            "Epoch 10/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 7.6997e-05 - val_loss: 1.1041e-06\n",
            "Epoch 11/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - loss: 8.2592e-05 - val_loss: 2.7193e-06\n",
            "Epoch 12/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - loss: 5.7996e-05 - val_loss: 1.8968e-06\n",
            "Epoch 13/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 50ms/step - loss: 6.2431e-05 - val_loss: 2.0485e-06\n",
            "Epoch 14/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 37ms/step - loss: 5.3408e-05 - val_loss: 1.5672e-06\n",
            "Epoch 15/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 51ms/step - loss: 5.8296e-05 - val_loss: 8.2409e-07\n",
            "Epoch 16/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 36ms/step - loss: 5.8106e-05 - val_loss: 3.6434e-06\n",
            "Epoch 17/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 52ms/step - loss: 5.5228e-05 - val_loss: 7.9969e-06\n",
            "Epoch 18/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - loss: 6.7087e-05 - val_loss: 7.9133e-07\n",
            "Epoch 19/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 52ms/step - loss: 6.4729e-05 - val_loss: 1.3781e-06\n",
            "Epoch 20/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 36ms/step - loss: 5.6552e-05 - val_loss: 2.2085e-06\n",
            "Epoch 21/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 50ms/step - loss: 5.9309e-05 - val_loss: 2.4485e-06\n",
            "Epoch 22/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 35ms/step - loss: 6.4895e-05 - val_loss: 3.3322e-06\n",
            "Epoch 23/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 51ms/step - loss: 6.9810e-05 - val_loss: 4.0857e-06\n",
            "Epoch 24/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 35ms/step - loss: 6.0972e-05 - val_loss: 1.2624e-06\n",
            "Epoch 25/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 51ms/step - loss: 5.7488e-05 - val_loss: 3.8567e-06\n",
            "Epoch 26/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - loss: 6.0101e-05 - val_loss: 1.5142e-05\n",
            "Epoch 27/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - loss: 7.8789e-05 - val_loss: 2.6861e-06\n",
            "Epoch 28/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 37ms/step - loss: 5.6827e-05 - val_loss: 6.5436e-06\n",
            "Epoch 29/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - loss: 5.4024e-05 - val_loss: 1.1959e-06\n",
            "Epoch 30/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 49ms/step - loss: 6.4378e-05 - val_loss: 1.2456e-05\n",
            "Epoch 31/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 35ms/step - loss: 5.8685e-05 - val_loss: 8.3709e-06\n",
            "Epoch 32/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 51ms/step - loss: 6.1724e-05 - val_loss: 4.5614e-06\n",
            "Epoch 33/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 35ms/step - loss: 6.3328e-05 - val_loss: 2.2125e-06\n",
            "Epoch 34/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 6.2649e-05 - val_loss: 1.9694e-06\n",
            "Epoch 35/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 40ms/step - loss: 5.3643e-05 - val_loss: 2.4655e-06\n",
            "Epoch 36/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 44ms/step - loss: 7.1883e-05 - val_loss: 2.0782e-06\n",
            "Epoch 37/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - loss: 6.7407e-05 - val_loss: 2.3527e-06\n",
            "Epoch 38/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - loss: 5.3140e-05 - val_loss: 7.5840e-06\n",
            "Epoch 39/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 45ms/step - loss: 5.7873e-05 - val_loss: 2.4742e-06\n",
            "Epoch 40/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 47ms/step - loss: 5.6357e-05 - val_loss: 2.8366e-06\n",
            "Epoch 41/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 40ms/step - loss: 5.6076e-05 - val_loss: 8.9540e-07\n",
            "Epoch 42/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - loss: 5.1208e-05 - val_loss: 5.3352e-07\n",
            "Epoch 43/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 37ms/step - loss: 6.1002e-05 - val_loss: 8.9547e-06\n",
            "Epoch 44/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 54ms/step - loss: 7.6572e-05 - val_loss: 3.1959e-06\n",
            "Epoch 45/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 37ms/step - loss: 6.8291e-05 - val_loss: 1.7707e-06\n",
            "Epoch 46/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 52ms/step - loss: 7.5582e-05 - val_loss: 3.5524e-06\n",
            "Epoch 47/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 38ms/step - loss: 7.2259e-05 - val_loss: 6.2372e-06\n",
            "Epoch 48/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 53ms/step - loss: 6.4589e-05 - val_loss: 1.5659e-06\n",
            "Epoch 49/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - loss: 5.1065e-05 - val_loss: 3.2517e-05\n",
            "Epoch 50/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 53ms/step - loss: 8.4049e-05 - val_loss: 1.7233e-06\n",
            "Epoch 51/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 37ms/step - loss: 6.2525e-05 - val_loss: 6.7815e-05\n",
            "Epoch 52/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 51ms/step - loss: 7.1769e-05 - val_loss: 9.8314e-06\n",
            "Epoch 53/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 46ms/step - loss: 6.5015e-05 - val_loss: 1.4027e-06\n",
            "Epoch 54/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 46ms/step - loss: 5.8603e-05 - val_loss: 1.1576e-05\n",
            "Epoch 55/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 49ms/step - loss: 6.0903e-05 - val_loss: 1.6674e-06\n",
            "Epoch 56/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 37ms/step - loss: 6.4229e-05 - val_loss: 1.5786e-06\n",
            "Epoch 57/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 6.6984e-05 - val_loss: 1.1165e-06\n",
            "Epoch 58/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 43ms/step - loss: 7.8333e-05 - val_loss: 6.2802e-07\n",
            "Epoch 59/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 40ms/step - loss: 5.3275e-05 - val_loss: 7.5413e-06\n",
            "Epoch 60/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 56ms/step - loss: 5.4459e-05 - val_loss: 5.5324e-06\n",
            "Epoch 61/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 39ms/step - loss: 6.2993e-05 - val_loss: 1.4059e-06\n",
            "Epoch 62/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 54ms/step - loss: 5.8058e-05 - val_loss: 2.2989e-06\n",
            "Epoch 63/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 37ms/step - loss: 5.9370e-05 - val_loss: 1.9964e-06\n",
            "Epoch 64/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - loss: 6.3728e-05 - val_loss: 1.3948e-06\n",
            "Epoch 65/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 52ms/step - loss: 5.0623e-05 - val_loss: 1.5325e-06\n",
            "Epoch 66/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - loss: 6.1430e-05 - val_loss: 1.0786e-05\n",
            "Epoch 67/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 37ms/step - loss: 6.6709e-05 - val_loss: 7.3641e-07\n",
            "Epoch 68/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 43ms/step - loss: 5.5356e-05 - val_loss: 9.3173e-07\n",
            "Epoch 69/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 44ms/step - loss: 6.7616e-05 - val_loss: 1.2896e-06\n",
            "Epoch 70/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 51ms/step - loss: 5.8783e-05 - val_loss: 1.5749e-05\n",
            "Epoch 71/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - loss: 6.6449e-05 - val_loss: 1.9237e-06\n",
            "Epoch 72/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 7.5724e-05 - val_loss: 4.9505e-07\n",
            "Epoch 73/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 44ms/step - loss: 5.5378e-05 - val_loss: 5.0640e-07\n",
            "Epoch 74/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - loss: 6.4398e-05 - val_loss: 2.3841e-06\n",
            "Epoch 75/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 51ms/step - loss: 6.2873e-05 - val_loss: 6.7030e-06\n",
            "Epoch 76/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 37ms/step - loss: 6.4898e-05 - val_loss: 8.6468e-06\n",
            "Epoch 77/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 37ms/step - loss: 7.2795e-05 - val_loss: 2.1336e-06\n",
            "Epoch 78/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 7.4981e-05 - val_loss: 4.7571e-07\n",
            "Epoch 79/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 51ms/step - loss: 5.8760e-05 - val_loss: 1.1482e-05\n",
            "Epoch 80/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - loss: 6.8888e-05 - val_loss: 5.0081e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions\n",
        "HV_bilstm_gru_predictions = bilstm_gru_model.predict(HV_X_test)"
      ],
      "metadata": {
        "id": "v5nF6O0HeqiA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e861389d-2232-4c51-e61b-7d82ad4d6ea7"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mse = mean_squared_error(HV_y_test, HV_bilstm_gru_predictions)\n",
        "print(f'MSE: {mse}')\n",
        "\n",
        "rmse = np.sqrt(mse)\n",
        "print(f'RMSE: {rmse}')\n",
        "\n",
        "mae = mean_absolute_error(HV_y_test, HV_bilstm_gru_predictions)\n",
        "print(f'MAE: {mae}')\n",
        "\n",
        "mape = calculate_mape(HV_y_test, HV_bilstm_gru_predictions)\n",
        "print(f'MAPE: {mape}%')"
      ],
      "metadata": {
        "id": "f61Cmfi-e2N4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da7b0e31-a09e-40a5-d6f1-8614c7cafb25"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 5.047211978356515e-06\n",
            "RMSE: 0.0022466000931088102\n",
            "MAE: 0.0016256147971412016\n",
            "MAPE: 16645.354378091197%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "54ooGu9899RS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# path_1 = '/content/drive/MyDrive/Volatility/New_data_2000_2024/New_predictions/CCV/'\n",
        "\n",
        "# df_pred = pd.DataFrame(HV_lstm_predictions[:,0], columns=['lstm_pred'])\n",
        "# filename = 'LSTM_pred.csv'\n",
        "# df_pred.to_csv(path_1 + filename)\n",
        "\n",
        "\n",
        "# df_pred = pd.DataFrame(HV_gru_predictions[:,0], columns=['gru_pred'])\n",
        "# filename = 'GRU_pred.csv'\n",
        "# df_pred.to_csv(path_1 + filename)\n",
        "\n",
        "\n",
        "# df_pred = pd.DataFrame(HV_lstm_gru_predictions[:,0], columns=['lstm_gru_pred'])\n",
        "# filename = 'LSTM_GRU_pred.csv'\n",
        "# df_pred.to_csv(path_1 + filename)\n",
        "\n",
        "\n",
        "# df_pred = pd.DataFrame(HV_bilstm_predictions[:,0], columns=['bilstm_pred'])\n",
        "# filename = 'BiLSTM_pred.csv'\n",
        "# df_pred.to_csv(path_1 + filename)\n",
        "\n",
        "\n",
        "# df_pred = pd.DataFrame(HV_bilstm_gru_predictions[:,0], columns=['bilstm_gru_pred'])\n",
        "# filename = 'BiLSTM_GRU_pred.csv'\n",
        "# df_pred.to_csv(path_1 + filename)"
      ],
      "metadata": {
        "id": "MShFf0om-AiO"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6pJVTKhB99Wl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cX3aHr7Ge2TQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}