{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "AIQfC7oiLhnU",
        "UiS7McIrLmEd",
        "b1e3A5gvPzR6",
        "b4HabdZkeZeL"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Bmw42Ki0AU8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "from google.colab import drive\n",
        "import yfinance as yf\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, GRU, Dense, Dropout, Flatten, Bidirectional\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from math import sqrt\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "path = '/content/drive/MyDrive/Volatility/New_data_2000_2024/Not_normal_wd/'"
      ],
      "metadata": {
        "id": "uif3K8sx1zgI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5d0524e-8ddf-4498-e5e6-89d0e34cf20e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def set_index(df):\n",
        "  df.index = pd.to_datetime(df['Date'])\n",
        "  df.drop(columns=['Date'], inplace=True)"
      ],
      "metadata": {
        "id": "IEBT-saF1ziO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filename = 'PV_data.csv'\n",
        "HV_data = pd.read_csv(path + filename)"
      ],
      "metadata": {
        "id": "m5XWHLl3k5d0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_index(HV_data)"
      ],
      "metadata": {
        "id": "v0I6EtnNlZ9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tm_data = HV_data"
      ],
      "metadata": {
        "id": "CTbxn5dH1-DF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "HV_data = HV_data.drop(columns=['PV'])"
      ],
      "metadata": {
        "id": "qf9pZQ2X2Egq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "HV_data['PV'] = tm_data['PV']"
      ],
      "metadata": {
        "id": "VSre9lq_2Ema"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "HV_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "id": "jXOA2Imr2ErH",
        "outputId": "a27675f9-cf7b-4a13-99be-8ba82a244bc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            ('GARCH', 'normal', 0)  ('GARCH', 'gaussian', 0)  \\\n",
              "Date                                                           \n",
              "2000-02-02                0.039601                  0.039601   \n",
              "2000-02-03                0.037979                  0.037979   \n",
              "2000-02-04                0.036791                  0.036791   \n",
              "2000-02-07                0.046593                  0.046593   \n",
              "2000-02-08                0.049131                  0.049131   \n",
              "...                            ...                       ...   \n",
              "2024-08-26                0.000120                  0.000120   \n",
              "2024-08-27               -0.003889                 -0.003889   \n",
              "2024-08-28                0.000280                  0.000280   \n",
              "2024-08-29               -0.000182                 -0.000182   \n",
              "2024-08-30               -0.000978                 -0.000978   \n",
              "\n",
              "            ('GARCH', 'ged', 0)  ('FIGARCH', 'normal', 0)  \\\n",
              "Date                                                        \n",
              "2000-02-02             0.040044                  0.038388   \n",
              "2000-02-03             0.041000                  0.038633   \n",
              "2000-02-04             0.038214                  0.036990   \n",
              "2000-02-07             0.047968                  0.046474   \n",
              "2000-02-08             0.049560                  0.046711   \n",
              "...                         ...                       ...   \n",
              "2024-08-26             0.000456                  0.000121   \n",
              "2024-08-27            -0.003539                 -0.004368   \n",
              "2024-08-28             0.000449                  0.000483   \n",
              "2024-08-29            -0.000122                 -0.000352   \n",
              "2024-08-30            -0.000987                 -0.000533   \n",
              "\n",
              "            ('FIGARCH', 'normal', 1)  ('FIGARCH', 'gaussian', 0)  \\\n",
              "Date                                                               \n",
              "2000-02-02                  0.038388                    0.038388   \n",
              "2000-02-03                  0.038633                    0.038633   \n",
              "2000-02-04                  0.036990                    0.036990   \n",
              "2000-02-07                  0.046474                    0.046474   \n",
              "2000-02-08                  0.046711                    0.046711   \n",
              "...                              ...                         ...   \n",
              "2024-08-26                  0.000121                    0.000121   \n",
              "2024-08-27                 -0.004368                   -0.004368   \n",
              "2024-08-28                  0.000483                    0.000483   \n",
              "2024-08-29                 -0.000352                   -0.000352   \n",
              "2024-08-30                 -0.000533                   -0.000533   \n",
              "\n",
              "            ('FIGARCH', 'gaussian', 1)  ('FIGARCH', 'ged', 0)  \\\n",
              "Date                                                            \n",
              "2000-02-02                    0.038388               0.038865   \n",
              "2000-02-03                    0.038633               0.040342   \n",
              "2000-02-04                    0.036990               0.039265   \n",
              "2000-02-07                    0.046474               0.048168   \n",
              "2000-02-08                    0.046711               0.045562   \n",
              "...                                ...                    ...   \n",
              "2024-08-26                    0.000121               0.000423   \n",
              "2024-08-27                   -0.004368              -0.001972   \n",
              "2024-08-28                    0.000483               0.000381   \n",
              "2024-08-29                   -0.000352              -0.002202   \n",
              "2024-08-30                   -0.000533              -0.001374   \n",
              "\n",
              "            ('FIGARCH', 'ged', 1)    gdp_growth  ...   usd_eur     usd_jpy  \\\n",
              "Date                                             ...                         \n",
              "2000-02-02               0.038865  28984.929215  ...  2.781970  307.252039   \n",
              "2000-02-03               0.040342  28984.929215  ...  2.799436  311.491144   \n",
              "2000-02-04               0.039265  28984.929215  ...  2.728548  306.262089   \n",
              "2000-02-07               0.048168  28984.929215  ...  2.733357  299.491542   \n",
              "2000-02-08               0.045562  28984.929215  ...  2.730104  301.761354   \n",
              "...                           ...           ...  ...       ...         ...   \n",
              "2024-08-26               0.000423      0.000000  ... -0.002546    0.509117   \n",
              "2024-08-27              -0.001972      0.000000  ...  0.002051   -0.551543   \n",
              "2024-08-28               0.000381      0.000000  ...  0.000849    0.247487   \n",
              "2024-08-29              -0.002202      0.000000  ...  0.002333   -0.148492   \n",
              "2024-08-30              -0.001374      0.000000  ...  0.001838   -0.685894   \n",
              "\n",
              "             usd_gbp    usd_cny   usd_cad    usd_mxn     gt_data  log_returns  \\\n",
              "Date                                                                            \n",
              "2000-02-02  4.529620  23.415205  4.090860  26.750733  209.303607    -0.005604   \n",
              "2000-02-03  4.529266  23.412659  4.119569  26.561052  209.303607    -0.008693   \n",
              "2000-02-04  4.474254  23.415452  4.106629  26.433950  209.303607     0.000572   \n",
              "2000-02-07  4.460147  23.414391  4.140641  26.339020  209.303607     0.027307   \n",
              "2000-02-08  4.470789  23.415982  4.142338  26.135551  209.303607     0.010478   \n",
              "...              ...        ...       ...        ...         ...          ...   \n",
              "2024-08-26 -0.003041   0.005162  0.001980  -0.105925    0.404061     0.008246   \n",
              "2024-08-27 -0.001202  -0.006788 -0.001556  -0.173948    0.404061     0.009336   \n",
              "2024-08-28  0.000849   0.002263  0.002051  -0.219910    0.707107     0.010307   \n",
              "2024-08-29  0.002404  -0.000071 -0.000566   0.084711   -0.101015     0.005365   \n",
              "2024-08-30  0.003818   0.005091 -0.002333   0.092207   -0.101015    -0.007129   \n",
              "\n",
              "            ('APARCH', 'studentst', 1)        PV  \n",
              "Date                                              \n",
              "2000-02-02                    0.037128  0.035334  \n",
              "2000-02-03                    0.038336  0.036011  \n",
              "2000-02-04                    0.049778  0.034207  \n",
              "2000-02-07                    0.065732  0.038502  \n",
              "2000-02-08                    0.043373  0.041434  \n",
              "...                                ...       ...  \n",
              "2024-08-26                   -0.004076  0.000011  \n",
              "2024-08-27                   -0.005604  0.000029  \n",
              "2024-08-28                   -0.001642  0.000023  \n",
              "2024-08-29                    0.000277  0.000082  \n",
              "2024-08-30                    0.000044  0.000463  \n",
              "\n",
              "[6184 rows x 32 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-69709107-9d4d-4249-8de8-eb6bd1ab3b7d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>('GARCH', 'normal', 0)</th>\n",
              "      <th>('GARCH', 'gaussian', 0)</th>\n",
              "      <th>('GARCH', 'ged', 0)</th>\n",
              "      <th>('FIGARCH', 'normal', 0)</th>\n",
              "      <th>('FIGARCH', 'normal', 1)</th>\n",
              "      <th>('FIGARCH', 'gaussian', 0)</th>\n",
              "      <th>('FIGARCH', 'gaussian', 1)</th>\n",
              "      <th>('FIGARCH', 'ged', 0)</th>\n",
              "      <th>('FIGARCH', 'ged', 1)</th>\n",
              "      <th>gdp_growth</th>\n",
              "      <th>...</th>\n",
              "      <th>usd_eur</th>\n",
              "      <th>usd_jpy</th>\n",
              "      <th>usd_gbp</th>\n",
              "      <th>usd_cny</th>\n",
              "      <th>usd_cad</th>\n",
              "      <th>usd_mxn</th>\n",
              "      <th>gt_data</th>\n",
              "      <th>log_returns</th>\n",
              "      <th>('APARCH', 'studentst', 1)</th>\n",
              "      <th>PV</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2000-02-02</th>\n",
              "      <td>0.039601</td>\n",
              "      <td>0.039601</td>\n",
              "      <td>0.040044</td>\n",
              "      <td>0.038388</td>\n",
              "      <td>0.038388</td>\n",
              "      <td>0.038388</td>\n",
              "      <td>0.038388</td>\n",
              "      <td>0.038865</td>\n",
              "      <td>0.038865</td>\n",
              "      <td>28984.929215</td>\n",
              "      <td>...</td>\n",
              "      <td>2.781970</td>\n",
              "      <td>307.252039</td>\n",
              "      <td>4.529620</td>\n",
              "      <td>23.415205</td>\n",
              "      <td>4.090860</td>\n",
              "      <td>26.750733</td>\n",
              "      <td>209.303607</td>\n",
              "      <td>-0.005604</td>\n",
              "      <td>0.037128</td>\n",
              "      <td>0.035334</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-02-03</th>\n",
              "      <td>0.037979</td>\n",
              "      <td>0.037979</td>\n",
              "      <td>0.041000</td>\n",
              "      <td>0.038633</td>\n",
              "      <td>0.038633</td>\n",
              "      <td>0.038633</td>\n",
              "      <td>0.038633</td>\n",
              "      <td>0.040342</td>\n",
              "      <td>0.040342</td>\n",
              "      <td>28984.929215</td>\n",
              "      <td>...</td>\n",
              "      <td>2.799436</td>\n",
              "      <td>311.491144</td>\n",
              "      <td>4.529266</td>\n",
              "      <td>23.412659</td>\n",
              "      <td>4.119569</td>\n",
              "      <td>26.561052</td>\n",
              "      <td>209.303607</td>\n",
              "      <td>-0.008693</td>\n",
              "      <td>0.038336</td>\n",
              "      <td>0.036011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-02-04</th>\n",
              "      <td>0.036791</td>\n",
              "      <td>0.036791</td>\n",
              "      <td>0.038214</td>\n",
              "      <td>0.036990</td>\n",
              "      <td>0.036990</td>\n",
              "      <td>0.036990</td>\n",
              "      <td>0.036990</td>\n",
              "      <td>0.039265</td>\n",
              "      <td>0.039265</td>\n",
              "      <td>28984.929215</td>\n",
              "      <td>...</td>\n",
              "      <td>2.728548</td>\n",
              "      <td>306.262089</td>\n",
              "      <td>4.474254</td>\n",
              "      <td>23.415452</td>\n",
              "      <td>4.106629</td>\n",
              "      <td>26.433950</td>\n",
              "      <td>209.303607</td>\n",
              "      <td>0.000572</td>\n",
              "      <td>0.049778</td>\n",
              "      <td>0.034207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-02-07</th>\n",
              "      <td>0.046593</td>\n",
              "      <td>0.046593</td>\n",
              "      <td>0.047968</td>\n",
              "      <td>0.046474</td>\n",
              "      <td>0.046474</td>\n",
              "      <td>0.046474</td>\n",
              "      <td>0.046474</td>\n",
              "      <td>0.048168</td>\n",
              "      <td>0.048168</td>\n",
              "      <td>28984.929215</td>\n",
              "      <td>...</td>\n",
              "      <td>2.733357</td>\n",
              "      <td>299.491542</td>\n",
              "      <td>4.460147</td>\n",
              "      <td>23.414391</td>\n",
              "      <td>4.140641</td>\n",
              "      <td>26.339020</td>\n",
              "      <td>209.303607</td>\n",
              "      <td>0.027307</td>\n",
              "      <td>0.065732</td>\n",
              "      <td>0.038502</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-02-08</th>\n",
              "      <td>0.049131</td>\n",
              "      <td>0.049131</td>\n",
              "      <td>0.049560</td>\n",
              "      <td>0.046711</td>\n",
              "      <td>0.046711</td>\n",
              "      <td>0.046711</td>\n",
              "      <td>0.046711</td>\n",
              "      <td>0.045562</td>\n",
              "      <td>0.045562</td>\n",
              "      <td>28984.929215</td>\n",
              "      <td>...</td>\n",
              "      <td>2.730104</td>\n",
              "      <td>301.761354</td>\n",
              "      <td>4.470789</td>\n",
              "      <td>23.415982</td>\n",
              "      <td>4.142338</td>\n",
              "      <td>26.135551</td>\n",
              "      <td>209.303607</td>\n",
              "      <td>0.010478</td>\n",
              "      <td>0.043373</td>\n",
              "      <td>0.041434</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-08-26</th>\n",
              "      <td>0.000120</td>\n",
              "      <td>0.000120</td>\n",
              "      <td>0.000456</td>\n",
              "      <td>0.000121</td>\n",
              "      <td>0.000121</td>\n",
              "      <td>0.000121</td>\n",
              "      <td>0.000121</td>\n",
              "      <td>0.000423</td>\n",
              "      <td>0.000423</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.002546</td>\n",
              "      <td>0.509117</td>\n",
              "      <td>-0.003041</td>\n",
              "      <td>0.005162</td>\n",
              "      <td>0.001980</td>\n",
              "      <td>-0.105925</td>\n",
              "      <td>0.404061</td>\n",
              "      <td>0.008246</td>\n",
              "      <td>-0.004076</td>\n",
              "      <td>0.000011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-08-27</th>\n",
              "      <td>-0.003889</td>\n",
              "      <td>-0.003889</td>\n",
              "      <td>-0.003539</td>\n",
              "      <td>-0.004368</td>\n",
              "      <td>-0.004368</td>\n",
              "      <td>-0.004368</td>\n",
              "      <td>-0.004368</td>\n",
              "      <td>-0.001972</td>\n",
              "      <td>-0.001972</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.002051</td>\n",
              "      <td>-0.551543</td>\n",
              "      <td>-0.001202</td>\n",
              "      <td>-0.006788</td>\n",
              "      <td>-0.001556</td>\n",
              "      <td>-0.173948</td>\n",
              "      <td>0.404061</td>\n",
              "      <td>0.009336</td>\n",
              "      <td>-0.005604</td>\n",
              "      <td>0.000029</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-08-28</th>\n",
              "      <td>0.000280</td>\n",
              "      <td>0.000280</td>\n",
              "      <td>0.000449</td>\n",
              "      <td>0.000483</td>\n",
              "      <td>0.000483</td>\n",
              "      <td>0.000483</td>\n",
              "      <td>0.000483</td>\n",
              "      <td>0.000381</td>\n",
              "      <td>0.000381</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000849</td>\n",
              "      <td>0.247487</td>\n",
              "      <td>0.000849</td>\n",
              "      <td>0.002263</td>\n",
              "      <td>0.002051</td>\n",
              "      <td>-0.219910</td>\n",
              "      <td>0.707107</td>\n",
              "      <td>0.010307</td>\n",
              "      <td>-0.001642</td>\n",
              "      <td>0.000023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-08-29</th>\n",
              "      <td>-0.000182</td>\n",
              "      <td>-0.000182</td>\n",
              "      <td>-0.000122</td>\n",
              "      <td>-0.000352</td>\n",
              "      <td>-0.000352</td>\n",
              "      <td>-0.000352</td>\n",
              "      <td>-0.000352</td>\n",
              "      <td>-0.002202</td>\n",
              "      <td>-0.002202</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.002333</td>\n",
              "      <td>-0.148492</td>\n",
              "      <td>0.002404</td>\n",
              "      <td>-0.000071</td>\n",
              "      <td>-0.000566</td>\n",
              "      <td>0.084711</td>\n",
              "      <td>-0.101015</td>\n",
              "      <td>0.005365</td>\n",
              "      <td>0.000277</td>\n",
              "      <td>0.000082</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-08-30</th>\n",
              "      <td>-0.000978</td>\n",
              "      <td>-0.000978</td>\n",
              "      <td>-0.000987</td>\n",
              "      <td>-0.000533</td>\n",
              "      <td>-0.000533</td>\n",
              "      <td>-0.000533</td>\n",
              "      <td>-0.000533</td>\n",
              "      <td>-0.001374</td>\n",
              "      <td>-0.001374</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.001838</td>\n",
              "      <td>-0.685894</td>\n",
              "      <td>0.003818</td>\n",
              "      <td>0.005091</td>\n",
              "      <td>-0.002333</td>\n",
              "      <td>0.092207</td>\n",
              "      <td>-0.101015</td>\n",
              "      <td>-0.007129</td>\n",
              "      <td>0.000044</td>\n",
              "      <td>0.000463</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6184 rows × 32 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-69709107-9d4d-4249-8de8-eb6bd1ab3b7d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-69709107-9d4d-4249-8de8-eb6bd1ab3b7d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-69709107-9d4d-4249-8de8-eb6bd1ab3b7d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4d663b93-3ee3-4a17-99d4-a359891655e9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4d663b93-3ee3-4a17-99d4-a359891655e9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4d663b93-3ee3-4a17-99d4-a359891655e9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "HV_data"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split train, validation and test data"
      ],
      "metadata": {
        "id": "f31d2QX72Q-8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_data(data, target, train_end =datetime(2022, 5, 30), test_start=datetime(2022, 5, 31), test_size=0.1):\n",
        "  test_data = data.loc[test_start:]\n",
        "\n",
        "  train_val = data.loc[:train_end]\n",
        "  train_data, val_data = train_test_split(train_val, test_size=test_size, shuffle=False)\n",
        "\n",
        "  return train_data, val_data, test_data"
      ],
      "metadata": {
        "id": "3ZBlldE1h1rw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sliding_window_transform(X, y, timesteps):\n",
        "  X_windows = []\n",
        "  y_windows = []\n",
        "  for i in range(len(X) - timesteps + 1):\n",
        "    X_window = X[i:i + timesteps]\n",
        "    y_window = y[i + timesteps - 1]\n",
        "    X_windows.append(X_window)\n",
        "    y_windows.append(y_window)\n",
        "\n",
        "  return np.array(X_windows), np.array(y_windows)"
      ],
      "metadata": {
        "id": "x-xBiOOU2LEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the rolling window function\n",
        "def rolling_window(df, in_sample_window_size, out_of_sample_size):\n",
        "  X, y = [], []\n",
        "  for i in range(in_sample_window_size, len(df) - out_of_sample_size):\n",
        "    X.append(df.iloc[i - in_sample_window_size:i, :-1].values)  # All features except the target column\n",
        "    y.append(df.iloc[i:i + out_of_sample_size, -1].values)  # Target column\n",
        "\n",
        "  return np.array(X), np.array(y)"
      ],
      "metadata": {
        "id": "H4oEdogIh6PT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "x2Pa23Ux2Ynt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_mape(actual, predicted):\n",
        "  actual, predicted = np.array(actual), np.array(predicted)\n",
        "  return np.mean(np.abs((actual - predicted) / actual)) * 100"
      ],
      "metadata": {
        "id": "coiUqSlqjI50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PV"
      ],
      "metadata": {
        "id": "2Ak0aCvF2bqR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "daily_train, daily_val, daily_test = split_data(HV_data, 'PV')"
      ],
      "metadata": {
        "id": "9Me1cu3q2LH6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "in_sam_win_sz = 25\n",
        "out_sam_win_sz = 5"
      ],
      "metadata": {
        "id": "wbIoahpP-zBI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "HV_X_train, HV_y_train = rolling_window(daily_train, in_sam_win_sz, out_sam_win_sz)\n",
        "HV_X_val, HV_y_val = rolling_window(daily_val, in_sam_win_sz, out_sam_win_sz)\n",
        "HV_X_test, HV_y_test = rolling_window(daily_test, in_sam_win_sz, out_sam_win_sz)"
      ],
      "metadata": {
        "id": "hxzzyyCR-1_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# HV_X_train = HV_X_train.reshape(HV_X_train.shape[0], win_sz, -1)\n",
        "# HV_X_val = HV_X_val.reshape(HV_X_val.shape[0], win_sz, -1)\n",
        "# HV_X_test = HV_X_test.reshape(HV_X_test.shape[0], win_sz, -1)"
      ],
      "metadata": {
        "id": "ns46ckgGA42H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LSTM"
      ],
      "metadata": {
        "id": "AIQfC7oiLhnU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_garch_model = Sequential()\n",
        "lstm_garch_model.add(LSTM(48, input_shape=(HV_X_train.shape[1], HV_X_train.shape[2]), return_sequences=True))\n",
        "lstm_garch_model.add(Dropout(0.1))\n",
        "lstm_garch_model.add(LSTM(16))\n",
        "lstm_garch_model.add(Dropout(0.1))\n",
        "lstm_garch_model.add(Dense(5))\n",
        "\n",
        "lstm_garch_model.compile(optimizer=Adam(learning_rate=0.01), loss='mse')"
      ],
      "metadata": {
        "id": "Zf6h10cy1zlx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6b3acaf-5f26-40d1-d612-1880f59e865c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_garch_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zpm8uSZJ3ESB",
        "outputId": "798ac966-d6bd-49b6-9f40-af7e8c6714d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m48\u001b[0m)              │          \u001b[38;5;34m15,360\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m48\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │           \u001b[38;5;34m4,160\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │              \u001b[38;5;34m85\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">15,360</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">85</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m19,605\u001b[0m (76.58 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,605</span> (76.58 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m19,605\u001b[0m (76.58 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,605</span> (76.58 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_history = lstm_garch_model.fit(HV_X_train, HV_y_train, epochs=80, batch_size=32, validation_data=(HV_X_val, HV_y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FcrtK-L3NgU",
        "outputId": "4b99c1f2-9846-4fad-e71e-01ca5caca7c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 37ms/step - loss: 0.0073 - val_loss: 1.0608e-05\n",
            "Epoch 2/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 1.0533e-04 - val_loss: 3.9712e-06\n",
            "Epoch 3/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 33ms/step - loss: 6.3497e-05 - val_loss: 4.1045e-06\n",
            "Epoch 4/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 23ms/step - loss: 6.5936e-05 - val_loss: 2.7905e-06\n",
            "Epoch 5/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 28ms/step - loss: 5.0899e-05 - val_loss: 1.8241e-06\n",
            "Epoch 6/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - loss: 4.2152e-05 - val_loss: 7.1404e-06\n",
            "Epoch 7/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 4.6088e-05 - val_loss: 6.5788e-07\n",
            "Epoch 8/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - loss: 4.3177e-05 - val_loss: 9.5981e-07\n",
            "Epoch 9/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - loss: 3.9228e-05 - val_loss: 1.5769e-06\n",
            "Epoch 10/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - loss: 4.2683e-05 - val_loss: 2.6218e-04\n",
            "Epoch 11/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 2.2687e-04 - val_loss: 6.8085e-07\n",
            "Epoch 12/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - loss: 3.3925e-05 - val_loss: 2.8479e-06\n",
            "Epoch 13/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 3.5397e-05 - val_loss: 9.9413e-07\n",
            "Epoch 14/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 33ms/step - loss: 3.8539e-05 - val_loss: 2.9845e-06\n",
            "Epoch 15/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 21ms/step - loss: 3.1855e-05 - val_loss: 6.1572e-06\n",
            "Epoch 16/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - loss: 3.7240e-05 - val_loss: 6.6578e-07\n",
            "Epoch 17/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - loss: 3.1872e-05 - val_loss: 3.3826e-07\n",
            "Epoch 18/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 3.4130e-05 - val_loss: 7.5720e-07\n",
            "Epoch 19/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - loss: 3.1066e-05 - val_loss: 1.7786e-06\n",
            "Epoch 20/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - loss: 2.8081e-05 - val_loss: 2.4885e-06\n",
            "Epoch 21/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 2.6580e-05 - val_loss: 2.0557e-07\n",
            "Epoch 22/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 3.1844e-05 - val_loss: 3.1223e-06\n",
            "Epoch 23/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 3.2610e-05 - val_loss: 3.5467e-06\n",
            "Epoch 24/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - loss: 3.9326e-05 - val_loss: 2.9462e-07\n",
            "Epoch 25/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 4.0404e-05 - val_loss: 2.1309e-06\n",
            "Epoch 26/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - loss: 3.5851e-05 - val_loss: 4.4916e-06\n",
            "Epoch 27/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 35ms/step - loss: 4.1428e-05 - val_loss: 1.7283e-06\n",
            "Epoch 28/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 3.2961e-05 - val_loss: 3.6833e-07\n",
            "Epoch 29/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - loss: 3.4053e-05 - val_loss: 3.8833e-06\n",
            "Epoch 30/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 3.6332e-05 - val_loss: 8.7435e-06\n",
            "Epoch 31/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 3.8333e-05 - val_loss: 2.0561e-05\n",
            "Epoch 32/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 4.0784e-05 - val_loss: 2.1073e-06\n",
            "Epoch 33/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - loss: 3.5126e-05 - val_loss: 2.2067e-05\n",
            "Epoch 34/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 4.0294e-05 - val_loss: 3.7284e-07\n",
            "Epoch 35/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - loss: 3.2060e-05 - val_loss: 2.9350e-06\n",
            "Epoch 36/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 35ms/step - loss: 3.1238e-05 - val_loss: 1.4254e-06\n",
            "Epoch 37/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 3.4759e-05 - val_loss: 3.4763e-06\n",
            "Epoch 38/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - loss: 3.6590e-05 - val_loss: 3.6719e-06\n",
            "Epoch 39/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 33ms/step - loss: 3.0528e-05 - val_loss: 4.8051e-06\n",
            "Epoch 40/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 2.9930e-05 - val_loss: 1.0448e-06\n",
            "Epoch 41/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - loss: 3.3970e-05 - val_loss: 1.2461e-05\n",
            "Epoch 42/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - loss: 3.4122e-05 - val_loss: 3.3389e-06\n",
            "Epoch 43/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 3.1574e-05 - val_loss: 7.1553e-07\n",
            "Epoch 44/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - loss: 3.0943e-05 - val_loss: 2.0593e-06\n",
            "Epoch 45/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 34ms/step - loss: 3.0055e-05 - val_loss: 3.3269e-06\n",
            "Epoch 46/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 4.1710e-05 - val_loss: 3.6954e-06\n",
            "Epoch 47/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 2.8636e-05 - val_loss: 1.8979e-06\n",
            "Epoch 48/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 33ms/step - loss: 3.4333e-05 - val_loss: 7.9184e-07\n",
            "Epoch 49/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 23ms/step - loss: 3.3789e-05 - val_loss: 2.9560e-07\n",
            "Epoch 50/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - loss: 3.2543e-05 - val_loss: 8.0902e-06\n",
            "Epoch 51/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - loss: 4.1875e-05 - val_loss: 6.0404e-07\n",
            "Epoch 52/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 3.4919e-05 - val_loss: 3.5993e-05\n",
            "Epoch 53/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - loss: 5.2844e-05 - val_loss: 2.6707e-06\n",
            "Epoch 54/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 31ms/step - loss: 3.3645e-05 - val_loss: 5.8235e-06\n",
            "Epoch 55/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 2.5687e-05 - val_loss: 1.9763e-06\n",
            "Epoch 56/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - loss: 3.2406e-05 - val_loss: 1.2684e-06\n",
            "Epoch 57/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - loss: 3.3932e-05 - val_loss: 1.5253e-06\n",
            "Epoch 58/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 3.6053e-05 - val_loss: 4.7892e-06\n",
            "Epoch 59/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 3.0515e-05 - val_loss: 2.4457e-06\n",
            "Epoch 60/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - loss: 3.5276e-05 - val_loss: 3.2595e-06\n",
            "Epoch 61/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 23ms/step - loss: 2.8021e-05 - val_loss: 2.3061e-05\n",
            "Epoch 62/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 34ms/step - loss: 4.1032e-05 - val_loss: 1.2077e-05\n",
            "Epoch 63/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 2.9827e-05 - val_loss: 7.1323e-07\n",
            "Epoch 64/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - loss: 3.7926e-05 - val_loss: 6.7359e-07\n",
            "Epoch 65/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 23ms/step - loss: 3.0929e-05 - val_loss: 1.6898e-05\n",
            "Epoch 66/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - loss: 3.8616e-05 - val_loss: 1.5596e-06\n",
            "Epoch 67/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - loss: 3.0202e-05 - val_loss: 2.5602e-06\n",
            "Epoch 68/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 4.2348e-05 - val_loss: 1.1993e-06\n",
            "Epoch 69/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 2.8727e-05 - val_loss: 1.6069e-06\n",
            "Epoch 70/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - loss: 3.3555e-05 - val_loss: 1.1364e-06\n",
            "Epoch 71/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 3.7979e-05 - val_loss: 3.3458e-06\n",
            "Epoch 72/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 3.2868e-05 - val_loss: 1.3063e-05\n",
            "Epoch 73/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 31ms/step - loss: 3.3268e-05 - val_loss: 2.4530e-07\n",
            "Epoch 74/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 4.0254e-05 - val_loss: 5.6151e-06\n",
            "Epoch 75/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 3.4364e-05 - val_loss: 3.1754e-06\n",
            "Epoch 76/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 42ms/step - loss: 3.8294e-05 - val_loss: 4.3702e-06\n",
            "Epoch 77/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 23ms/step - loss: 4.3323e-05 - val_loss: 1.3470e-06\n",
            "Epoch 78/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 3.4270e-05 - val_loss: 4.0877e-07\n",
            "Epoch 79/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - loss: 3.0063e-05 - val_loss: 1.3780e-06\n",
            "Epoch 80/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 3.7803e-05 - val_loss: 2.5724e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions\n",
        "HV_lstm_predictions = lstm_garch_model.predict(HV_X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-zmdwqm_6_e",
        "outputId": "37adcf45-2a44-4e08-ff2f-9dc8f3043219"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mse = mean_squared_error(HV_y_test, HV_lstm_predictions)\n",
        "print(f'MSE: {mse}')\n",
        "\n",
        "rmse = np.sqrt(mse)\n",
        "print(f'RMSE: {rmse}')\n",
        "\n",
        "mae = mean_absolute_error(HV_y_test, HV_lstm_predictions)\n",
        "print(f'MAE: {mae}')\n",
        "\n",
        "mape = calculate_mape(HV_y_test, HV_lstm_predictions)\n",
        "print(f'MAPE: {mape}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8BUSWddHo1Q",
        "outputId": "18a2ece4-45dd-4f3d-8f8b-754f257fe1e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 2.611688609984893e-06\n",
            "RMSE: 0.0016160719693085741\n",
            "MAE: 0.0014694676902743827\n",
            "MAPE: 6344.17074594108%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GRU"
      ],
      "metadata": {
        "id": "UiS7McIrLmEd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gru_model = Sequential()\n",
        "gru_model.add(GRU(48, input_shape=(HV_X_train.shape[1], HV_X_train.shape[2]), return_sequences=True))\n",
        "gru_model.add(Dropout(0.1))\n",
        "gru_model.add(GRU(16))\n",
        "gru_model.add(Dropout(0.1))\n",
        "gru_model.add(Dense(5))\n",
        "\n",
        "gru_model.compile(optimizer=Adam(learning_rate=0.01), loss='mse')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fd5ZZjRH2dD",
        "outputId": "4098ed25-e462-4d6b-e813-42d522c64a47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gru_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "fi7nCfJRL0nz",
        "outputId": "eeb596e8-be57-42a4-ba0b-3e73f4950292"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ gru (\u001b[38;5;33mGRU\u001b[0m)                            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m48\u001b[0m)              │          \u001b[38;5;34m11,664\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m48\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_1 (\u001b[38;5;33mGRU\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │           \u001b[38;5;34m3,168\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │              \u001b[38;5;34m85\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">11,664</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,168</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">85</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m14,917\u001b[0m (58.27 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,917</span> (58.27 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m14,917\u001b[0m (58.27 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,917</span> (58.27 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gru_history = gru_model.fit(HV_X_train, HV_y_train, epochs=80, batch_size=32, validation_data=(HV_X_val, HV_y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAo9MoSmNg_1",
        "outputId": "95ef0bc9-5971-4aee-d7e9-342e6d112c2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - loss: 0.0670 - val_loss: 6.2660e-05\n",
            "Epoch 2/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - loss: 5.8746e-04 - val_loss: 4.2085e-05\n",
            "Epoch 3/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - loss: 2.1113e-04 - val_loss: 1.8485e-05\n",
            "Epoch 4/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - loss: 1.4633e-04 - val_loss: 1.0115e-05\n",
            "Epoch 5/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 9.7844e-05 - val_loss: 6.6330e-06\n",
            "Epoch 6/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - loss: 9.6379e-05 - val_loss: 8.1706e-06\n",
            "Epoch 7/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - loss: 8.1637e-05 - val_loss: 4.4493e-06\n",
            "Epoch 8/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - loss: 6.9791e-05 - val_loss: 3.6407e-06\n",
            "Epoch 9/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - loss: 6.1209e-05 - val_loss: 3.9006e-06\n",
            "Epoch 10/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 40ms/step - loss: 5.4266e-05 - val_loss: 3.9509e-06\n",
            "Epoch 11/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - loss: 4.2961e-05 - val_loss: 3.6860e-06\n",
            "Epoch 12/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 40ms/step - loss: 5.4394e-05 - val_loss: 2.4154e-06\n",
            "Epoch 13/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - loss: 5.0394e-05 - val_loss: 2.0953e-06\n",
            "Epoch 14/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - loss: 6.6017e-05 - val_loss: 1.8553e-06\n",
            "Epoch 15/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 4.7292e-05 - val_loss: 1.9112e-06\n",
            "Epoch 16/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - loss: 4.4405e-05 - val_loss: 4.5921e-06\n",
            "Epoch 17/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - loss: 4.7427e-05 - val_loss: 1.6090e-06\n",
            "Epoch 18/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 43ms/step - loss: 3.6319e-05 - val_loss: 2.1392e-06\n",
            "Epoch 19/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - loss: 3.8741e-05 - val_loss: 4.9881e-06\n",
            "Epoch 20/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - loss: 4.3366e-05 - val_loss: 2.7403e-06\n",
            "Epoch 21/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - loss: 3.6395e-05 - val_loss: 4.1989e-06\n",
            "Epoch 22/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 38ms/step - loss: 4.4208e-05 - val_loss: 3.8024e-06\n",
            "Epoch 23/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - loss: 4.1063e-05 - val_loss: 1.0000e-05\n",
            "Epoch 24/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 43ms/step - loss: 4.3663e-05 - val_loss: 1.5769e-06\n",
            "Epoch 25/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - loss: 4.7854e-05 - val_loss: 1.7338e-06\n",
            "Epoch 26/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 41ms/step - loss: 4.2119e-05 - val_loss: 6.3144e-06\n",
            "Epoch 27/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - loss: 4.2748e-05 - val_loss: 2.1130e-06\n",
            "Epoch 28/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 40ms/step - loss: 3.6234e-05 - val_loss: 2.7271e-06\n",
            "Epoch 29/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - loss: 4.4228e-05 - val_loss: 4.5040e-06\n",
            "Epoch 30/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 3.8554e-05 - val_loss: 1.5893e-06\n",
            "Epoch 31/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - loss: 3.6292e-05 - val_loss: 3.8359e-06\n",
            "Epoch 32/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - loss: 3.8645e-05 - val_loss: 2.8875e-06\n",
            "Epoch 33/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 3.8521e-05 - val_loss: 1.2551e-06\n",
            "Epoch 34/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - loss: 3.2802e-05 - val_loss: 1.1718e-06\n",
            "Epoch 35/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - loss: 3.7994e-05 - val_loss: 4.6762e-06\n",
            "Epoch 36/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 38ms/step - loss: 4.7593e-05 - val_loss: 5.9519e-05\n",
            "Epoch 37/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - loss: 4.9597e-05 - val_loss: 4.5403e-06\n",
            "Epoch 38/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - loss: 4.4717e-05 - val_loss: 4.9821e-06\n",
            "Epoch 39/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 29ms/step - loss: 5.1403e-05 - val_loss: 1.4594e-05\n",
            "Epoch 40/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - loss: 4.3001e-05 - val_loss: 1.3927e-06\n",
            "Epoch 41/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - loss: 3.8715e-05 - val_loss: 7.2670e-06\n",
            "Epoch 42/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - loss: 4.0075e-05 - val_loss: 4.9329e-06\n",
            "Epoch 43/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - loss: 3.9656e-05 - val_loss: 1.2653e-06\n",
            "Epoch 44/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - loss: 3.4878e-05 - val_loss: 3.1961e-06\n",
            "Epoch 45/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 3.9280e-05 - val_loss: 2.9153e-06\n",
            "Epoch 46/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - loss: 3.8608e-05 - val_loss: 4.9055e-06\n",
            "Epoch 47/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - loss: 4.1047e-05 - val_loss: 5.0842e-06\n",
            "Epoch 48/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 3.6800e-05 - val_loss: 2.2134e-05\n",
            "Epoch 49/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - loss: 4.5914e-05 - val_loss: 5.4620e-06\n",
            "Epoch 50/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - loss: 3.6363e-05 - val_loss: 1.1994e-05\n",
            "Epoch 51/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 37ms/step - loss: 4.3815e-05 - val_loss: 9.0643e-06\n",
            "Epoch 52/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - loss: 3.4559e-05 - val_loss: 2.3258e-06\n",
            "Epoch 53/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - loss: 3.6542e-05 - val_loss: 2.3516e-06\n",
            "Epoch 54/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 29ms/step - loss: 3.2618e-05 - val_loss: 1.0634e-05\n",
            "Epoch 55/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 40ms/step - loss: 4.2318e-05 - val_loss: 1.3902e-05\n",
            "Epoch 56/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - loss: 3.9066e-05 - val_loss: 8.6192e-06\n",
            "Epoch 57/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 43ms/step - loss: 3.8863e-05 - val_loss: 2.0602e-05\n",
            "Epoch 58/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - loss: 4.6006e-05 - val_loss: 5.2429e-06\n",
            "Epoch 59/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - loss: 4.0959e-05 - val_loss: 3.6522e-06\n",
            "Epoch 60/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 39ms/step - loss: 3.4305e-05 - val_loss: 2.6851e-06\n",
            "Epoch 61/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - loss: 4.7580e-05 - val_loss: 1.3869e-04\n",
            "Epoch 62/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - loss: 1.1974e-04 - val_loss: 1.2009e-05\n",
            "Epoch 63/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - loss: 3.8550e-05 - val_loss: 4.8628e-06\n",
            "Epoch 64/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - loss: 3.4301e-05 - val_loss: 1.9111e-05\n",
            "Epoch 65/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - loss: 3.7996e-05 - val_loss: 2.6093e-06\n",
            "Epoch 66/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - loss: 4.9744e-05 - val_loss: 3.4319e-06\n",
            "Epoch 67/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - loss: 3.4249e-05 - val_loss: 2.4534e-06\n",
            "Epoch 68/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - loss: 4.4813e-05 - val_loss: 1.6784e-06\n",
            "Epoch 69/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - loss: 3.8226e-05 - val_loss: 1.6276e-06\n",
            "Epoch 70/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 4.0571e-05 - val_loss: 7.9551e-07\n",
            "Epoch 71/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - loss: 4.1464e-05 - val_loss: 1.5875e-06\n",
            "Epoch 72/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 41ms/step - loss: 4.1368e-05 - val_loss: 1.3553e-05\n",
            "Epoch 73/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - loss: 4.0114e-05 - val_loss: 1.7439e-05\n",
            "Epoch 74/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 40ms/step - loss: 5.8137e-05 - val_loss: 6.7510e-05\n",
            "Epoch 75/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - loss: 7.7707e-05 - val_loss: 4.0215e-06\n",
            "Epoch 76/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 3.6292e-05 - val_loss: 5.0652e-06\n",
            "Epoch 77/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - loss: 3.7613e-05 - val_loss: 1.8005e-06\n",
            "Epoch 78/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - loss: 3.8164e-05 - val_loss: 8.8909e-06\n",
            "Epoch 79/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 3.6472e-05 - val_loss: 8.1098e-06\n",
            "Epoch 80/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - loss: 3.6669e-05 - val_loss: 2.6547e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions\n",
        "HV_gru_predictions = gru_model.predict(HV_X_test)"
      ],
      "metadata": {
        "id": "jed591XqNhSM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3db06902-8e13-4e17-9836-71ad9850a833"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mse = mean_squared_error(HV_y_test, HV_gru_predictions)\n",
        "print(f'MSE: {mse}')\n",
        "\n",
        "rmse = np.sqrt(mse)\n",
        "print(f'RMSE: {rmse}')\n",
        "\n",
        "mae = mean_absolute_error(HV_y_test, HV_gru_predictions)\n",
        "print(f'MAE: {mae}')\n",
        "\n",
        "mape = calculate_mape(HV_y_test, HV_gru_predictions)\n",
        "print(f'MAPE: {mape}%')"
      ],
      "metadata": {
        "id": "WeZeC001NhcB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2888f57-ca40-4998-e244-aff0333331f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 2.8057435073858354e-06\n",
            "RMSE: 0.0016750353749655066\n",
            "MAE: 0.00133325639364019\n",
            "MAPE: 5662.25831667539%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LSTM_GRU"
      ],
      "metadata": {
        "id": "b1e3A5gvPzR6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_gru_model = Sequential()\n",
        "lstm_gru_model.add(LSTM(48, input_shape=(HV_X_train.shape[1], HV_X_train.shape[2]), return_sequences=True))\n",
        "lstm_gru_model.add(Dropout(0.1))\n",
        "lstm_gru_model.add(GRU(16))\n",
        "lstm_gru_model.add(Dropout(0.1))\n",
        "lstm_gru_model.add(Dense(5))\n",
        "\n",
        "lstm_gru_model.compile(optimizer=Adam(learning_rate=0.01), loss='mse')"
      ],
      "metadata": {
        "id": "M4sDHB06Nhfb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_gru_model.summary()"
      ],
      "metadata": {
        "id": "OihmLvRzQWlV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_gru_history = lstm_gru_model.fit(HV_X_train, HV_y_train, epochs=80, batch_size=32, validation_data=(HV_X_val, HV_y_val))"
      ],
      "metadata": {
        "id": "_6UxHjRWQWnn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d5c4a7f-d530-4a7e-db26-135133f0d7a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - loss: 0.0109 - val_loss: 2.4173e-05\n",
            "Epoch 2/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 2.6380e-04 - val_loss: 8.1992e-06\n",
            "Epoch 3/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 38ms/step - loss: 1.2662e-04 - val_loss: 3.1900e-05\n",
            "Epoch 4/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - loss: 8.9400e-05 - val_loss: 5.8371e-06\n",
            "Epoch 5/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - loss: 6.7880e-05 - val_loss: 3.4081e-06\n",
            "Epoch 6/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 24ms/step - loss: 5.5710e-05 - val_loss: 3.2129e-06\n",
            "Epoch 7/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 38ms/step - loss: 4.8164e-05 - val_loss: 1.4671e-06\n",
            "Epoch 8/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - loss: 4.1400e-05 - val_loss: 4.8812e-06\n",
            "Epoch 9/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - loss: 4.4342e-05 - val_loss: 2.2063e-06\n",
            "Epoch 10/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - loss: 4.1704e-05 - val_loss: 5.9347e-06\n",
            "Epoch 11/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - loss: 3.6976e-05 - val_loss: 6.3904e-06\n",
            "Epoch 12/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 46ms/step - loss: 3.9569e-05 - val_loss: 1.7317e-06\n",
            "Epoch 13/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - loss: 3.9292e-05 - val_loss: 2.5145e-06\n",
            "Epoch 14/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 3.7744e-05 - val_loss: 5.7864e-07\n",
            "Epoch 15/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 35ms/step - loss: 3.8267e-05 - val_loss: 1.0235e-06\n",
            "Epoch 16/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 24ms/step - loss: 3.3591e-05 - val_loss: 1.3760e-05\n",
            "Epoch 17/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 39ms/step - loss: 3.9781e-05 - val_loss: 1.5206e-06\n",
            "Epoch 18/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 3.2220e-05 - val_loss: 1.5792e-06\n",
            "Epoch 19/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 3.0181e-05 - val_loss: 2.1413e-06\n",
            "Epoch 20/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - loss: 4.3528e-05 - val_loss: 1.7359e-06\n",
            "Epoch 21/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 25ms/step - loss: 3.2471e-05 - val_loss: 2.4575e-06\n",
            "Epoch 22/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - loss: 3.8789e-05 - val_loss: 9.4711e-06\n",
            "Epoch 23/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 24ms/step - loss: 3.4490e-05 - val_loss: 3.0807e-06\n",
            "Epoch 24/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - loss: 3.6190e-05 - val_loss: 1.6829e-06\n",
            "Epoch 25/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - loss: 2.9486e-05 - val_loss: 4.2399e-06\n",
            "Epoch 26/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 2.9144e-05 - val_loss: 5.2099e-06\n",
            "Epoch 27/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 3.8803e-05 - val_loss: 2.2360e-06\n",
            "Epoch 28/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - loss: 3.2750e-05 - val_loss: 7.8514e-06\n",
            "Epoch 29/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 3.7419e-05 - val_loss: 1.7209e-06\n",
            "Epoch 30/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 3.6769e-05 - val_loss: 2.5351e-06\n",
            "Epoch 31/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - loss: 3.3875e-05 - val_loss: 1.0439e-04\n",
            "Epoch 32/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 9.1280e-05 - val_loss: 1.8872e-06\n",
            "Epoch 33/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 5.0488e-05 - val_loss: 1.9255e-05\n",
            "Epoch 34/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 37ms/step - loss: 4.6334e-05 - val_loss: 2.7122e-06\n",
            "Epoch 35/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - loss: 3.3627e-05 - val_loss: 7.5226e-06\n",
            "Epoch 36/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - loss: 4.1693e-05 - val_loss: 2.2142e-06\n",
            "Epoch 37/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - loss: 4.0570e-05 - val_loss: 4.0342e-06\n",
            "Epoch 38/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 3.3336e-05 - val_loss: 4.4437e-06\n",
            "Epoch 39/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 31ms/step - loss: 3.4813e-05 - val_loss: 6.7604e-06\n",
            "Epoch 40/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - loss: 3.9612e-05 - val_loss: 4.6534e-06\n",
            "Epoch 41/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 3.6343e-05 - val_loss: 1.7835e-05\n",
            "Epoch 42/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - loss: 4.4609e-05 - val_loss: 1.5189e-05\n",
            "Epoch 43/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - loss: 4.4806e-05 - val_loss: 6.4419e-06\n",
            "Epoch 44/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 3.2660e-05 - val_loss: 1.4206e-05\n",
            "Epoch 45/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - loss: 3.5037e-05 - val_loss: 5.3123e-06\n",
            "Epoch 46/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - loss: 3.4270e-05 - val_loss: 2.8324e-06\n",
            "Epoch 47/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 3.5278e-05 - val_loss: 5.5073e-05\n",
            "Epoch 48/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - loss: 3.8158e-05 - val_loss: 5.6216e-06\n",
            "Epoch 49/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - loss: 3.2984e-05 - val_loss: 6.9607e-06\n",
            "Epoch 50/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 3.9028e-05 - val_loss: 1.8958e-06\n",
            "Epoch 51/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - loss: 3.7642e-05 - val_loss: 2.2304e-06\n",
            "Epoch 52/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - loss: 3.5069e-05 - val_loss: 5.8883e-07\n",
            "Epoch 53/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - loss: 3.7070e-05 - val_loss: 5.4003e-06\n",
            "Epoch 54/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - loss: 4.2650e-05 - val_loss: 1.0540e-06\n",
            "Epoch 55/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - loss: 3.0590e-05 - val_loss: 2.6422e-06\n",
            "Epoch 56/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - loss: 4.4547e-05 - val_loss: 3.7957e-05\n",
            "Epoch 57/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - loss: 4.6065e-05 - val_loss: 1.3573e-06\n",
            "Epoch 58/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 3.4894e-05 - val_loss: 1.9096e-06\n",
            "Epoch 59/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - loss: 3.6055e-05 - val_loss: 4.7427e-05\n",
            "Epoch 60/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - loss: 4.4932e-05 - val_loss: 7.8961e-05\n",
            "Epoch 61/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 5.8517e-05 - val_loss: 1.3968e-06\n",
            "Epoch 62/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - loss: 3.5679e-05 - val_loss: 2.5728e-06\n",
            "Epoch 63/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 37ms/step - loss: 3.2384e-05 - val_loss: 5.6125e-06\n",
            "Epoch 64/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - loss: 3.8101e-05 - val_loss: 1.2558e-06\n",
            "Epoch 65/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 37ms/step - loss: 4.0730e-05 - val_loss: 2.1449e-06\n",
            "Epoch 66/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 2.9673e-05 - val_loss: 6.8457e-06\n",
            "Epoch 67/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - loss: 4.2543e-05 - val_loss: 1.3902e-05\n",
            "Epoch 68/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - loss: 3.5192e-05 - val_loss: 3.2934e-06\n",
            "Epoch 69/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 3.6370e-05 - val_loss: 8.8933e-06\n",
            "Epoch 70/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - loss: 4.1163e-05 - val_loss: 1.1622e-06\n",
            "Epoch 71/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 34ms/step - loss: 3.8373e-05 - val_loss: 4.2306e-06\n",
            "Epoch 72/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - loss: 3.6970e-05 - val_loss: 1.6315e-05\n",
            "Epoch 73/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 37ms/step - loss: 3.5864e-05 - val_loss: 5.2418e-06\n",
            "Epoch 74/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - loss: 3.0401e-05 - val_loss: 1.7388e-06\n",
            "Epoch 75/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - loss: 3.6463e-05 - val_loss: 2.4533e-06\n",
            "Epoch 76/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 3.0425e-05 - val_loss: 2.7855e-06\n",
            "Epoch 77/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 4.0489e-05 - val_loss: 9.7714e-06\n",
            "Epoch 78/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - loss: 3.4452e-05 - val_loss: 9.5613e-06\n",
            "Epoch 79/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - loss: 3.4001e-05 - val_loss: 1.9406e-06\n",
            "Epoch 80/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 3.2730e-05 - val_loss: 6.2777e-07\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions\n",
        "HV_lstm_gru_predictions = lstm_gru_model.predict(HV_X_test)"
      ],
      "metadata": {
        "id": "HQLIfgQ5QWsf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c89d9021-aec1-44e7-aeec-186c3c0bf9ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mse = mean_squared_error(HV_y_test, HV_lstm_gru_predictions)\n",
        "print(f'MSE: {mse}')\n",
        "\n",
        "rmse = np.sqrt(mse)\n",
        "print(f'RMSE: {rmse}')\n",
        "\n",
        "mae = mean_absolute_error(HV_y_test, HV_lstm_gru_predictions)\n",
        "print(f'MAE: {mae}')\n",
        "\n",
        "mape = calculate_mape(HV_y_test, HV_lstm_gru_predictions)\n",
        "print(f'MAPE: {mape}%')"
      ],
      "metadata": {
        "id": "ieo5NKO1QWvw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44b0c9bc-27a5-4bd9-81c9-e61921964520"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 5.578489274671656e-07\n",
            "RMSE: 0.0007468928487187205\n",
            "MAE: 0.0005493840658028756\n",
            "MAPE: 2212.6836840501746%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# path_1 = '/content/drive/MyDrive/Volatility/Predictions/PV/'\n",
        "\n",
        "# df_pred = pd.DataFrame(HV_lstm_gru_predictions[:,0], columns=['lstm_gru_pred'])\n",
        "# filename = 'LSTM_GRU_pred.csv'\n",
        "# df_pred.to_csv(path_1 + filename)"
      ],
      "metadata": {
        "id": "3J725cxrt5ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BiLSTM"
      ],
      "metadata": {
        "id": "JgH4xoeTU2xa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bilstm_model = Sequential()\n",
        "bilstm_model.add(Bidirectional(LSTM(48, return_sequences=True), input_shape=(HV_X_train.shape[1], HV_X_train.shape[2])))\n",
        "bilstm_model.add(Dropout(0.1))\n",
        "bilstm_model.add(Bidirectional(LSTM(16)))\n",
        "bilstm_model.add(Dropout(0.1))\n",
        "bilstm_model.add(Dense(5))\n",
        "\n",
        "bilstm_model.compile(optimizer=Adam(learning_rate=0.01), loss='mse')"
      ],
      "metadata": {
        "id": "OWUQwJo7QWyz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e932200-fb55-407d-ea18-c83d22da5dcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bilstm_model.summary()"
      ],
      "metadata": {
        "id": "HnknoIEUcfdt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "7c33db66-7c6d-4127-c93b-d4b4c7369678"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m96\u001b[0m)              │          \u001b[38;5;34m30,720\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m96\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │          \u001b[38;5;34m14,464\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │             \u001b[38;5;34m165\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">30,720</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">14,464</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">165</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m45,349\u001b[0m (177.14 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">45,349</span> (177.14 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m45,349\u001b[0m (177.14 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">45,349</span> (177.14 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bilstm_history = bilstm_model.fit(HV_X_train, HV_y_train, epochs=80, batch_size=32, validation_data=(HV_X_val, HV_y_val))"
      ],
      "metadata": {
        "id": "4bc45pjEatbC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a6fbbb2-d810-426f-85e4-a6b8e259169c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 44ms/step - loss: 3.4415e-05 - val_loss: 4.2823e-06\n",
            "Epoch 2/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 109ms/step - loss: 4.4700e-05 - val_loss: 1.4009e-05\n",
            "Epoch 3/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 46ms/step - loss: 4.0948e-05 - val_loss: 8.2534e-07\n",
            "Epoch 4/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 55ms/step - loss: 3.4303e-05 - val_loss: 1.6793e-06\n",
            "Epoch 5/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 39ms/step - loss: 3.0404e-05 - val_loss: 3.2688e-06\n",
            "Epoch 6/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - loss: 3.9508e-05 - val_loss: 6.1384e-06\n",
            "Epoch 7/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 54ms/step - loss: 3.7375e-05 - val_loss: 1.9906e-06\n",
            "Epoch 8/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 46ms/step - loss: 4.0867e-05 - val_loss: 5.9492e-08\n",
            "Epoch 9/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 40ms/step - loss: 3.9123e-05 - val_loss: 1.0652e-06\n",
            "Epoch 10/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 57ms/step - loss: 2.9171e-05 - val_loss: 2.3213e-05\n",
            "Epoch 11/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 39ms/step - loss: 9.2348e-05 - val_loss: 1.1478e-05\n",
            "Epoch 12/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 44ms/step - loss: 3.6645e-05 - val_loss: 4.6777e-06\n",
            "Epoch 13/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 60ms/step - loss: 4.5940e-05 - val_loss: 1.3121e-06\n",
            "Epoch 14/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 39ms/step - loss: 4.2507e-05 - val_loss: 1.2854e-06\n",
            "Epoch 15/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - loss: 4.1452e-05 - val_loss: 4.1695e-06\n",
            "Epoch 16/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 71ms/step - loss: 3.6301e-05 - val_loss: 2.3726e-06\n",
            "Epoch 17/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 55ms/step - loss: 3.5017e-05 - val_loss: 5.9335e-07\n",
            "Epoch 18/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 40ms/step - loss: 3.5301e-05 - val_loss: 2.1779e-06\n",
            "Epoch 19/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - loss: 3.6969e-05 - val_loss: 1.3203e-06\n",
            "Epoch 20/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 53ms/step - loss: 4.1338e-05 - val_loss: 8.4931e-06\n",
            "Epoch 21/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 40ms/step - loss: 3.5495e-05 - val_loss: 6.0839e-07\n",
            "Epoch 22/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 46ms/step - loss: 3.8672e-05 - val_loss: 3.3167e-06\n",
            "Epoch 23/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 45ms/step - loss: 3.7058e-05 - val_loss: 2.5276e-06\n",
            "Epoch 24/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 49ms/step - loss: 3.6943e-05 - val_loss: 1.6363e-06\n",
            "Epoch 25/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 56ms/step - loss: 4.3998e-05 - val_loss: 1.2414e-06\n",
            "Epoch 26/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 40ms/step - loss: 3.2983e-05 - val_loss: 2.0631e-06\n",
            "Epoch 27/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 54ms/step - loss: 3.3086e-05 - val_loss: 1.7194e-05\n",
            "Epoch 28/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 3.5469e-05 - val_loss: 1.7675e-06\n",
            "Epoch 29/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 57ms/step - loss: 3.7462e-05 - val_loss: 7.7498e-07\n",
            "Epoch 30/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 41ms/step - loss: 3.5290e-05 - val_loss: 1.4659e-06\n",
            "Epoch 31/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - loss: 3.7933e-05 - val_loss: 4.2628e-06\n",
            "Epoch 32/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 48ms/step - loss: 3.3222e-05 - val_loss: 5.0520e-07\n",
            "Epoch 33/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 57ms/step - loss: 3.2390e-05 - val_loss: 4.9049e-07\n",
            "Epoch 34/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 39ms/step - loss: 2.8205e-05 - val_loss: 1.4936e-06\n",
            "Epoch 35/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 46ms/step - loss: 3.4785e-05 - val_loss: 2.3488e-05\n",
            "Epoch 36/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 58ms/step - loss: 4.1345e-05 - val_loss: 1.9001e-06\n",
            "Epoch 37/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - loss: 3.4291e-05 - val_loss: 9.7340e-07\n",
            "Epoch 38/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 52ms/step - loss: 4.0449e-05 - val_loss: 1.0208e-06\n",
            "Epoch 39/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - loss: 3.6542e-05 - val_loss: 1.0637e-06\n",
            "Epoch 40/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 46ms/step - loss: 3.6518e-05 - val_loss: 7.2818e-06\n",
            "Epoch 41/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 56ms/step - loss: 3.9838e-05 - val_loss: 6.2738e-07\n",
            "Epoch 42/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 40ms/step - loss: 3.5464e-05 - val_loss: 1.6930e-06\n",
            "Epoch 43/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 40ms/step - loss: 5.1533e-05 - val_loss: 5.2817e-06\n",
            "Epoch 44/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 54ms/step - loss: 3.7891e-05 - val_loss: 7.4481e-06\n",
            "Epoch 45/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 39ms/step - loss: 3.3773e-05 - val_loss: 8.9658e-07\n",
            "Epoch 46/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 55ms/step - loss: 4.2120e-05 - val_loss: 1.0121e-05\n",
            "Epoch 47/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - loss: 4.3700e-05 - val_loss: 9.3295e-06\n",
            "Epoch 48/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 49ms/step - loss: 4.1041e-05 - val_loss: 8.3079e-07\n",
            "Epoch 49/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 57ms/step - loss: 4.6125e-05 - val_loss: 1.7651e-05\n",
            "Epoch 50/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 40ms/step - loss: 4.0158e-05 - val_loss: 2.8028e-07\n",
            "Epoch 51/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 46ms/step - loss: 3.6345e-05 - val_loss: 4.1038e-05\n",
            "Epoch 52/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 56ms/step - loss: 5.5652e-05 - val_loss: 2.3316e-06\n",
            "Epoch 53/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - loss: 4.7479e-05 - val_loss: 7.3965e-07\n",
            "Epoch 54/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 45ms/step - loss: 3.6401e-05 - val_loss: 5.5169e-06\n",
            "Epoch 55/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 55ms/step - loss: 3.4476e-05 - val_loss: 6.8803e-07\n",
            "Epoch 56/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 40ms/step - loss: 3.9072e-05 - val_loss: 6.5703e-07\n",
            "Epoch 57/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 57ms/step - loss: 4.4686e-05 - val_loss: 3.9301e-05\n",
            "Epoch 58/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 40ms/step - loss: 4.6549e-05 - val_loss: 5.8077e-07\n",
            "Epoch 59/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 40ms/step - loss: 3.1235e-05 - val_loss: 6.8840e-06\n",
            "Epoch 60/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 60ms/step - loss: 4.7241e-05 - val_loss: 2.8625e-06\n",
            "Epoch 61/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 52ms/step - loss: 2.8844e-05 - val_loss: 2.3624e-06\n",
            "Epoch 62/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 57ms/step - loss: 3.5145e-05 - val_loss: 1.2171e-06\n",
            "Epoch 63/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - loss: 2.9128e-05 - val_loss: 2.0602e-05\n",
            "Epoch 64/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 56ms/step - loss: 3.6552e-05 - val_loss: 5.7576e-07\n",
            "Epoch 65/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 41ms/step - loss: 3.1691e-05 - val_loss: 1.7486e-07\n",
            "Epoch 66/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 47ms/step - loss: 3.2818e-05 - val_loss: 4.0054e-06\n",
            "Epoch 67/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 58ms/step - loss: 3.6583e-05 - val_loss: 4.0552e-06\n",
            "Epoch 68/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 3.8246e-05 - val_loss: 7.4209e-07\n",
            "Epoch 69/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 44ms/step - loss: 3.4498e-05 - val_loss: 1.7823e-06\n",
            "Epoch 70/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 58ms/step - loss: 3.7792e-05 - val_loss: 3.2354e-07\n",
            "Epoch 71/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 41ms/step - loss: 3.4975e-05 - val_loss: 4.4246e-06\n",
            "Epoch 72/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 58ms/step - loss: 4.2298e-05 - val_loss: 4.3586e-06\n",
            "Epoch 73/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 40ms/step - loss: 3.6900e-05 - val_loss: 3.6394e-05\n",
            "Epoch 74/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 40ms/step - loss: 6.2614e-05 - val_loss: 3.9454e-06\n",
            "Epoch 75/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 52ms/step - loss: 3.7079e-05 - val_loss: 6.3938e-06\n",
            "Epoch 76/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 54ms/step - loss: 4.1052e-05 - val_loss: 1.8334e-06\n",
            "Epoch 77/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 41ms/step - loss: 4.9952e-05 - val_loss: 3.5886e-07\n",
            "Epoch 78/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 48ms/step - loss: 4.5501e-05 - val_loss: 1.1163e-06\n",
            "Epoch 79/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - loss: 4.3696e-05 - val_loss: 4.0360e-06\n",
            "Epoch 80/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 41ms/step - loss: 3.1663e-05 - val_loss: 1.0288e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions\n",
        "HV_bilstm_predictions = bilstm_model.predict(HV_X_test)"
      ],
      "metadata": {
        "id": "tSQQeKmCatdG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8cfdce1-2a02-4191-9183-7db6c329e770"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mse = mean_squared_error(HV_y_test, HV_bilstm_predictions)\n",
        "print(f'MSE: {mse}')\n",
        "\n",
        "rmse = np.sqrt(mse)\n",
        "print(f'RMSE: {rmse}')\n",
        "\n",
        "mae = mean_absolute_error(HV_y_test, HV_bilstm_predictions)\n",
        "print(f'MAE: {mae}')\n",
        "\n",
        "mape = calculate_mape(HV_y_test, HV_bilstm_predictions)\n",
        "print(f'MAPE: {mape}%')"
      ],
      "metadata": {
        "id": "GQwOXFU3atgm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb6416a5-a5a8-4573-830c-bdc7335de7b9"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 1.0247554957240659e-05\n",
            "RMSE: 0.003201180244416215\n",
            "MAE: 0.0031130404465647635\n",
            "MAPE: 13608.89820555021%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BiLSTM_GRU"
      ],
      "metadata": {
        "id": "b4HabdZkeZeL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bilstm_gru_model = Sequential()\n",
        "bilstm_gru_model.add(Bidirectional(LSTM(48, return_sequences=True), input_shape=(HV_X_train.shape[1], HV_X_train.shape[2])))\n",
        "bilstm_gru_model.add(Dropout(0.1))\n",
        "bilstm_gru_model.add(GRU(16))\n",
        "bilstm_gru_model.add(Dropout(0.1))\n",
        "bilstm_gru_model.add(Dense(5))\n",
        "\n",
        "bilstm_gru_model.compile(optimizer=Adam(learning_rate=0.01), loss='mse')"
      ],
      "metadata": {
        "id": "39zUotTIc80l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ef519bc-c05a-4aaa-acac-8cb66f5d24f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bilstm_gru_model.summary()"
      ],
      "metadata": {
        "id": "ueo7IuG1eqcL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "2723418c-787a-4f09-f6ff-7fd206f8201b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m96\u001b[0m)              │          \u001b[38;5;34m30,720\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m96\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_3 (\u001b[38;5;33mGRU\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │           \u001b[38;5;34m5,472\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │              \u001b[38;5;34m85\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">30,720</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">5,472</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">85</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m36,277\u001b[0m (141.71 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">36,277</span> (141.71 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m36,277\u001b[0m (141.71 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">36,277</span> (141.71 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bilstm_gru_history = bilstm_gru_model.fit(HV_X_train, HV_y_train, epochs=80, batch_size=32, validation_data=(HV_X_val, HV_y_val))"
      ],
      "metadata": {
        "id": "UrcF0MvXeqeh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2460c56a-e730-45e6-9ec1-a5064c4c0bdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 52ms/step - loss: 0.0323 - val_loss: 6.5646e-05\n",
            "Epoch 2/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 36ms/step - loss: 4.2718e-04 - val_loss: 4.3528e-05\n",
            "Epoch 3/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - loss: 1.5845e-04 - val_loss: 8.4139e-06\n",
            "Epoch 4/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 45ms/step - loss: 1.0029e-04 - val_loss: 9.5934e-06\n",
            "Epoch 5/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 46ms/step - loss: 6.8120e-05 - val_loss: 9.0690e-06\n",
            "Epoch 6/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 40ms/step - loss: 5.3443e-05 - val_loss: 5.7811e-06\n",
            "Epoch 7/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 51ms/step - loss: 4.5732e-05 - val_loss: 4.4138e-06\n",
            "Epoch 8/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 36ms/step - loss: 4.3909e-05 - val_loss: 2.4479e-06\n",
            "Epoch 9/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 4.5953e-05 - val_loss: 2.6581e-06\n",
            "Epoch 10/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 45ms/step - loss: 3.4843e-05 - val_loss: 2.6013e-06\n",
            "Epoch 11/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - loss: 3.8788e-05 - val_loss: 2.6350e-06\n",
            "Epoch 12/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 50ms/step - loss: 3.6026e-05 - val_loss: 3.4532e-06\n",
            "Epoch 13/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 35ms/step - loss: 4.1724e-05 - val_loss: 2.2120e-06\n",
            "Epoch 14/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 3.5846e-05 - val_loss: 1.8744e-06\n",
            "Epoch 15/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 49ms/step - loss: 4.2533e-05 - val_loss: 1.7681e-06\n",
            "Epoch 16/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 37ms/step - loss: 4.0388e-05 - val_loss: 1.7309e-06\n",
            "Epoch 17/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 37ms/step - loss: 3.9304e-05 - val_loss: 9.9401e-06\n",
            "Epoch 18/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 46ms/step - loss: 4.7340e-05 - val_loss: 1.9286e-06\n",
            "Epoch 19/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 40ms/step - loss: 3.3683e-05 - val_loss: 5.4234e-06\n",
            "Epoch 20/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 43ms/step - loss: 3.2557e-05 - val_loss: 2.2737e-06\n",
            "Epoch 21/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 45ms/step - loss: 3.6971e-05 - val_loss: 1.2711e-06\n",
            "Epoch 22/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - loss: 3.1688e-05 - val_loss: 4.2593e-06\n",
            "Epoch 23/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 49ms/step - loss: 3.3037e-05 - val_loss: 1.7834e-06\n",
            "Epoch 24/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 35ms/step - loss: 3.7633e-05 - val_loss: 1.6281e-06\n",
            "Epoch 25/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 3.7930e-05 - val_loss: 1.4168e-06\n",
            "Epoch 26/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 45ms/step - loss: 3.3578e-05 - val_loss: 9.3381e-06\n",
            "Epoch 27/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 43ms/step - loss: 3.1683e-05 - val_loss: 3.2746e-06\n",
            "Epoch 28/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 41ms/step - loss: 4.3789e-05 - val_loss: 1.5036e-06\n",
            "Epoch 29/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - loss: 3.2341e-05 - val_loss: 2.6603e-06\n",
            "Epoch 30/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 2.9057e-05 - val_loss: 2.5928e-06\n",
            "Epoch 31/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - loss: 3.6684e-05 - val_loss: 4.3157e-06\n",
            "Epoch 32/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - loss: 3.2541e-05 - val_loss: 5.7770e-06\n",
            "Epoch 33/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - loss: 3.5112e-05 - val_loss: 1.4428e-06\n",
            "Epoch 34/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 50ms/step - loss: 3.6360e-05 - val_loss: 1.2765e-06\n",
            "Epoch 35/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 35ms/step - loss: 4.9648e-05 - val_loss: 1.4212e-06\n",
            "Epoch 36/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 2.9189e-05 - val_loss: 4.8345e-06\n",
            "Epoch 37/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 43ms/step - loss: 3.1970e-05 - val_loss: 1.5731e-06\n",
            "Epoch 38/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - loss: 3.8148e-05 - val_loss: 1.2981e-06\n",
            "Epoch 39/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 4.1962e-05 - val_loss: 5.5048e-06\n",
            "Epoch 40/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 40ms/step - loss: 3.5936e-05 - val_loss: 3.2551e-05\n",
            "Epoch 41/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 45ms/step - loss: 4.3065e-05 - val_loss: 1.1719e-06\n",
            "Epoch 42/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 44ms/step - loss: 3.3158e-05 - val_loss: 6.6483e-07\n",
            "Epoch 43/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - loss: 3.6581e-05 - val_loss: 1.8744e-06\n",
            "Epoch 44/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 3.5324e-05 - val_loss: 1.8203e-05\n",
            "Epoch 45/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 3.0006e-05 - val_loss: 1.6020e-06\n",
            "Epoch 46/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - loss: 3.6744e-05 - val_loss: 9.2654e-07\n",
            "Epoch 47/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - loss: 4.0101e-05 - val_loss: 6.1113e-06\n",
            "Epoch 48/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 49ms/step - loss: 3.9808e-05 - val_loss: 1.5703e-06\n",
            "Epoch 49/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 38ms/step - loss: 3.4528e-05 - val_loss: 1.1502e-06\n",
            "Epoch 50/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 3.7433e-05 - val_loss: 2.1261e-05\n",
            "Epoch 51/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 51ms/step - loss: 4.3580e-05 - val_loss: 7.0449e-07\n",
            "Epoch 52/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 36ms/step - loss: 3.3934e-05 - val_loss: 3.5320e-06\n",
            "Epoch 53/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - loss: 3.2870e-05 - val_loss: 8.2988e-06\n",
            "Epoch 54/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 51ms/step - loss: 3.2969e-05 - val_loss: 2.5883e-06\n",
            "Epoch 55/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - loss: 3.5272e-05 - val_loss: 1.4574e-06\n",
            "Epoch 56/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 3.2411e-05 - val_loss: 9.9821e-07\n",
            "Epoch 57/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 49ms/step - loss: 3.6794e-05 - val_loss: 5.9865e-05\n",
            "Epoch 58/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - loss: 5.6574e-05 - val_loss: 6.0876e-06\n",
            "Epoch 59/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - loss: 3.5823e-05 - val_loss: 1.7292e-06\n",
            "Epoch 60/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 44ms/step - loss: 2.5813e-05 - val_loss: 5.7081e-06\n",
            "Epoch 61/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - loss: 3.1229e-05 - val_loss: 1.6470e-06\n",
            "Epoch 62/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 51ms/step - loss: 2.6916e-05 - val_loss: 1.8597e-06\n",
            "Epoch 63/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - loss: 3.9696e-05 - val_loss: 5.7819e-07\n",
            "Epoch 64/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 40ms/step - loss: 3.8595e-05 - val_loss: 6.6290e-07\n",
            "Epoch 65/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - loss: 4.0936e-05 - val_loss: 1.8812e-05\n",
            "Epoch 66/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 3.2706e-05 - val_loss: 2.3394e-06\n",
            "Epoch 67/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 48ms/step - loss: 2.8523e-05 - val_loss: 3.1168e-06\n",
            "Epoch 68/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 40ms/step - loss: 3.3492e-05 - val_loss: 2.1603e-06\n",
            "Epoch 69/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 36ms/step - loss: 2.9535e-05 - val_loss: 6.1077e-06\n",
            "Epoch 70/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - loss: 4.7400e-05 - val_loss: 5.8423e-07\n",
            "Epoch 71/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - loss: 3.4021e-05 - val_loss: 4.2849e-06\n",
            "Epoch 72/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - loss: 3.2011e-05 - val_loss: 6.7934e-07\n",
            "Epoch 73/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 51ms/step - loss: 3.3264e-05 - val_loss: 2.8045e-06\n",
            "Epoch 74/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - loss: 3.1301e-05 - val_loss: 4.5973e-07\n",
            "Epoch 75/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 50ms/step - loss: 3.4841e-05 - val_loss: 8.2305e-06\n",
            "Epoch 76/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 35ms/step - loss: 3.4545e-05 - val_loss: 1.3069e-06\n",
            "Epoch 77/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 3.1748e-05 - val_loss: 2.9563e-07\n",
            "Epoch 78/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - loss: 3.8986e-05 - val_loss: 4.9913e-06\n",
            "Epoch 79/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 49ms/step - loss: 3.8960e-05 - val_loss: 9.1257e-07\n",
            "Epoch 80/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 36ms/step - loss: 3.7127e-05 - val_loss: 4.7436e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions\n",
        "HV_bilstm_gru_predictions = bilstm_gru_model.predict(HV_X_test)"
      ],
      "metadata": {
        "id": "v5nF6O0HeqiA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d935243c-e4d9-4518-e973-ac1c182a9548"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mse = mean_squared_error(HV_y_test, HV_bilstm_gru_predictions)\n",
        "print(f'MSE: {mse}')\n",
        "\n",
        "rmse = np.sqrt(mse)\n",
        "print(f'RMSE: {rmse}')\n",
        "\n",
        "mae = mean_absolute_error(HV_y_test, HV_bilstm_gru_predictions)\n",
        "print(f'MAE: {mae}')\n",
        "\n",
        "mape = calculate_mape(HV_y_test, HV_bilstm_gru_predictions)\n",
        "print(f'MAPE: {mape}%')"
      ],
      "metadata": {
        "id": "f61Cmfi-e2N4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ebe1cdc-f150-40bb-bdc7-561cc8374e15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 4.627419194858454e-06\n",
            "RMSE: 0.002151143694609557\n",
            "MAE: 0.002051647363948764\n",
            "MAPE: 8776.591474993325%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cX3aHr7Ge2TQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# path_1 = '/content/drive/MyDrive/Volatility/New_data_2000_2024/New_predictions/PV/'\n",
        "\n",
        "# df_pred = pd.DataFrame(HV_lstm_predictions[:,0], columns=['lstm_pred'])\n",
        "# filename = 'LSTM_pred.csv'\n",
        "# df_pred.to_csv(path_1 + filename)\n",
        "\n",
        "\n",
        "# df_pred = pd.DataFrame(HV_gru_predictions[:,0], columns=['gru_pred'])\n",
        "# filename = 'GRU_pred.csv'\n",
        "# df_pred.to_csv(path_1 + filename)\n",
        "\n",
        "\n",
        "# df_pred = pd.DataFrame(HV_lstm_gru_predictions[:,0], columns=['lstm_gru_pred'])\n",
        "# filename = 'LSTM_GRU_pred.csv'\n",
        "# df_pred.to_csv(path_1 + filename)\n",
        "\n",
        "\n",
        "# df_pred = pd.DataFrame(HV_bilstm_predictions[:,0], columns=['bilstm_pred'])\n",
        "# filename = 'BiLSTM_pred.csv'\n",
        "# df_pred.to_csv(path_1 + filename)\n",
        "\n",
        "\n",
        "# df_pred = pd.DataFrame(HV_bilstm_gru_predictions[:,0], columns=['bilstm_gru_pred'])\n",
        "# filename = 'BiLSTM_GRU_pred.csv'\n",
        "# df_pred.to_csv(path_1 + filename)"
      ],
      "metadata": {
        "id": "RBJlEEnK-6Fc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r0Z2-rBy-6Hh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}