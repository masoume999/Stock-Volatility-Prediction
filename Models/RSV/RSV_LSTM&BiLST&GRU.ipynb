{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "f31d2QX72Q-8",
        "AIQfC7oiLhnU",
        "UiS7McIrLmEd",
        "b1e3A5gvPzR6"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8Bmw42Ki0AU8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "from google.colab import drive\n",
        "import yfinance as yf\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, GRU, Dense, Dropout, Flatten, Bidirectional\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from math import sqrt\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "path = '/content/drive/MyDrive/Volatility/New_data_2000_2024/Not_normal_wd/'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uif3K8sx1zgI",
        "outputId": "3ee97358-6951-48e3-81df-f0952bc32c60"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def set_index(df):\n",
        "  df.index = pd.to_datetime(df['Date'])\n",
        "  df.drop(columns=['Date'], inplace=True)"
      ],
      "metadata": {
        "id": "IEBT-saF1ziO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filename = 'RSV_data.csv'\n",
        "HV_data = pd.read_csv(path + filename)"
      ],
      "metadata": {
        "id": "4L7n--ks1-w1"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_index(HV_data)"
      ],
      "metadata": {
        "id": "2L4kSCVl2LAW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tm_data = HV_data"
      ],
      "metadata": {
        "id": "e7o1u1os1_MT"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "HV_data = HV_data.drop(columns=['RSV'])"
      ],
      "metadata": {
        "id": "2MxDepW-2FoY"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "HV_data['RSV'] = tm_data['RSV']"
      ],
      "metadata": {
        "id": "E03UB1xs2FtN"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "HV_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "id": "kfg0zvIM2FyJ",
        "outputId": "2a789e50-f556-4690-c40b-48ea27130e66"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              gdp_growth        volume  ('GARCH', 'normal', 0)  \\\n",
              "Date                                                             \n",
              "2000-02-02  28984.929215  2.945453e+09                0.039601   \n",
              "2000-02-03  28984.929215  2.935907e+09                0.037979   \n",
              "2000-02-04  28984.929215  3.274647e+09                0.036791   \n",
              "2000-02-07  28984.929215  3.413593e+09                0.046593   \n",
              "2000-02-08  28984.929215  2.868803e+09                0.049131   \n",
              "...                  ...           ...                     ...   \n",
              "2024-08-26      0.000000  1.609587e+08                0.000120   \n",
              "2024-08-27      0.000000  9.767973e+07               -0.003889   \n",
              "2024-08-28      0.000000  2.498703e+08                0.000280   \n",
              "2024-08-29      0.000000 -1.799304e+08               -0.000182   \n",
              "2024-08-30      0.000000 -7.921081e+08               -0.000978   \n",
              "\n",
              "            ('GARCH', 'normal', 1)  ('GARCH', 'gaussian', 0)  \\\n",
              "Date                                                           \n",
              "2000-02-02                0.038301                  0.039601   \n",
              "2000-02-03                0.038355                  0.037979   \n",
              "2000-02-04                0.037755                  0.036791   \n",
              "2000-02-07                0.055072                  0.046593   \n",
              "2000-02-08                0.041984                  0.049131   \n",
              "...                            ...                       ...   \n",
              "2024-08-26               -0.000665                  0.000120   \n",
              "2024-08-27               -0.004798                 -0.003889   \n",
              "2024-08-28               -0.001148                  0.000280   \n",
              "2024-08-29               -0.000395                 -0.000182   \n",
              "2024-08-30               -0.000269                 -0.000978   \n",
              "\n",
              "            ('GARCH', 'gaussian', 1)  ('GARCH', 'ged', 0)  \\\n",
              "Date                                                        \n",
              "2000-02-02                  0.038301             0.040044   \n",
              "2000-02-03                  0.038355             0.041000   \n",
              "2000-02-04                  0.037755             0.038214   \n",
              "2000-02-07                  0.055072             0.047968   \n",
              "2000-02-08                  0.041984             0.049560   \n",
              "...                              ...                  ...   \n",
              "2024-08-26                 -0.000665             0.000456   \n",
              "2024-08-27                 -0.004798            -0.003539   \n",
              "2024-08-28                 -0.001148             0.000449   \n",
              "2024-08-29                 -0.000395            -0.000122   \n",
              "2024-08-30                 -0.000269            -0.000987   \n",
              "\n",
              "            ('GARCH', 'ged', 1)  ('FIGARCH', 'normal', 0)  \\\n",
              "Date                                                        \n",
              "2000-02-02             0.039199                  0.038388   \n",
              "2000-02-03             0.040608                  0.038633   \n",
              "2000-02-04             0.040159                  0.036990   \n",
              "2000-02-07             0.057512                  0.046474   \n",
              "2000-02-08             0.042487                  0.046711   \n",
              "...                         ...                       ...   \n",
              "2024-08-26            -0.000424                  0.000121   \n",
              "2024-08-27            -0.002953                 -0.004368   \n",
              "2024-08-28            -0.000383                  0.000483   \n",
              "2024-08-29             0.000615                 -0.000352   \n",
              "2024-08-30             0.000618                 -0.000533   \n",
              "\n",
              "            ('FIGARCH', 'normal', 1)  ...   usd_eur     usd_jpy   usd_gbp  \\\n",
              "Date                                  ...                                   \n",
              "2000-02-02                  0.038388  ...  2.781970  307.252039  4.529620   \n",
              "2000-02-03                  0.038633  ...  2.799436  311.491144  4.529266   \n",
              "2000-02-04                  0.036990  ...  2.728548  306.262089  4.474254   \n",
              "2000-02-07                  0.046474  ...  2.733357  299.491542  4.460147   \n",
              "2000-02-08                  0.046711  ...  2.730104  301.761354  4.470789   \n",
              "...                              ...  ...       ...         ...       ...   \n",
              "2024-08-26                  0.000121  ... -0.002546    0.509117 -0.003041   \n",
              "2024-08-27                 -0.004368  ...  0.002051   -0.551543 -0.001202   \n",
              "2024-08-28                  0.000483  ...  0.000849    0.247487  0.000849   \n",
              "2024-08-29                 -0.000352  ...  0.002333   -0.148492  0.002404   \n",
              "2024-08-30                 -0.000533  ...  0.001838   -0.685894  0.003818   \n",
              "\n",
              "              usd_cny   usd_cad    usd_mxn     gt_data  log_returns  \\\n",
              "Date                                                                  \n",
              "2000-02-02  23.415205  4.090860  26.750733  209.303607    -0.005604   \n",
              "2000-02-03  23.412659  4.119569  26.561052  209.303607    -0.008693   \n",
              "2000-02-04  23.415452  4.106629  26.433950  209.303607     0.000572   \n",
              "2000-02-07  23.414391  4.140641  26.339020  209.303607     0.027307   \n",
              "2000-02-08  23.415982  4.142338  26.135551  209.303607     0.010478   \n",
              "...               ...       ...        ...         ...          ...   \n",
              "2024-08-26   0.005162  0.001980  -0.105925    0.404061     0.008246   \n",
              "2024-08-27  -0.006788 -0.001556  -0.173948    0.404061     0.009336   \n",
              "2024-08-28   0.002263  0.002051  -0.219910    0.707107     0.010307   \n",
              "2024-08-29  -0.000071 -0.000566   0.084711   -0.101015     0.005365   \n",
              "2024-08-30   0.005091 -0.002333   0.092207   -0.101015    -0.007129   \n",
              "\n",
              "            ('APARCH', 'studentst', 1)       RSV  \n",
              "Date                                              \n",
              "2000-02-02                    0.037128  0.032740  \n",
              "2000-02-03                    0.038336  0.033467  \n",
              "2000-02-04                    0.049778  0.032057  \n",
              "2000-02-07                    0.065732  0.034853  \n",
              "2000-02-08                    0.043373  0.035254  \n",
              "...                                ...       ...  \n",
              "2024-08-26                   -0.004076  0.000006  \n",
              "2024-08-27                   -0.005604 -0.000017  \n",
              "2024-08-28                   -0.001642  0.000048  \n",
              "2024-08-29                    0.000277  0.000080  \n",
              "2024-08-30                    0.000044  0.000376  \n",
              "\n",
              "[6184 rows x 30 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-49f5ec8e-d824-4b3e-b845-cdc05242bd19\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gdp_growth</th>\n",
              "      <th>volume</th>\n",
              "      <th>('GARCH', 'normal', 0)</th>\n",
              "      <th>('GARCH', 'normal', 1)</th>\n",
              "      <th>('GARCH', 'gaussian', 0)</th>\n",
              "      <th>('GARCH', 'gaussian', 1)</th>\n",
              "      <th>('GARCH', 'ged', 0)</th>\n",
              "      <th>('GARCH', 'ged', 1)</th>\n",
              "      <th>('FIGARCH', 'normal', 0)</th>\n",
              "      <th>('FIGARCH', 'normal', 1)</th>\n",
              "      <th>...</th>\n",
              "      <th>usd_eur</th>\n",
              "      <th>usd_jpy</th>\n",
              "      <th>usd_gbp</th>\n",
              "      <th>usd_cny</th>\n",
              "      <th>usd_cad</th>\n",
              "      <th>usd_mxn</th>\n",
              "      <th>gt_data</th>\n",
              "      <th>log_returns</th>\n",
              "      <th>('APARCH', 'studentst', 1)</th>\n",
              "      <th>RSV</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2000-02-02</th>\n",
              "      <td>28984.929215</td>\n",
              "      <td>2.945453e+09</td>\n",
              "      <td>0.039601</td>\n",
              "      <td>0.038301</td>\n",
              "      <td>0.039601</td>\n",
              "      <td>0.038301</td>\n",
              "      <td>0.040044</td>\n",
              "      <td>0.039199</td>\n",
              "      <td>0.038388</td>\n",
              "      <td>0.038388</td>\n",
              "      <td>...</td>\n",
              "      <td>2.781970</td>\n",
              "      <td>307.252039</td>\n",
              "      <td>4.529620</td>\n",
              "      <td>23.415205</td>\n",
              "      <td>4.090860</td>\n",
              "      <td>26.750733</td>\n",
              "      <td>209.303607</td>\n",
              "      <td>-0.005604</td>\n",
              "      <td>0.037128</td>\n",
              "      <td>0.032740</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-02-03</th>\n",
              "      <td>28984.929215</td>\n",
              "      <td>2.935907e+09</td>\n",
              "      <td>0.037979</td>\n",
              "      <td>0.038355</td>\n",
              "      <td>0.037979</td>\n",
              "      <td>0.038355</td>\n",
              "      <td>0.041000</td>\n",
              "      <td>0.040608</td>\n",
              "      <td>0.038633</td>\n",
              "      <td>0.038633</td>\n",
              "      <td>...</td>\n",
              "      <td>2.799436</td>\n",
              "      <td>311.491144</td>\n",
              "      <td>4.529266</td>\n",
              "      <td>23.412659</td>\n",
              "      <td>4.119569</td>\n",
              "      <td>26.561052</td>\n",
              "      <td>209.303607</td>\n",
              "      <td>-0.008693</td>\n",
              "      <td>0.038336</td>\n",
              "      <td>0.033467</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-02-04</th>\n",
              "      <td>28984.929215</td>\n",
              "      <td>3.274647e+09</td>\n",
              "      <td>0.036791</td>\n",
              "      <td>0.037755</td>\n",
              "      <td>0.036791</td>\n",
              "      <td>0.037755</td>\n",
              "      <td>0.038214</td>\n",
              "      <td>0.040159</td>\n",
              "      <td>0.036990</td>\n",
              "      <td>0.036990</td>\n",
              "      <td>...</td>\n",
              "      <td>2.728548</td>\n",
              "      <td>306.262089</td>\n",
              "      <td>4.474254</td>\n",
              "      <td>23.415452</td>\n",
              "      <td>4.106629</td>\n",
              "      <td>26.433950</td>\n",
              "      <td>209.303607</td>\n",
              "      <td>0.000572</td>\n",
              "      <td>0.049778</td>\n",
              "      <td>0.032057</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-02-07</th>\n",
              "      <td>28984.929215</td>\n",
              "      <td>3.413593e+09</td>\n",
              "      <td>0.046593</td>\n",
              "      <td>0.055072</td>\n",
              "      <td>0.046593</td>\n",
              "      <td>0.055072</td>\n",
              "      <td>0.047968</td>\n",
              "      <td>0.057512</td>\n",
              "      <td>0.046474</td>\n",
              "      <td>0.046474</td>\n",
              "      <td>...</td>\n",
              "      <td>2.733357</td>\n",
              "      <td>299.491542</td>\n",
              "      <td>4.460147</td>\n",
              "      <td>23.414391</td>\n",
              "      <td>4.140641</td>\n",
              "      <td>26.339020</td>\n",
              "      <td>209.303607</td>\n",
              "      <td>0.027307</td>\n",
              "      <td>0.065732</td>\n",
              "      <td>0.034853</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2000-02-08</th>\n",
              "      <td>28984.929215</td>\n",
              "      <td>2.868803e+09</td>\n",
              "      <td>0.049131</td>\n",
              "      <td>0.041984</td>\n",
              "      <td>0.049131</td>\n",
              "      <td>0.041984</td>\n",
              "      <td>0.049560</td>\n",
              "      <td>0.042487</td>\n",
              "      <td>0.046711</td>\n",
              "      <td>0.046711</td>\n",
              "      <td>...</td>\n",
              "      <td>2.730104</td>\n",
              "      <td>301.761354</td>\n",
              "      <td>4.470789</td>\n",
              "      <td>23.415982</td>\n",
              "      <td>4.142338</td>\n",
              "      <td>26.135551</td>\n",
              "      <td>209.303607</td>\n",
              "      <td>0.010478</td>\n",
              "      <td>0.043373</td>\n",
              "      <td>0.035254</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-08-26</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.609587e+08</td>\n",
              "      <td>0.000120</td>\n",
              "      <td>-0.000665</td>\n",
              "      <td>0.000120</td>\n",
              "      <td>-0.000665</td>\n",
              "      <td>0.000456</td>\n",
              "      <td>-0.000424</td>\n",
              "      <td>0.000121</td>\n",
              "      <td>0.000121</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.002546</td>\n",
              "      <td>0.509117</td>\n",
              "      <td>-0.003041</td>\n",
              "      <td>0.005162</td>\n",
              "      <td>0.001980</td>\n",
              "      <td>-0.105925</td>\n",
              "      <td>0.404061</td>\n",
              "      <td>0.008246</td>\n",
              "      <td>-0.004076</td>\n",
              "      <td>0.000006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-08-27</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>9.767973e+07</td>\n",
              "      <td>-0.003889</td>\n",
              "      <td>-0.004798</td>\n",
              "      <td>-0.003889</td>\n",
              "      <td>-0.004798</td>\n",
              "      <td>-0.003539</td>\n",
              "      <td>-0.002953</td>\n",
              "      <td>-0.004368</td>\n",
              "      <td>-0.004368</td>\n",
              "      <td>...</td>\n",
              "      <td>0.002051</td>\n",
              "      <td>-0.551543</td>\n",
              "      <td>-0.001202</td>\n",
              "      <td>-0.006788</td>\n",
              "      <td>-0.001556</td>\n",
              "      <td>-0.173948</td>\n",
              "      <td>0.404061</td>\n",
              "      <td>0.009336</td>\n",
              "      <td>-0.005604</td>\n",
              "      <td>-0.000017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-08-28</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.498703e+08</td>\n",
              "      <td>0.000280</td>\n",
              "      <td>-0.001148</td>\n",
              "      <td>0.000280</td>\n",
              "      <td>-0.001148</td>\n",
              "      <td>0.000449</td>\n",
              "      <td>-0.000383</td>\n",
              "      <td>0.000483</td>\n",
              "      <td>0.000483</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000849</td>\n",
              "      <td>0.247487</td>\n",
              "      <td>0.000849</td>\n",
              "      <td>0.002263</td>\n",
              "      <td>0.002051</td>\n",
              "      <td>-0.219910</td>\n",
              "      <td>0.707107</td>\n",
              "      <td>0.010307</td>\n",
              "      <td>-0.001642</td>\n",
              "      <td>0.000048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-08-29</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.799304e+08</td>\n",
              "      <td>-0.000182</td>\n",
              "      <td>-0.000395</td>\n",
              "      <td>-0.000182</td>\n",
              "      <td>-0.000395</td>\n",
              "      <td>-0.000122</td>\n",
              "      <td>0.000615</td>\n",
              "      <td>-0.000352</td>\n",
              "      <td>-0.000352</td>\n",
              "      <td>...</td>\n",
              "      <td>0.002333</td>\n",
              "      <td>-0.148492</td>\n",
              "      <td>0.002404</td>\n",
              "      <td>-0.000071</td>\n",
              "      <td>-0.000566</td>\n",
              "      <td>0.084711</td>\n",
              "      <td>-0.101015</td>\n",
              "      <td>0.005365</td>\n",
              "      <td>0.000277</td>\n",
              "      <td>0.000080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-08-30</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>-7.921081e+08</td>\n",
              "      <td>-0.000978</td>\n",
              "      <td>-0.000269</td>\n",
              "      <td>-0.000978</td>\n",
              "      <td>-0.000269</td>\n",
              "      <td>-0.000987</td>\n",
              "      <td>0.000618</td>\n",
              "      <td>-0.000533</td>\n",
              "      <td>-0.000533</td>\n",
              "      <td>...</td>\n",
              "      <td>0.001838</td>\n",
              "      <td>-0.685894</td>\n",
              "      <td>0.003818</td>\n",
              "      <td>0.005091</td>\n",
              "      <td>-0.002333</td>\n",
              "      <td>0.092207</td>\n",
              "      <td>-0.101015</td>\n",
              "      <td>-0.007129</td>\n",
              "      <td>0.000044</td>\n",
              "      <td>0.000376</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6184 rows × 30 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-49f5ec8e-d824-4b3e-b845-cdc05242bd19')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-49f5ec8e-d824-4b3e-b845-cdc05242bd19 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-49f5ec8e-d824-4b3e-b845-cdc05242bd19');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-75def7c5-7654-41ab-a4a6-a4bf71172294\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-75def7c5-7654-41ab-a4a6-a4bf71172294')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-75def7c5-7654-41ab-a4a6-a4bf71172294 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "HV_data"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split train, validation and test data"
      ],
      "metadata": {
        "id": "f31d2QX72Q-8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_data(data, target, train_end =datetime(2022, 5, 30), test_start=datetime(2022, 5, 31), test_size=0.1):\n",
        "  test_data = data.loc[test_start:]\n",
        "\n",
        "  train_val = data.loc[:train_end]\n",
        "  train_data, val_data = train_test_split(train_val, test_size=test_size, shuffle=False)\n",
        "\n",
        "  return train_data, val_data, test_data"
      ],
      "metadata": {
        "id": "3ZBlldE1h1rw"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sliding_window_transform(X, y, timesteps):\n",
        "  X_windows = []\n",
        "  y_windows = []\n",
        "  for i in range(len(X) - timesteps + 1):\n",
        "    X_window = X[i:i + timesteps]\n",
        "    y_window = y[i + timesteps - 1]\n",
        "    X_windows.append(X_window)\n",
        "    y_windows.append(y_window)\n",
        "\n",
        "  return np.array(X_windows), np.array(y_windows)"
      ],
      "metadata": {
        "id": "x-xBiOOU2LEc"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the rolling window function\n",
        "def rolling_window(df, in_sample_window_size, out_of_sample_size):\n",
        "  X, y = [], []\n",
        "  for i in range(in_sample_window_size, len(df) - out_of_sample_size):\n",
        "    X.append(df.iloc[i - in_sample_window_size:i, :-1].values)  # All features except the target column\n",
        "    y.append(df.iloc[i:i + out_of_sample_size, -1].values)  # Target column\n",
        "\n",
        "  return np.array(X), np.array(y)"
      ],
      "metadata": {
        "id": "H4oEdogIh6PT"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "x2Pa23Ux2Ynt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_mape(actual, predicted):\n",
        "  actual, predicted = np.array(actual), np.array(predicted)\n",
        "  return np.mean(np.abs((actual - predicted) / actual)) * 100"
      ],
      "metadata": {
        "id": "coiUqSlqjI50"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RSV"
      ],
      "metadata": {
        "id": "2Ak0aCvF2bqR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "daily_train, daily_val, daily_test = split_data(HV_data, 'RSV')"
      ],
      "metadata": {
        "id": "9Me1cu3q2LH6"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "in_sam_win_sz = 25\n",
        "out_sam_win_sz = 5"
      ],
      "metadata": {
        "id": "wbIoahpP-zBI"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "HV_X_train, HV_y_train = rolling_window(daily_train, in_sam_win_sz, out_sam_win_sz)\n",
        "HV_X_val, HV_y_val = rolling_window(daily_val, in_sam_win_sz, out_sam_win_sz)\n",
        "HV_X_test, HV_y_test = rolling_window(daily_test, in_sam_win_sz, out_sam_win_sz)"
      ],
      "metadata": {
        "id": "hxzzyyCR-1_m"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# HV_X_train = HV_X_train.reshape(HV_X_train.shape[0], win_sz, -1)\n",
        "# HV_X_val = HV_X_val.reshape(HV_X_val.shape[0], win_sz, -1)\n",
        "# HV_X_test = HV_X_test.reshape(HV_X_test.shape[0], win_sz, -1)"
      ],
      "metadata": {
        "id": "ns46ckgGA42H"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LSTM"
      ],
      "metadata": {
        "id": "AIQfC7oiLhnU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_garch_model = Sequential()\n",
        "lstm_garch_model.add(LSTM(48, input_shape=(HV_X_train.shape[1], HV_X_train.shape[2]), return_sequences=True))\n",
        "lstm_garch_model.add(Dropout(0.1))\n",
        "lstm_garch_model.add(LSTM(16))\n",
        "lstm_garch_model.add(Dropout(0.1))\n",
        "lstm_garch_model.add(Dense(5))\n",
        "\n",
        "lstm_garch_model.compile(optimizer=Adam(learning_rate=0.01), loss='mse')"
      ],
      "metadata": {
        "id": "Zf6h10cy1zlx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e885eee-fd17-4845-93c9-988ef7a4a695"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_garch_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zpm8uSZJ3ESB",
        "outputId": "694bbd36-83e1-45ec-d6b7-fcf81f0213d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m48\u001b[0m)              │          \u001b[38;5;34m14,976\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m48\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │           \u001b[38;5;34m4,160\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │              \u001b[38;5;34m85\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">14,976</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">85</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m19,221\u001b[0m (75.08 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,221</span> (75.08 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m19,221\u001b[0m (75.08 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,221</span> (75.08 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_history = lstm_garch_model.fit(HV_X_train, HV_y_train, epochs=80, batch_size=32, validation_data=(HV_X_val, HV_y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FcrtK-L3NgU",
        "outputId": "8358c9cc-6edb-486b-c64e-f6bb5ad02718"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - loss: 0.0066 - val_loss: 1.1097e-05\n",
            "Epoch 2/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - loss: 9.1052e-05 - val_loss: 5.1735e-06\n",
            "Epoch 3/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 7.1336e-05 - val_loss: 4.9625e-06\n",
            "Epoch 4/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 5.1469e-05 - val_loss: 4.9727e-06\n",
            "Epoch 5/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 32ms/step - loss: 4.2721e-05 - val_loss: 3.6466e-06\n",
            "Epoch 6/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 4.7878e-05 - val_loss: 2.4101e-06\n",
            "Epoch 7/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 4.1347e-05 - val_loss: 3.0953e-06\n",
            "Epoch 8/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 3.2048e-05 - val_loss: 4.5980e-06\n",
            "Epoch 9/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - loss: 3.6944e-05 - val_loss: 2.2697e-06\n",
            "Epoch 10/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 3.5711e-05 - val_loss: 1.9591e-06\n",
            "Epoch 11/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - loss: 3.7176e-05 - val_loss: 2.2079e-06\n",
            "Epoch 12/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - loss: 3.0754e-05 - val_loss: 4.2239e-06\n",
            "Epoch 13/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 3.3569e-05 - val_loss: 2.9094e-06\n",
            "Epoch 14/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 3.1039e-05 - val_loss: 5.3432e-06\n",
            "Epoch 15/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 28ms/step - loss: 3.1121e-05 - val_loss: 1.3982e-06\n",
            "Epoch 16/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - loss: 3.1592e-05 - val_loss: 2.1282e-06\n",
            "Epoch 17/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 2.6788e-05 - val_loss: 7.1407e-06\n",
            "Epoch 18/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - loss: 2.8878e-05 - val_loss: 3.6896e-06\n",
            "Epoch 19/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 27ms/step - loss: 3.1391e-05 - val_loss: 1.6758e-06\n",
            "Epoch 20/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 3.4990e-05 - val_loss: 6.0042e-06\n",
            "Epoch 21/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 3.0816e-05 - val_loss: 2.0793e-06\n",
            "Epoch 22/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - loss: 2.6921e-05 - val_loss: 5.5861e-06\n",
            "Epoch 23/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 3.8702e-05 - val_loss: 2.2658e-06\n",
            "Epoch 24/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 27ms/step - loss: 3.7531e-05 - val_loss: 2.6543e-06\n",
            "Epoch 25/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - loss: 2.6277e-05 - val_loss: 1.5154e-05\n",
            "Epoch 26/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 3.1499e-05 - val_loss: 1.4004e-06\n",
            "Epoch 27/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - loss: 2.9385e-05 - val_loss: 2.5043e-06\n",
            "Epoch 28/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - loss: 3.2393e-05 - val_loss: 8.4312e-07\n",
            "Epoch 29/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 2.7164e-05 - val_loss: 2.0407e-06\n",
            "Epoch 30/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 2.8300e-05 - val_loss: 3.7465e-06\n",
            "Epoch 31/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 2.9887e-05 - val_loss: 1.2385e-06\n",
            "Epoch 32/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - loss: 3.4851e-05 - val_loss: 4.7681e-06\n",
            "Epoch 33/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 2.5984e-05 - val_loss: 5.5884e-07\n",
            "Epoch 34/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - loss: 2.8478e-05 - val_loss: 1.3750e-06\n",
            "Epoch 35/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - loss: 3.6270e-05 - val_loss: 1.6680e-05\n",
            "Epoch 36/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 2.5842e-05 - val_loss: 4.4614e-06\n",
            "Epoch 37/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - loss: 3.0533e-05 - val_loss: 6.7549e-07\n",
            "Epoch 38/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - loss: 3.1424e-05 - val_loss: 1.1397e-06\n",
            "Epoch 39/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 2.6993e-05 - val_loss: 1.2235e-06\n",
            "Epoch 40/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 2.6737e-05 - val_loss: 5.9176e-06\n",
            "Epoch 41/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - loss: 2.8465e-05 - val_loss: 3.7313e-06\n",
            "Epoch 42/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 3.0391e-05 - val_loss: 1.8427e-06\n",
            "Epoch 43/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 2.6863e-05 - val_loss: 9.1993e-07\n",
            "Epoch 44/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 3.7156e-05 - val_loss: 1.1350e-05\n",
            "Epoch 45/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 27ms/step - loss: 2.6234e-05 - val_loss: 1.4553e-06\n",
            "Epoch 46/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - loss: 2.6853e-05 - val_loss: 1.2847e-06\n",
            "Epoch 47/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - loss: 2.8840e-05 - val_loss: 1.5972e-06\n",
            "Epoch 48/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - loss: 2.8853e-05 - val_loss: 5.2909e-07\n",
            "Epoch 49/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 3.0565e-05 - val_loss: 2.4939e-05\n",
            "Epoch 50/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 3.3685e-05 - val_loss: 6.6068e-06\n",
            "Epoch 51/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 34ms/step - loss: 2.6109e-05 - val_loss: 5.0861e-07\n",
            "Epoch 52/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 2.6836e-05 - val_loss: 2.2276e-06\n",
            "Epoch 53/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 3.2274e-05 - val_loss: 3.6734e-06\n",
            "Epoch 54/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 33ms/step - loss: 2.8034e-05 - val_loss: 5.9838e-06\n",
            "Epoch 55/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 23ms/step - loss: 2.9910e-05 - val_loss: 1.6545e-06\n",
            "Epoch 56/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 35ms/step - loss: 2.7178e-05 - val_loss: 1.1643e-06\n",
            "Epoch 57/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 2.7044e-05 - val_loss: 9.0839e-07\n",
            "Epoch 58/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - loss: 3.0157e-05 - val_loss: 3.6819e-06\n",
            "Epoch 59/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - loss: 2.9430e-05 - val_loss: 2.6408e-07\n",
            "Epoch 60/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 2.4388e-05 - val_loss: 3.7678e-06\n",
            "Epoch 61/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 3.1460e-05 - val_loss: 3.0755e-07\n",
            "Epoch 62/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 32ms/step - loss: 2.5187e-05 - val_loss: 1.0634e-05\n",
            "Epoch 63/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 2.9795e-05 - val_loss: 7.2001e-07\n",
            "Epoch 64/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 3.5155e-05 - val_loss: 6.7779e-07\n",
            "Epoch 65/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 35ms/step - loss: 3.0399e-05 - val_loss: 1.6984e-06\n",
            "Epoch 66/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 2.7823e-05 - val_loss: 3.3174e-06\n",
            "Epoch 67/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - loss: 2.3595e-05 - val_loss: 3.5041e-07\n",
            "Epoch 68/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - loss: 2.6475e-05 - val_loss: 2.4155e-07\n",
            "Epoch 69/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 2.7715e-05 - val_loss: 3.6661e-05\n",
            "Epoch 70/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 3.4578e-05 - val_loss: 6.0167e-07\n",
            "Epoch 71/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - loss: 2.9553e-05 - val_loss: 2.1505e-06\n",
            "Epoch 72/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 3.1179e-05 - val_loss: 5.1989e-06\n",
            "Epoch 73/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - loss: 2.5616e-05 - val_loss: 4.5649e-07\n",
            "Epoch 74/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 32ms/step - loss: 2.8924e-05 - val_loss: 8.0997e-06\n",
            "Epoch 75/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - loss: 2.8099e-05 - val_loss: 3.7588e-07\n",
            "Epoch 76/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - loss: 3.3853e-05 - val_loss: 2.5908e-06\n",
            "Epoch 77/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - loss: 3.3872e-05 - val_loss: 5.5669e-07\n",
            "Epoch 78/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 2.6302e-05 - val_loss: 4.0616e-07\n",
            "Epoch 79/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - loss: 2.7470e-05 - val_loss: 7.4155e-05\n",
            "Epoch 80/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - loss: 6.0356e-05 - val_loss: 2.4530e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions\n",
        "HV_lstm_predictions = lstm_garch_model.predict(HV_X_test)"
      ],
      "metadata": {
        "id": "A-zmdwqm_6_e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "840a029b-54bf-4ec2-8fee-db40408a2382"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mse = mean_squared_error(HV_y_test, HV_lstm_predictions)\n",
        "print(f'MSE: {mse}')\n",
        "\n",
        "rmse = np.sqrt(mse)\n",
        "print(f'RMSE: {rmse}')\n",
        "\n",
        "mae = mean_absolute_error(HV_y_test, HV_lstm_predictions)\n",
        "print(f'MAE: {mae}')\n",
        "\n",
        "mape = calculate_mape(HV_y_test, HV_lstm_predictions)\n",
        "print(f'MAPE: {mape}%')"
      ],
      "metadata": {
        "id": "Y8BUSWddHo1Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80dcf32d-6130-4fc8-9f3a-5e8115b2b510"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 2.3267506141488733e-06\n",
            "RMSE: 0.001525369009174132\n",
            "MAE: 0.0013677358577675667\n",
            "MAPE: 7457.865567349863%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GRU"
      ],
      "metadata": {
        "id": "UiS7McIrLmEd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gru_model = Sequential()\n",
        "gru_model.add(GRU(48, input_shape=(HV_X_train.shape[1], HV_X_train.shape[2]), return_sequences=True))\n",
        "gru_model.add(Dropout(0.1))\n",
        "gru_model.add(GRU(16))\n",
        "gru_model.add(Dropout(0.1))\n",
        "gru_model.add(Dense(5))\n",
        "\n",
        "gru_model.compile(optimizer=Adam(learning_rate=0.01), loss='mse')"
      ],
      "metadata": {
        "id": "2fd5ZZjRH2dD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57b1ce3a-d770-4715-a7e7-fbf681cbab20"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gru_model.summary()"
      ],
      "metadata": {
        "id": "fi7nCfJRL0nz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "cc7b6b47-2793-42ab-d455-bf16339fd43a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ gru (\u001b[38;5;33mGRU\u001b[0m)                            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m48\u001b[0m)              │          \u001b[38;5;34m11,376\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m48\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_1 (\u001b[38;5;33mGRU\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │           \u001b[38;5;34m3,168\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │              \u001b[38;5;34m85\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">11,376</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,168</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">85</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m14,629\u001b[0m (57.14 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,629</span> (57.14 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m14,629\u001b[0m (57.14 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,629</span> (57.14 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gru_history = gru_model.fit(HV_X_train, HV_y_train, epochs=80, batch_size=32, validation_data=(HV_X_val, HV_y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAo9MoSmNg_1",
        "outputId": "900793e1-5ee5-4f40-d974-e5b07094bbb2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - loss: 0.0560 - val_loss: 6.1343e-05\n",
            "Epoch 2/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 32ms/step - loss: 2.8607e-04 - val_loss: 2.4601e-05\n",
            "Epoch 3/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 37ms/step - loss: 1.3209e-04 - val_loss: 1.1010e-05\n",
            "Epoch 4/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step - loss: 8.6310e-05 - val_loss: 8.4314e-06\n",
            "Epoch 5/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 45ms/step - loss: 6.5336e-05 - val_loss: 5.6662e-06\n",
            "Epoch 6/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 37ms/step - loss: 5.6119e-05 - val_loss: 5.6572e-06\n",
            "Epoch 7/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - loss: 6.0238e-05 - val_loss: 3.6890e-06\n",
            "Epoch 8/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 40ms/step - loss: 5.2036e-05 - val_loss: 3.2625e-06\n",
            "Epoch 9/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - loss: 5.2588e-05 - val_loss: 2.5483e-06\n",
            "Epoch 10/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - loss: 5.0406e-05 - val_loss: 2.6062e-06\n",
            "Epoch 11/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 4.8226e-05 - val_loss: 2.1722e-06\n",
            "Epoch 12/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 49ms/step - loss: 4.0099e-05 - val_loss: 3.1822e-06\n",
            "Epoch 13/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 35ms/step - loss: 3.3072e-05 - val_loss: 7.8337e-06\n",
            "Epoch 14/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 4.4043e-05 - val_loss: 1.8618e-06\n",
            "Epoch 15/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - loss: 4.0222e-05 - val_loss: 1.7874e-06\n",
            "Epoch 16/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - loss: 4.0549e-05 - val_loss: 2.0115e-06\n",
            "Epoch 17/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - loss: 3.7371e-05 - val_loss: 1.6529e-06\n",
            "Epoch 18/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 28ms/step - loss: 3.1238e-05 - val_loss: 4.2870e-06\n",
            "Epoch 19/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 34ms/step - loss: 3.4449e-05 - val_loss: 1.8977e-06\n",
            "Epoch 20/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - loss: 3.2093e-05 - val_loss: 2.2069e-06\n",
            "Epoch 21/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 38ms/step - loss: 3.6895e-05 - val_loss: 1.6525e-06\n",
            "Epoch 22/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - loss: 2.6646e-05 - val_loss: 2.3737e-06\n",
            "Epoch 23/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 3.9991e-05 - val_loss: 1.8293e-05\n",
            "Epoch 24/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - loss: 4.3406e-05 - val_loss: 1.6114e-06\n",
            "Epoch 25/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 39ms/step - loss: 3.2963e-05 - val_loss: 2.2606e-06\n",
            "Epoch 26/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - loss: 3.5209e-05 - val_loss: 2.5491e-06\n",
            "Epoch 27/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 28ms/step - loss: 2.9905e-05 - val_loss: 2.7762e-06\n",
            "Epoch 28/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - loss: 3.3860e-05 - val_loss: 2.8036e-06\n",
            "Epoch 29/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - loss: 4.2116e-05 - val_loss: 1.9005e-06\n",
            "Epoch 30/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - loss: 2.9446e-05 - val_loss: 2.4072e-06\n",
            "Epoch 31/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - loss: 3.2408e-05 - val_loss: 2.0415e-06\n",
            "Epoch 32/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 39ms/step - loss: 3.1940e-05 - val_loss: 2.5904e-06\n",
            "Epoch 33/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - loss: 3.0312e-05 - val_loss: 5.5257e-06\n",
            "Epoch 34/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 3.2637e-05 - val_loss: 8.1661e-06\n",
            "Epoch 35/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - loss: 3.3443e-05 - val_loss: 2.9925e-06\n",
            "Epoch 36/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - loss: 2.7533e-05 - val_loss: 7.2843e-06\n",
            "Epoch 37/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - loss: 3.0952e-05 - val_loss: 7.1441e-06\n",
            "Epoch 38/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 3.5161e-05 - val_loss: 4.6438e-06\n",
            "Epoch 39/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 32ms/step - loss: 3.2943e-05 - val_loss: 2.0467e-06\n",
            "Epoch 40/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - loss: 3.2847e-05 - val_loss: 1.2848e-06\n",
            "Epoch 41/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - loss: 3.4180e-05 - val_loss: 1.3475e-06\n",
            "Epoch 42/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 34ms/step - loss: 3.6777e-05 - val_loss: 2.5155e-06\n",
            "Epoch 43/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - loss: 3.3935e-05 - val_loss: 5.0764e-06\n",
            "Epoch 44/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - loss: 3.2721e-05 - val_loss: 7.8170e-06\n",
            "Epoch 45/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - loss: 3.7186e-05 - val_loss: 2.3335e-06\n",
            "Epoch 46/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - loss: 2.8630e-05 - val_loss: 1.6714e-06\n",
            "Epoch 47/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - loss: 2.7127e-05 - val_loss: 2.7148e-06\n",
            "Epoch 48/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 37ms/step - loss: 3.3103e-05 - val_loss: 1.6810e-05\n",
            "Epoch 49/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - loss: 3.5808e-05 - val_loss: 1.7031e-06\n",
            "Epoch 50/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 37ms/step - loss: 3.0861e-05 - val_loss: 4.2140e-06\n",
            "Epoch 51/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - loss: 3.4602e-05 - val_loss: 1.7893e-06\n",
            "Epoch 52/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 28ms/step - loss: 2.6687e-05 - val_loss: 1.1962e-06\n",
            "Epoch 53/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - loss: 3.0681e-05 - val_loss: 5.5286e-06\n",
            "Epoch 54/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - loss: 3.2569e-05 - val_loss: 2.1414e-06\n",
            "Epoch 55/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 37ms/step - loss: 3.4449e-05 - val_loss: 1.9007e-06\n",
            "Epoch 56/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - loss: 2.6950e-05 - val_loss: 5.7113e-06\n",
            "Epoch 57/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 39ms/step - loss: 3.0701e-05 - val_loss: 2.3249e-06\n",
            "Epoch 58/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - loss: 3.1634e-05 - val_loss: 3.0874e-06\n",
            "Epoch 59/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 28ms/step - loss: 3.2021e-05 - val_loss: 6.3897e-06\n",
            "Epoch 60/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 39ms/step - loss: 3.4375e-05 - val_loss: 9.8738e-06\n",
            "Epoch 61/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - loss: 3.1164e-05 - val_loss: 3.7995e-06\n",
            "Epoch 62/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - loss: 3.7828e-05 - val_loss: 9.4107e-07\n",
            "Epoch 63/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 3.4705e-05 - val_loss: 1.0733e-05\n",
            "Epoch 64/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - loss: 3.1663e-05 - val_loss: 1.5323e-06\n",
            "Epoch 65/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 2.6318e-05 - val_loss: 2.1203e-06\n",
            "Epoch 66/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - loss: 3.3574e-05 - val_loss: 2.0587e-06\n",
            "Epoch 67/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 37ms/step - loss: 3.4487e-05 - val_loss: 2.9148e-06\n",
            "Epoch 68/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - loss: 2.8367e-05 - val_loss: 1.1073e-05\n",
            "Epoch 69/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 40ms/step - loss: 3.2460e-05 - val_loss: 1.2259e-06\n",
            "Epoch 70/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - loss: 3.0191e-05 - val_loss: 8.7039e-07\n",
            "Epoch 71/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - loss: 2.7837e-05 - val_loss: 6.5465e-06\n",
            "Epoch 72/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 41ms/step - loss: 3.2865e-05 - val_loss: 1.3169e-05\n",
            "Epoch 73/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - loss: 2.9643e-05 - val_loss: 3.7449e-06\n",
            "Epoch 74/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 44ms/step - loss: 3.2449e-05 - val_loss: 8.9066e-07\n",
            "Epoch 75/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - loss: 2.9906e-05 - val_loss: 6.3794e-06\n",
            "Epoch 76/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - loss: 2.8431e-05 - val_loss: 4.6096e-06\n",
            "Epoch 77/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 40ms/step - loss: 3.0473e-05 - val_loss: 4.8126e-06\n",
            "Epoch 78/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - loss: 3.6873e-05 - val_loss: 1.8597e-06\n",
            "Epoch 79/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - loss: 2.9661e-05 - val_loss: 1.1887e-05\n",
            "Epoch 80/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 3.6256e-05 - val_loss: 2.5593e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions\n",
        "HV_gru_predictions = gru_model.predict(HV_X_test)"
      ],
      "metadata": {
        "id": "jed591XqNhSM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cb79d32-f94b-4872-91b2-a1c78c5b1ca7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mse = mean_squared_error(HV_y_test, HV_gru_predictions)\n",
        "print(f'MSE: {mse}')\n",
        "\n",
        "rmse = np.sqrt(mse)\n",
        "print(f'RMSE: {rmse}')\n",
        "\n",
        "mae = mean_absolute_error(HV_y_test, HV_gru_predictions)\n",
        "print(f'MAE: {mae}')\n",
        "\n",
        "mape = calculate_mape(HV_y_test, HV_gru_predictions)\n",
        "print(f'MAPE: {mape}%')"
      ],
      "metadata": {
        "id": "WeZeC001NhcB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df33645e-cc5f-4cc8-ad02-ca4e55cc76f7"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 2.5573864480569353e-06\n",
            "RMSE: 0.0015991830564563068\n",
            "MAE: 0.001373610420296297\n",
            "MAPE: 7642.33579490894%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LSTM_GRU"
      ],
      "metadata": {
        "id": "b1e3A5gvPzR6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_gru_model = Sequential()\n",
        "lstm_gru_model.add(LSTM(48, input_shape=(HV_X_train.shape[1], HV_X_train.shape[2]), return_sequences=True))\n",
        "lstm_gru_model.add(Dropout(0.1))\n",
        "lstm_gru_model.add(GRU(16))\n",
        "lstm_gru_model.add(Dropout(0.1))\n",
        "lstm_gru_model.add(Dense(5))\n",
        "\n",
        "lstm_gru_model.compile(optimizer=Adam(learning_rate=0.01), loss='mse')"
      ],
      "metadata": {
        "id": "M4sDHB06Nhfb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_gru_model.summary()"
      ],
      "metadata": {
        "id": "OihmLvRzQWlV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_gru_history = lstm_gru_model.fit(HV_X_train, HV_y_train, epochs=80, batch_size=32, validation_data=(HV_X_val, HV_y_val))"
      ],
      "metadata": {
        "id": "_6UxHjRWQWnn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80f3ac64-5181-4dc7-de97-5251a0ef3b14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 27ms/step - loss: 0.0246 - val_loss: 2.9721e-04\n",
            "Epoch 2/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - loss: 5.0866e-04 - val_loss: 8.3940e-05\n",
            "Epoch 3/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - loss: 2.3584e-04 - val_loss: 7.2060e-05\n",
            "Epoch 4/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 1.3601e-04 - val_loss: 1.3846e-05\n",
            "Epoch 5/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - loss: 1.0222e-04 - val_loss: 3.9017e-06\n",
            "Epoch 6/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 25ms/step - loss: 6.9343e-05 - val_loss: 1.0278e-05\n",
            "Epoch 7/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - loss: 6.2726e-05 - val_loss: 2.7753e-06\n",
            "Epoch 8/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - loss: 5.5831e-05 - val_loss: 2.0435e-06\n",
            "Epoch 9/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 4.6880e-05 - val_loss: 1.7410e-06\n",
            "Epoch 10/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 35ms/step - loss: 4.3278e-05 - val_loss: 3.9505e-06\n",
            "Epoch 11/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - loss: 4.0384e-05 - val_loss: 1.9179e-06\n",
            "Epoch 12/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 3.4364e-05 - val_loss: 2.4434e-06\n",
            "Epoch 13/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - loss: 3.1647e-05 - val_loss: 7.0697e-06\n",
            "Epoch 14/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - loss: 3.2543e-05 - val_loss: 9.7827e-05\n",
            "Epoch 15/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 8.7136e-05 - val_loss: 4.6848e-06\n",
            "Epoch 16/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - loss: 3.5714e-05 - val_loss: 1.2644e-06\n",
            "Epoch 17/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - loss: 2.9954e-05 - val_loss: 3.5555e-06\n",
            "Epoch 18/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 3.3888e-05 - val_loss: 2.1629e-06\n",
            "Epoch 19/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - loss: 2.9341e-05 - val_loss: 2.5915e-06\n",
            "Epoch 20/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - loss: 3.1993e-05 - val_loss: 1.7191e-06\n",
            "Epoch 21/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 3.1265e-05 - val_loss: 1.4104e-06\n",
            "Epoch 22/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 3.0409e-05 - val_loss: 3.6863e-06\n",
            "Epoch 23/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 34ms/step - loss: 3.4816e-05 - val_loss: 6.5807e-06\n",
            "Epoch 24/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 3.0945e-05 - val_loss: 1.1821e-06\n",
            "Epoch 25/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - loss: 2.7357e-05 - val_loss: 1.9837e-06\n",
            "Epoch 26/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 2.5009e-05 - val_loss: 5.6791e-06\n",
            "Epoch 27/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - loss: 3.2514e-05 - val_loss: 3.8736e-06\n",
            "Epoch 28/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - loss: 3.1600e-05 - val_loss: 4.4851e-06\n",
            "Epoch 29/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - loss: 2.9867e-05 - val_loss: 1.5373e-06\n",
            "Epoch 30/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - loss: 2.9597e-05 - val_loss: 3.3918e-06\n",
            "Epoch 31/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 29ms/step - loss: 3.1369e-05 - val_loss: 7.8305e-06\n",
            "Epoch 32/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - loss: 2.6243e-05 - val_loss: 2.9105e-06\n",
            "Epoch 33/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 4.0926e-05 - val_loss: 2.2394e-06\n",
            "Epoch 34/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - loss: 2.6467e-05 - val_loss: 2.1500e-06\n",
            "Epoch 35/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - loss: 2.9989e-05 - val_loss: 1.2841e-06\n",
            "Epoch 36/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 3.2938e-05 - val_loss: 1.0425e-05\n",
            "Epoch 37/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 2.9629e-05 - val_loss: 1.5606e-05\n",
            "Epoch 38/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - loss: 4.1758e-05 - val_loss: 1.4252e-06\n",
            "Epoch 39/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - loss: 3.3379e-05 - val_loss: 5.5377e-06\n",
            "Epoch 40/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 31ms/step - loss: 3.1268e-05 - val_loss: 2.2066e-06\n",
            "Epoch 41/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 3.3850e-05 - val_loss: 3.4518e-06\n",
            "Epoch 42/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 31ms/step - loss: 3.0901e-05 - val_loss: 4.1889e-06\n",
            "Epoch 43/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - loss: 3.4849e-05 - val_loss: 1.2697e-06\n",
            "Epoch 44/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - loss: 2.3150e-05 - val_loss: 1.1739e-05\n",
            "Epoch 45/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - loss: 3.6365e-05 - val_loss: 4.7525e-06\n",
            "Epoch 46/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - loss: 2.9966e-05 - val_loss: 2.2999e-06\n",
            "Epoch 47/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 3.2290e-05 - val_loss: 1.1806e-05\n",
            "Epoch 48/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 34ms/step - loss: 3.0379e-05 - val_loss: 3.2792e-06\n",
            "Epoch 49/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 3.7629e-05 - val_loss: 4.7655e-05\n",
            "Epoch 50/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 38ms/step - loss: 3.6331e-05 - val_loss: 1.8369e-06\n",
            "Epoch 51/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 28ms/step - loss: 3.2171e-05 - val_loss: 4.0664e-06\n",
            "Epoch 52/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 2.9805e-05 - val_loss: 9.9576e-06\n",
            "Epoch 53/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - loss: 2.8822e-05 - val_loss: 3.4385e-06\n",
            "Epoch 54/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - loss: 3.3106e-05 - val_loss: 1.9660e-06\n",
            "Epoch 55/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 2.7721e-05 - val_loss: 1.3951e-06\n",
            "Epoch 56/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - loss: 2.9162e-05 - val_loss: 6.0550e-06\n",
            "Epoch 57/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - loss: 2.9736e-05 - val_loss: 3.6166e-06\n",
            "Epoch 58/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 3.1858e-05 - val_loss: 9.8099e-06\n",
            "Epoch 59/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 3.8104e-05 - val_loss: 2.6479e-06\n",
            "Epoch 60/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 34ms/step - loss: 2.8272e-05 - val_loss: 4.9258e-06\n",
            "Epoch 61/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - loss: 3.5249e-05 - val_loss: 6.8712e-06\n",
            "Epoch 62/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - loss: 3.0117e-05 - val_loss: 9.6039e-06\n",
            "Epoch 63/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 3.1182e-05 - val_loss: 1.1602e-06\n",
            "Epoch 64/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - loss: 2.8506e-05 - val_loss: 1.4135e-06\n",
            "Epoch 65/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - loss: 3.1384e-05 - val_loss: 4.1485e-06\n",
            "Epoch 66/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - loss: 3.4517e-05 - val_loss: 5.5176e-06\n",
            "Epoch 67/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - loss: 2.8838e-05 - val_loss: 6.2533e-06\n",
            "Epoch 68/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - loss: 2.9258e-05 - val_loss: 2.9366e-06\n",
            "Epoch 69/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - loss: 2.7550e-05 - val_loss: 8.5011e-06\n",
            "Epoch 70/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - loss: 3.0707e-05 - val_loss: 1.9682e-06\n",
            "Epoch 71/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - loss: 3.0394e-05 - val_loss: 1.5698e-06\n",
            "Epoch 72/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 2.7488e-05 - val_loss: 6.8574e-06\n",
            "Epoch 73/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - loss: 3.1788e-05 - val_loss: 1.0069e-05\n",
            "Epoch 74/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - loss: 2.9977e-05 - val_loss: 1.6460e-06\n",
            "Epoch 75/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 2.7618e-05 - val_loss: 1.9792e-06\n",
            "Epoch 76/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - loss: 2.6958e-05 - val_loss: 1.7466e-06\n",
            "Epoch 77/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - loss: 2.6767e-05 - val_loss: 2.8484e-06\n",
            "Epoch 78/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: 2.7130e-05 - val_loss: 5.1401e-06\n",
            "Epoch 79/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - loss: 3.2529e-05 - val_loss: 5.0862e-06\n",
            "Epoch 80/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - loss: 3.1664e-05 - val_loss: 4.8524e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions\n",
        "HV_lstm_gru_predictions = lstm_gru_model.predict(HV_X_test)"
      ],
      "metadata": {
        "id": "HQLIfgQ5QWsf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fc36246-4585-4153-f0ae-959698f9f1d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mse = mean_squared_error(HV_y_test, HV_lstm_gru_predictions)\n",
        "print(f'MSE: {mse}')\n",
        "\n",
        "rmse = np.sqrt(mse)\n",
        "print(f'RMSE: {rmse}')\n",
        "\n",
        "mae = mean_absolute_error(HV_y_test, HV_lstm_gru_predictions)\n",
        "print(f'MAE: {mae}')\n",
        "\n",
        "mape = calculate_mape(HV_y_test, HV_lstm_gru_predictions)\n",
        "print(f'MAPE: {mape}%')"
      ],
      "metadata": {
        "id": "ieo5NKO1QWvw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18f3e9d6-35c4-4e09-bcd9-8ced67e912d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 5.316968741530013e-06\n",
            "RMSE: 0.002305855316694873\n",
            "MAE: 0.0018807072415792062\n",
            "MAPE: 9693.418212872597%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# path_1 = '/content/drive/MyDrive/Volatility/Predictions/RSV/'\n",
        "\n",
        "# df_pred = pd.DataFrame(HV_lstm_gru_predictions[:,0], columns=['lstm_gru_pred'])\n",
        "# filename = 'LSTM_GRU_pred.csv'\n",
        "# df_pred.to_csv(path_1 + filename)"
      ],
      "metadata": {
        "id": "NvFc2RDZvsO6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BiLSTM"
      ],
      "metadata": {
        "id": "JgH4xoeTU2xa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bilstm_model = Sequential()\n",
        "bilstm_model.add(Bidirectional(LSTM(48, return_sequences=True), input_shape=(HV_X_train.shape[1], HV_X_train.shape[2])))\n",
        "bilstm_model.add(Dropout(0.1))\n",
        "bilstm_model.add(Bidirectional(LSTM(16)))\n",
        "bilstm_model.add(Dropout(0.1))\n",
        "bilstm_model.add(Dense(5))\n",
        "\n",
        "bilstm_model.compile(optimizer=Adam(learning_rate=0.01), loss='mse')"
      ],
      "metadata": {
        "id": "OWUQwJo7QWyz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cb1649c-bb84-42a6-9ed4-3c1b5ed1d8d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bilstm_model.summary()"
      ],
      "metadata": {
        "id": "HnknoIEUcfdt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "19d2bdd5-7b90-4360-b4f6-08d8ba4f1f1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m96\u001b[0m)              │          \u001b[38;5;34m29,952\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m96\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │          \u001b[38;5;34m14,464\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │             \u001b[38;5;34m165\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">29,952</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">14,464</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">165</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m44,581\u001b[0m (174.14 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">44,581</span> (174.14 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m44,581\u001b[0m (174.14 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">44,581</span> (174.14 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bilstm_history = bilstm_model.fit(HV_X_train, HV_y_train, epochs=80, batch_size=32, validation_data=(HV_X_val, HV_y_val))"
      ],
      "metadata": {
        "id": "4bc45pjEatbC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebd7487d-ca41-47f0-960a-6479615b5a98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 44ms/step - loss: 0.0247 - val_loss: 2.5887e-05\n",
            "Epoch 2/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 55ms/step - loss: 1.8603e-04 - val_loss: 1.3641e-05\n",
            "Epoch 3/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - loss: 1.0170e-04 - val_loss: 8.4130e-06\n",
            "Epoch 4/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 46ms/step - loss: 7.7310e-05 - val_loss: 4.6311e-06\n",
            "Epoch 5/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 55ms/step - loss: 5.8207e-05 - val_loss: 3.2686e-06\n",
            "Epoch 6/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 39ms/step - loss: 4.7356e-05 - val_loss: 2.1457e-06\n",
            "Epoch 7/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 40ms/step - loss: 4.4115e-05 - val_loss: 1.5099e-06\n",
            "Epoch 8/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 50ms/step - loss: 4.8948e-05 - val_loss: 2.4387e-06\n",
            "Epoch 9/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 53ms/step - loss: 4.3195e-05 - val_loss: 1.6678e-06\n",
            "Epoch 10/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 4.0633e-05 - val_loss: 9.3924e-07\n",
            "Epoch 11/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 51ms/step - loss: 3.2690e-05 - val_loss: 5.0342e-06\n",
            "Epoch 12/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 40ms/step - loss: 3.3070e-05 - val_loss: 1.3317e-06\n",
            "Epoch 13/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 44ms/step - loss: 3.2361e-05 - val_loss: 2.3145e-06\n",
            "Epoch 14/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 57ms/step - loss: 3.2671e-05 - val_loss: 5.0104e-06\n",
            "Epoch 15/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 39ms/step - loss: 3.0841e-05 - val_loss: 1.3131e-06\n",
            "Epoch 16/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - loss: 2.4636e-05 - val_loss: 8.4291e-06\n",
            "Epoch 17/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 55ms/step - loss: 2.7250e-05 - val_loss: 6.8862e-07\n",
            "Epoch 18/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 40ms/step - loss: 3.3859e-05 - val_loss: 7.3523e-07\n",
            "Epoch 19/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 3.0599e-05 - val_loss: 9.9041e-07\n",
            "Epoch 20/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 55ms/step - loss: 3.3781e-05 - val_loss: 1.0600e-06\n",
            "Epoch 21/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 41ms/step - loss: 2.3055e-05 - val_loss: 1.7741e-06\n",
            "Epoch 22/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 40ms/step - loss: 2.9756e-05 - val_loss: 9.4574e-07\n",
            "Epoch 23/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 54ms/step - loss: 2.7920e-05 - val_loss: 1.5038e-06\n",
            "Epoch 24/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - loss: 2.8399e-05 - val_loss: 3.6144e-06\n",
            "Epoch 25/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 57ms/step - loss: 2.7578e-05 - val_loss: 3.7388e-06\n",
            "Epoch 26/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 39ms/step - loss: 2.7652e-05 - val_loss: 5.4064e-06\n",
            "Epoch 27/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 55ms/step - loss: 2.9840e-05 - val_loss: 6.0885e-07\n",
            "Epoch 28/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - loss: 3.1514e-05 - val_loss: 9.3695e-07\n",
            "Epoch 29/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 45ms/step - loss: 3.0681e-05 - val_loss: 1.8970e-06\n",
            "Epoch 30/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 56ms/step - loss: 2.7180e-05 - val_loss: 2.4192e-06\n",
            "Epoch 31/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 40ms/step - loss: 2.6209e-05 - val_loss: 6.9000e-06\n",
            "Epoch 32/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - loss: 3.2296e-05 - val_loss: 1.6136e-06\n",
            "Epoch 33/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 53ms/step - loss: 3.1803e-05 - val_loss: 3.0523e-06\n",
            "Epoch 34/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 40ms/step - loss: 3.5751e-05 - val_loss: 2.3864e-06\n",
            "Epoch 35/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 55ms/step - loss: 2.6603e-05 - val_loss: 6.2658e-06\n",
            "Epoch 36/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 2.4286e-05 - val_loss: 1.2827e-06\n",
            "Epoch 37/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 40ms/step - loss: 2.6282e-05 - val_loss: 6.9558e-06\n",
            "Epoch 38/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 46ms/step - loss: 3.1285e-05 - val_loss: 9.3177e-07\n",
            "Epoch 39/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 46ms/step - loss: 3.3323e-05 - val_loss: 4.1643e-06\n",
            "Epoch 40/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - loss: 3.0589e-05 - val_loss: 1.5360e-06\n",
            "Epoch 41/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 45ms/step - loss: 2.7892e-05 - val_loss: 8.6210e-06\n",
            "Epoch 42/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 39ms/step - loss: 2.5465e-05 - val_loss: 2.7101e-06\n",
            "Epoch 43/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 56ms/step - loss: 3.3503e-05 - val_loss: 5.1155e-06\n",
            "Epoch 44/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 40ms/step - loss: 2.9598e-05 - val_loss: 2.7976e-06\n",
            "Epoch 45/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 50ms/step - loss: 2.0316e-05 - val_loss: 1.4475e-05\n",
            "Epoch 46/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 43ms/step - loss: 4.5656e-05 - val_loss: 4.1948e-06\n",
            "Epoch 47/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 40ms/step - loss: 3.4002e-05 - val_loss: 6.8181e-06\n",
            "Epoch 48/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 45ms/step - loss: 2.4791e-05 - val_loss: 4.1555e-07\n",
            "Epoch 49/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - loss: 2.9966e-05 - val_loss: 2.4952e-07\n",
            "Epoch 50/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 40ms/step - loss: 3.2447e-05 - val_loss: 2.4266e-06\n",
            "Epoch 51/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 45ms/step - loss: 3.2567e-05 - val_loss: 1.6005e-05\n",
            "Epoch 52/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - loss: 3.2751e-05 - val_loss: 1.0522e-06\n",
            "Epoch 53/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - loss: 3.2807e-05 - val_loss: 3.4827e-06\n",
            "Epoch 54/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 47ms/step - loss: 2.7612e-05 - val_loss: 1.9036e-06\n",
            "Epoch 55/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 50ms/step - loss: 2.7874e-05 - val_loss: 3.3252e-06\n",
            "Epoch 56/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 56ms/step - loss: 2.8295e-05 - val_loss: 6.4564e-07\n",
            "Epoch 57/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 41ms/step - loss: 3.3538e-05 - val_loss: 7.2810e-07\n",
            "Epoch 58/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 44ms/step - loss: 2.8604e-05 - val_loss: 3.0070e-06\n",
            "Epoch 59/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 54ms/step - loss: 3.0858e-05 - val_loss: 8.8112e-07\n",
            "Epoch 60/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 46ms/step - loss: 2.8712e-05 - val_loss: 5.9996e-06\n",
            "Epoch 61/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 52ms/step - loss: 3.2387e-05 - val_loss: 4.4796e-07\n",
            "Epoch 62/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 46ms/step - loss: 2.8849e-05 - val_loss: 3.2841e-07\n",
            "Epoch 63/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 51ms/step - loss: 2.4111e-05 - val_loss: 3.1699e-05\n",
            "Epoch 64/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - loss: 3.3262e-05 - val_loss: 2.4107e-06\n",
            "Epoch 65/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 40ms/step - loss: 3.3469e-05 - val_loss: 8.6778e-07\n",
            "Epoch 66/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 57ms/step - loss: 2.5382e-05 - val_loss: 3.1386e-06\n",
            "Epoch 67/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 41ms/step - loss: 3.0612e-05 - val_loss: 3.2803e-07\n",
            "Epoch 68/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 56ms/step - loss: 2.8319e-05 - val_loss: 9.4494e-06\n",
            "Epoch 69/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 40ms/step - loss: 2.8830e-05 - val_loss: 5.0290e-07\n",
            "Epoch 70/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 55ms/step - loss: 2.7652e-05 - val_loss: 4.7952e-05\n",
            "Epoch 71/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 44ms/step - loss: 7.8906e-05 - val_loss: 9.4930e-07\n",
            "Epoch 72/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 40ms/step - loss: 3.1729e-05 - val_loss: 1.3197e-05\n",
            "Epoch 73/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 46ms/step - loss: 4.0186e-05 - val_loss: 3.1686e-06\n",
            "Epoch 74/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 49ms/step - loss: 2.6629e-05 - val_loss: 1.3685e-06\n",
            "Epoch 75/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 40ms/step - loss: 3.1810e-05 - val_loss: 4.5158e-06\n",
            "Epoch 76/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 57ms/step - loss: 2.6528e-05 - val_loss: 2.5575e-07\n",
            "Epoch 77/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 41ms/step - loss: 2.8204e-05 - val_loss: 1.1465e-05\n",
            "Epoch 78/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 55ms/step - loss: 5.0691e-05 - val_loss: 4.1265e-06\n",
            "Epoch 79/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 40ms/step - loss: 3.8710e-05 - val_loss: 2.9563e-06\n",
            "Epoch 80/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 41ms/step - loss: 2.8169e-05 - val_loss: 4.6437e-07\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions\n",
        "HV_bilstm_predictions = bilstm_model.predict(HV_X_test)"
      ],
      "metadata": {
        "id": "tSQQeKmCatdG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cc7a4af-5feb-41eb-bc4f-cb7280fa877b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mse = mean_squared_error(HV_y_test, HV_bilstm_predictions)\n",
        "print(f'MSE: {mse}')\n",
        "\n",
        "rmse = np.sqrt(mse)\n",
        "print(f'RMSE: {rmse}')\n",
        "\n",
        "mae = mean_absolute_error(HV_y_test, HV_bilstm_predictions)\n",
        "print(f'MAE: {mae}')\n",
        "\n",
        "mape = calculate_mape(HV_y_test, HV_bilstm_predictions)\n",
        "print(f'MAPE: {mape}%')"
      ],
      "metadata": {
        "id": "GQwOXFU3atgm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "906d62cb-d835-49bf-bb54-6966217796c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 3.8155311358207005e-06\n",
            "RMSE: 0.0019533384591055134\n",
            "MAE: 0.0006127552149807471\n",
            "MAPE: 2879.532733753115%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BiLSTM_GRU"
      ],
      "metadata": {
        "id": "b4HabdZkeZeL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bilstm_gru_model = Sequential()\n",
        "bilstm_gru_model.add(Bidirectional(LSTM(48, return_sequences=True), input_shape=(HV_X_train.shape[1], HV_X_train.shape[2])))\n",
        "bilstm_gru_model.add(Dropout(0.1))\n",
        "bilstm_gru_model.add(GRU(16))\n",
        "bilstm_gru_model.add(Dropout(0.1))\n",
        "bilstm_gru_model.add(Dense(5))\n",
        "\n",
        "bilstm_gru_model.compile(optimizer=Adam(learning_rate=0.01), loss='mse')"
      ],
      "metadata": {
        "id": "39zUotTIc80l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcfb9ccd-df27-4f02-909a-05ebea9b38ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bilstm_gru_model.summary()"
      ],
      "metadata": {
        "id": "ueo7IuG1eqcL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "4f1285a7-32a4-4c18-e333-186969fa9c16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m96\u001b[0m)              │          \u001b[38;5;34m29,952\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m96\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_3 (\u001b[38;5;33mGRU\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │           \u001b[38;5;34m5,472\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │              \u001b[38;5;34m85\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">29,952</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">5,472</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">85</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m35,509\u001b[0m (138.71 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">35,509</span> (138.71 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m35,509\u001b[0m (138.71 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">35,509</span> (138.71 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bilstm_gru_history = bilstm_gru_model.fit(HV_X_train, HV_y_train, epochs=80, batch_size=32, validation_data=(HV_X_val, HV_y_val))"
      ],
      "metadata": {
        "id": "UrcF0MvXeqeh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dabed8a6-e53a-4bbe-c746-a43eda584a53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 41ms/step - loss: 0.0224 - val_loss: 9.5714e-05\n",
            "Epoch 2/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 49ms/step - loss: 4.0086e-04 - val_loss: 6.4990e-05\n",
            "Epoch 3/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - loss: 1.6273e-04 - val_loss: 1.6086e-05\n",
            "Epoch 4/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 45ms/step - loss: 9.3612e-05 - val_loss: 3.1896e-05\n",
            "Epoch 5/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - loss: 7.0743e-05 - val_loss: 1.1476e-05\n",
            "Epoch 6/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 50ms/step - loss: 4.9543e-05 - val_loss: 4.0822e-06\n",
            "Epoch 7/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 34ms/step - loss: 3.8572e-05 - val_loss: 2.7051e-06\n",
            "Epoch 8/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 3.8302e-05 - val_loss: 3.6396e-06\n",
            "Epoch 9/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 47ms/step - loss: 3.9543e-05 - val_loss: 4.1301e-06\n",
            "Epoch 10/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 38ms/step - loss: 3.0176e-05 - val_loss: 1.6422e-06\n",
            "Epoch 11/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 3.2826e-05 - val_loss: 1.4788e-06\n",
            "Epoch 12/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 3.0063e-05 - val_loss: 2.2954e-06\n",
            "Epoch 13/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 49ms/step - loss: 3.5162e-05 - val_loss: 1.8719e-06\n",
            "Epoch 14/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - loss: 3.2375e-05 - val_loss: 7.0371e-06\n",
            "Epoch 15/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 2.8123e-05 - val_loss: 2.1583e-06\n",
            "Epoch 16/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 47ms/step - loss: 3.0203e-05 - val_loss: 5.7427e-07\n",
            "Epoch 17/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - loss: 3.2126e-05 - val_loss: 1.3168e-06\n",
            "Epoch 18/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 48ms/step - loss: 2.5297e-05 - val_loss: 6.5766e-06\n",
            "Epoch 19/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - loss: 2.6938e-05 - val_loss: 1.9546e-06\n",
            "Epoch 20/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 3.3786e-05 - val_loss: 1.1832e-06\n",
            "Epoch 21/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - loss: 2.8123e-05 - val_loss: 7.7426e-05\n",
            "Epoch 22/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 49ms/step - loss: 1.0696e-04 - val_loss: 6.8396e-07\n",
            "Epoch 23/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - loss: 2.2003e-05 - val_loss: 2.1129e-06\n",
            "Epoch 24/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 48ms/step - loss: 2.3790e-05 - val_loss: 6.5806e-07\n",
            "Epoch 25/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - loss: 2.3584e-05 - val_loss: 1.3035e-06\n",
            "Epoch 26/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 49ms/step - loss: 2.8696e-05 - val_loss: 6.0305e-06\n",
            "Epoch 27/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 34ms/step - loss: 3.1123e-05 - val_loss: 9.6416e-07\n",
            "Epoch 28/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 2.4799e-05 - val_loss: 2.6036e-06\n",
            "Epoch 29/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 40ms/step - loss: 2.8281e-05 - val_loss: 2.6133e-06\n",
            "Epoch 30/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 49ms/step - loss: 2.9922e-05 - val_loss: 1.2242e-06\n",
            "Epoch 31/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 34ms/step - loss: 2.7334e-05 - val_loss: 1.9438e-06\n",
            "Epoch 32/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 50ms/step - loss: 2.6035e-05 - val_loss: 1.5617e-06\n",
            "Epoch 33/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 35ms/step - loss: 2.4685e-05 - val_loss: 4.3649e-07\n",
            "Epoch 34/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 50ms/step - loss: 3.0207e-05 - val_loss: 3.1987e-06\n",
            "Epoch 35/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - loss: 2.4020e-05 - val_loss: 2.5869e-06\n",
            "Epoch 36/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 41ms/step - loss: 2.7563e-05 - val_loss: 6.6517e-07\n",
            "Epoch 37/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 49ms/step - loss: 2.6061e-05 - val_loss: 1.0555e-06\n",
            "Epoch 38/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - loss: 2.7554e-05 - val_loss: 3.8888e-06\n",
            "Epoch 39/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 45ms/step - loss: 2.5471e-05 - val_loss: 1.1126e-05\n",
            "Epoch 40/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 45ms/step - loss: 2.4551e-05 - val_loss: 7.6646e-06\n",
            "Epoch 41/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - loss: 2.9366e-05 - val_loss: 2.1722e-06\n",
            "Epoch 42/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - loss: 3.2297e-05 - val_loss: 4.1048e-07\n",
            "Epoch 43/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 47ms/step - loss: 2.6979e-05 - val_loss: 2.4432e-05\n",
            "Epoch 44/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 40ms/step - loss: 2.9928e-05 - val_loss: 1.1473e-06\n",
            "Epoch 45/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - loss: 2.6118e-05 - val_loss: 1.0459e-06\n",
            "Epoch 46/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 49ms/step - loss: 3.4806e-05 - val_loss: 6.0849e-07\n",
            "Epoch 47/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 35ms/step - loss: 3.0803e-05 - val_loss: 8.4226e-07\n",
            "Epoch 48/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 49ms/step - loss: 2.8819e-05 - val_loss: 9.2154e-07\n",
            "Epoch 49/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 38ms/step - loss: 2.8787e-05 - val_loss: 7.0868e-07\n",
            "Epoch 50/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 2.7977e-05 - val_loss: 6.7936e-07\n",
            "Epoch 51/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 2.9949e-05 - val_loss: 1.3323e-06\n",
            "Epoch 52/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 40ms/step - loss: 2.8238e-05 - val_loss: 1.3525e-05\n",
            "Epoch 53/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 45ms/step - loss: 3.0108e-05 - val_loss: 8.3555e-07\n",
            "Epoch 54/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 45ms/step - loss: 3.7824e-05 - val_loss: 1.9506e-05\n",
            "Epoch 55/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 36ms/step - loss: 3.2016e-05 - val_loss: 3.5230e-06\n",
            "Epoch 56/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - loss: 2.1807e-05 - val_loss: 1.0971e-06\n",
            "Epoch 57/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 48ms/step - loss: 3.0221e-05 - val_loss: 1.8382e-07\n",
            "Epoch 58/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 40ms/step - loss: 3.4143e-05 - val_loss: 5.2550e-07\n",
            "Epoch 59/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - loss: 2.8859e-05 - val_loss: 1.9334e-06\n",
            "Epoch 60/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 53ms/step - loss: 2.9381e-05 - val_loss: 1.3823e-06\n",
            "Epoch 61/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - loss: 3.0320e-05 - val_loss: 3.5307e-06\n",
            "Epoch 62/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - loss: 2.8579e-05 - val_loss: 7.0028e-07\n",
            "Epoch 63/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - loss: 2.7910e-05 - val_loss: 3.7680e-06\n",
            "Epoch 64/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - loss: 2.8138e-05 - val_loss: 2.9551e-05\n",
            "Epoch 65/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 50ms/step - loss: 4.0284e-05 - val_loss: 6.1884e-07\n",
            "Epoch 66/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 35ms/step - loss: 2.8201e-05 - val_loss: 5.5945e-06\n",
            "Epoch 67/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 53ms/step - loss: 3.1554e-05 - val_loss: 3.0720e-06\n",
            "Epoch 68/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 36ms/step - loss: 2.4216e-05 - val_loss: 1.8313e-06\n",
            "Epoch 69/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 37ms/step - loss: 2.8419e-05 - val_loss: 3.0888e-05\n",
            "Epoch 70/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 49ms/step - loss: 3.6095e-05 - val_loss: 3.7833e-07\n",
            "Epoch 71/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - loss: 2.4593e-05 - val_loss: 5.8609e-07\n",
            "Epoch 72/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 51ms/step - loss: 2.7106e-05 - val_loss: 6.8151e-07\n",
            "Epoch 73/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - loss: 2.9251e-05 - val_loss: 6.5938e-07\n",
            "Epoch 74/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 42ms/step - loss: 3.4161e-05 - val_loss: 6.5323e-06\n",
            "Epoch 75/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - loss: 2.7959e-05 - val_loss: 1.1446e-06\n",
            "Epoch 76/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - loss: 2.4425e-05 - val_loss: 3.1601e-06\n",
            "Epoch 77/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 51ms/step - loss: 2.8968e-05 - val_loss: 1.7902e-07\n",
            "Epoch 78/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - loss: 3.4928e-05 - val_loss: 6.5241e-07\n",
            "Epoch 79/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 51ms/step - loss: 3.4563e-05 - val_loss: 5.6170e-07\n",
            "Epoch 80/80\n",
            "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 36ms/step - loss: 3.2344e-05 - val_loss: 2.6108e-07\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions\n",
        "HV_bilstm_gru_predictions = bilstm_gru_model.predict(HV_X_test)"
      ],
      "metadata": {
        "id": "v5nF6O0HeqiA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f9a2153-6b06-4f71-8a2b-8c7136906776"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mse = mean_squared_error(HV_y_test, HV_bilstm_gru_predictions)\n",
        "print(f'MSE: {mse}')\n",
        "\n",
        "rmse = np.sqrt(mse)\n",
        "print(f'RMSE: {rmse}')\n",
        "\n",
        "mae = mean_absolute_error(HV_y_test, HV_bilstm_gru_predictions)\n",
        "print(f'MAE: {mae}')\n",
        "\n",
        "mape = calculate_mape(HV_y_test, HV_bilstm_gru_predictions)\n",
        "print(f'MAPE: {mape}%')"
      ],
      "metadata": {
        "id": "f61Cmfi-e2N4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79257c0d-5247-4151-decc-989de19b402c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 2.1218975076803888e-07\n",
            "RMSE: 0.0004606405874084902\n",
            "MAE: 0.0003673203574768147\n",
            "MAPE: 1860.7385647695971%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cX3aHr7Ge2TQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# path_1 = '/content/drive/MyDrive/Volatility/New_data_2000_2024/New_predictions/RSV/'\n",
        "\n",
        "# df_pred = pd.DataFrame(HV_lstm_predictions[:,0], columns=['lstm_pred'])\n",
        "# filename = 'LSTM_pred.csv'\n",
        "# df_pred.to_csv(path_1 + filename)\n",
        "\n",
        "\n",
        "# df_pred = pd.DataFrame(HV_gru_predictions[:,0], columns=['gru_pred'])\n",
        "# filename = 'GRU_pred.csv'\n",
        "# df_pred.to_csv(path_1 + filename)\n",
        "\n",
        "\n",
        "# df_pred = pd.DataFrame(HV_lstm_gru_predictions[:,0], columns=['lstm_gru_pred'])\n",
        "# filename = 'LSTM_GRU_pred.csv'\n",
        "# df_pred.to_csv(path_1 + filename)\n",
        "\n",
        "\n",
        "# df_pred = pd.DataFrame(HV_bilstm_predictions[:,0], columns=['bilstm_pred'])\n",
        "# filename = 'BiLSTM_pred.csv'\n",
        "# df_pred.to_csv(path_1 + filename)\n",
        "\n",
        "\n",
        "# df_pred = pd.DataFrame(HV_bilstm_gru_predictions[:,0], columns=['bilstm_gru_pred'])\n",
        "# filename = 'BiLSTM_GRU_pred.csv'\n",
        "# df_pred.to_csv(path_1 + filename)"
      ],
      "metadata": {
        "id": "J72-kaK9-9en"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FqxXGkkX-9gd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}